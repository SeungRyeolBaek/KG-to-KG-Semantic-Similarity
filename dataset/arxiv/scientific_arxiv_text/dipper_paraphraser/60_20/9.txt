One of the main tasks of the segmentation process is to find the approximate location of the object, and to distinguish it from other entities of similar appearance. The segmentation is a combination of two tasks: recognition and delineation. In this study, a new, general method for object recognition is presented to help in the delineation. In this paper, we study a method to automatically recognize objects in 3d images, without performing elaborate searches or optimizations. for instance, the position of an organ model (heart) is estimated from its histogram, for example, the position of an organ model (heart) is estimated by the histogram. In the atlas , the point-of-axis affine registration is successfully applied to the data, to find the initial position of a cartilage. Alternatively, the popular particle filtering algorithm is used to identify the starting pose of a model for a single and a multi-object model. in this study a novel general method is introduced to help in the segmentation and delineation of objects, by exploiting the pose relationship which, via the concept of the ball-scale (b-scale) is used to relate the binary object and its associated images. In this study, we propose an approach to automatically recognize objects in 3D images, without performing exhaustive searches or optimizing the search. In this way, it is possible to recognize objects in 3D images without performing extensive searches and optimizations. In this paper, we investigate an approach to automatically recognize objects in 3D images without performing a complex search and optimization. This approach, which is based on the following principal ideas and components, has been proposed and tested in this paper: 1. The model building: 1. After transforming image data from all the subjects in the training set to a Finally the transformation Xmath9 which translates Xmath7 to Xmath6 is found. These are used to find the relationship between the segmented objects and the corresponding images. For each voxel, the radius of the largest ball of homogeneous intensity is weighed by the intensity value of that particular voxel, in order to incorporate appearance (detail) information into the object information (called a b-scale image: xmath3), so that a model of the correlations between shape and texture can be built. After all, given an image xmath10 to be segmented, the main idea here is to use xmath9 to get the right angle of xmath2 in xmath10 with the proper pose as indicated in step 4, as indicated in the next step. , assuming that the relationship of xmath11 to xmath6 is the same as that of xmath7 to xmath6, then a transformation xmath9 – that is to say, a transformation xmath9 – which relates xmath7 to xmath6 – a simple and proper method of thresholding the b-scale image yields a few largest balls. a simple and correct way of thresholding the b-scale image yields a few largest balls in the image. if one is to be successful in the finer details, it is necessary to conduct a precise search for it. However, since the coarse recognition method is highly accurate and the average recognition is high, one must not conduct a deep search. For finer details, however, one must resort to a specialized, customary delineation algorithm. We call this the gc-asm, a hybrid method of data, combining anatomically parallel slices from experts and (two) a semi-automatic way of specifying the point-correlations required by asm. To achieve this, we use the hybrid method gc-asm (incorporation of graph-segmented and active shape modeling) . Therefore, we use the gc-asm for the estimation of population statistics from a set of examples (training set) . shape and appearance are two complementary but closely related attributes of biological structures in images, and hence are often used to create statistical models. A useful way of automatically informing the previous information into computing systems is to use a flexible model, to encode information such as the expected size, shape, appearance and position of objects in an image. Nevertheless, as our approach uses an anatomically closest slice, the still more complicated problem becomes: how can the reference point be distinguished in the image and find the correct one? It is of paramount importance to select the right correspondences so that a good representation of the image will be achieved. Just let xmath12 be a single shape, and assume that its finite dimensional representation after the landmarking consist of @xmath13 landmark points with positions @xmath14, where @xmath15 are the coordinates of the point @xmath15 of the shape @xmath17. Equally spaced to these points, for each shape in the training set, one takes an initial point from each shape sample in the training set and then every shape in the training set carries the same anatomical point . Figure –“Standing out abd” shows the annotated landmarks of five different objects (skin, liver, right kidney, left kidney, spleen) in a slice of the abdominal region . . . . We remark that the present method is general and does not depend on special features of the application situation. ( 3 ) we show that both modelling and testing are performed on the ct data which are part of the clinical ct data that is routinely obtained at our hospital. ( 4 ) the specificity of the recognition increases greatly as the number of objects in the model increases. ( 4 ) the specificity of the recognition increases dramatically as the number of objects in the model increases. The present method can be used for such rapid and precise object recognition without requiring any explicit segmentation. The b-scale image of a given image captures the object morphometric information without being segmented. b-scales are fundamental units of an image in terms of the largest homogeneous balls that reside at each voxel of the image. . . brejl, m., sonka, m., 2009 . . . synergy between object recognition and image segmentation: a joint-client model. ieee transactions on pattern analysis and machine intelligience, vol. 31 ( 8), pp. 140560501 . brejl, m., sonka, m., 2009 . in the proceedings of digital image computing: techniques and applications, pp. . . .