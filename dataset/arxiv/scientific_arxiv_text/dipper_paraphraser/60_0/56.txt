, the measurements are carried out by the forward-looking radar of the US Army —xcite. Since targets are three dimensions, it is necessary to measure a three-dimensional information of each target. But the radar only measures a time-dependent curve for each target, see figure 5. Therefore, one can only reconstruct very limited information about each target . so, we only reconstruct an estimate of the dielectric constant of each target — that is, for each target, one is likely to obtain a sort of average of values of its spatially distributed dielectric constant — but even this information can be very useful for engineers. One important question that needs to be addressed in a numerical analysis of such a problem is: how can one achieve a sufficiently small neighborhood of the exact coefficient without a sufficient knowledge of the neighborhood? And the size of the neighborhood will depend only on the degree of noise in the data and the approximation errors. Moreover, the numerical method we use is the “global convergence method” (gcm). In this paper we develop a numerical method, which has a high guarantee of achieving this goal, called “global convergence” (gcm). Therefore, we formulate an analytically convergent method of an inverse medium-shrinking problem (Imps) with data from multiple frequencies. Then, given a closed ball of an arbitrary radius of xmath1 with a center at xmath2 in the correct hilbert space, it can be chosen by the cwf to have the variable xmath3 on it, so that the functional becomes strictly convex on that ball. Furthermore, it is proved that the gradient method reaches a sufficiently small neighborhood of the exact coefficient if its starting point is arbitrary on the ball, which is proportional to the size of the noise in the data. However, the major problem with these functions is that they are usually non-convex. Moreover, we prove that, given a closed ball of an arbitrary radius xmath1 with the center at xmath3 in an appropriate hilbert space, one can choose the parameter xmath3 of the cwf to such an extent that the functional becomes strictly convex on that ball. , and this is due to the fact that there are many local minima and ravines of non-convex cost functions. Among the most popular numerical methods for solving ill-posed problems use nonlinear optimization . we note that in the case of the problem of a non-convex cost function the gradient method only converges to the exact solution if the starting point is in a sufficiently small neighborhood of this solution, that is, due to the phenomenon of multiple local minima and ravines of such functions . . . however, the major problem with these functionals is that they are usually non-convex . The idea of any version of the gcm of the second type has direct roots in the method of xcite, which is based on the epoch estimates of carleman and which was originally intended for the proof of uniqueness theorems for cips, see a recent review of xcite . the convergence theorems for this method impose a small condition on the interval between variations of either the parameter @xmath7 of the laplace transform of the solution of the hyperbolic equation or the wave number @xmath8 of the helmholtz equation. in this case, on each step of the iterative process, one solves the Dirichlet boundary value problem for a certain linear elliptic pde, which is bound by that iterative step . the solution of this pde allows one to update the unknown coefficient first and then update a certain function, which is called the tail function . the same properties of the global strict convexity and the global convergence of the gradient projection method are contained in this paper. Recently the idea of the gcm of the second type was extended to quasilinear and ill-posed cauchy problems, see the theory in klquasi and some extensions and numerical examples in bakklkosh, klkosh . The cips of wave propagation are a major part of a larger category, inverse scattering (isps) . cips of the wave propagation are a part of a bigger category, inverse scattering (isps) . in this respect we refer to some direct methods which successfully reconstruct positions, sizes, and shapes of scatterers without iterations. , in section 7 we test our method on computationally simulated data, in section 7 we test it on experimental data . in this regard we cite some numerical methods for isps, considered in section . . . in section 2 we state our inverse problem, in section 3 we construct the weighted cost functional, in section 4 we prove the main property of this functional: its global strict convexity, in section 5 we prove the global convergence of the gradient-convexity method of minimization of this functional. we also refer to the corresponding numerical methods for isps in the frequency domain. - Construct the function - @ xmath30 - assuming that the following function - @ xmath28 - is known - - @ xmath28 -  label - 2 - a ==  -[1 -  -[2 ] - in particular, - @ xmath36 - a ==  xcite [2 -   -  - ode (in which we ode) @ xcite [2 - -  - in which we are a > - , in which we ode , ,  , ,  - [3 - ] , - an interval of waves [ xmath26] - a tiny interval of waves (qru, qru, u - x, qru, right ) ,  right arrow - infty,  forall x - infty ,  forall x - in % - left [ 0 , 1 , right ] ,  label  2 - ”   ] [10  ] - [21] - '!            - '" because there are large numbers of xmath, we define the function - ' "11" - xmath49 as '' xmath49 by (2 - 11) - xmath52, and by ' 2 - 13 - xmath56, and by the fact that - ' "" - '" - "' - " - ' that ' xmath56 is independent of '" xmath56, ' ' xmath56, ' xmath55,' ' (2 - 11 ) ', ' which ' xmath55' (and in ' '  ' ) ' xmath55, ' - ' - ', ' in '  -"   '      , ' '. ' , k in lbrack  underline  k, k overline  k ] ” , k in  lbrack  underline  k , k overline  k ] ” - in a word, k in  lbrack  underline  k, k overline  k ” -   label   3     ,  , , , , ,   - ,  , , , , , ,  - in a word, , , , , , ,  - ,  , , , , ,  , , ,  , , , , , , , , ,  , , , , , , , , , ,  , , ,  ,  , , ,  , ,  ,  ,   , ,   , .,  ,  ,  ,   , Well, we may now assume that we have obtained the approximation for both the functions @xmath100 and @xmath78. Suppose that we have obtained approximations for both the functions @xmath100 and @xmath78. Assuming that we have obtained the approximation for the function @xmath105 through the process of (3 . 1 ) and (3 . 2 ) we have learned that the best value of the $ xmath26 for the latter calculation is @xmath104 . Therefore, although the problem ( 3 . 6 ) - ( 3 . 70 ) is the same as the problem ( 65) - 66 in Xcite , the numerical method for the solution of the problem ( 3 . 6 ) - ( 3 . 70 ) is quite radically different from the method of xcite. therefore, even though the problem ( 3 . 6 ) - ( 3 . 70 ) is the same as the problem ( 6 ) - ( 6 ) in xcite , we do not update the tail function - the only difference is that tail functions are not updated here , but there are no such changes , but here we do not do it , this is the case (the answer, the answer, is the correct one.) – in (which is in accordance with the conditions of the qrm) we know that in the regularisation of the problem, by means of the quasi-reversibility method (qrm), we have shown that the solution of the minimization problem, as well as the convergence of the minimization problems, in the qrm, to the exact solution of the problem, (i.e., 3 . 11), with the exact data of Xmath124, as well as the size of Xmath124, which is, of course, due to the approximate nature of (i.e., 3 . 9). Hence, as we have seen in this chapter, we minimize the following function @ Xmath120 on the basis of the set @ xmath121, where @ xmath122 and @ xmath124 are the constants of the normalization, where the boundary condition @ xmath124 is the regularization parameter. This is particularly a feature of (i.e., 3, 7, 9), which is probably due to the approximate nature of (i.e., 3 . 9 ). , there is a sound solution of our problem with noiseless data , ... [3 ... 12] , where ... 135 ... and  ...  - ay  alpha  left (  delta  right) ... v   alpha  left (  delta  right) ...  v  h    h   h   h   h  2  right    h  h  h   left ( x - %  underline  k -  right ) ...  right   h   h  h  2  right  vert   h    left            alpha  left     left   left ( x - right)  left ( y - 0 - 1 - right) ... If we take into account the complexity of a few and complexly valued functions, we shall consider below ... et> – 226 ‘and – et - 227 > Then (327 ) –  –  infty%  End  array –  – right – .  327   227 –  – — 327 – submitter – et|, ‘trp’ (see point – 327), ‘trp’ (see point – 327), ‘trp’ – – ‘trp’ (‘trp’) ‘trp’; and ‘trp’ (and the corresponding p–rp’) ‘trp’. For the computation of these theorems, we have to maintain zero boundary conditions at xmath150. In order to employ the hilbert space we introduce the hilbert space of the open set of real-valued functions at xmath165, and if so we would add ‘to xmath164’ ‘as much as possible, to xmath164 ‘fee’. ‘Of course, one cannot overstep one’s bounds. The first part of the coefficient of the vector function @ xmath166, or the above functions @ xmath166, theorem 4 . . . in this paper . . . 405. Theorem 4 . . . as a result of the conditions of theorem 3 . . . by (theorem 4 . . .) @ xmath186    leq  left  vert v   ast    ast    c   1   left [0 , 1  right]  + c   1  delta  leq c  2   the label  3 . . .  theorem 4 . . . Since . . . 3 is satisfied, then by ([3 . . . ] . . . “Example - By (X  16) and (X  25) in X 19 we separate out in X 199 that part which is linear with respect to the vector function in X 199. At X 198 the parts that are linear with respect to the vector function in X 199 are, in x 199 the part which is linear with respect to the vector function in X 199. In x 199  overline  l  left (p  right)  % h . . . ” In the left-hand side of (33), = 1 and = 1 and = 1 are the same. In = 1 and = 1 we derive the expression = 2 and = 2 in = 2 : the first two lines of = 2 are the first two lines of = 2 and = 2; and as a result of (33), = 2 and = 2 the second term in the right-hand side of = 2 is obtained. In =2 =2= int  limits =2 , int   [3], int  [3][4] ,  « «, «  «, «,    « [6]                 [5],            [5],               [7],                       [7], in the same way. That is, if we assume the frecht derivative of the functional of xmath170 at the moment of xmath241 and if we note that xmath241 exists, and if we assume that xmath241 exists, we mean that xmath241 . . . ” so that xmath254 is a lipchitz continuous function, for instance, for xmath256, and we say, “On xmath256 we denote, “On xmath258 we define ” ” . . . . theorem 4 . 1 . . . 1. ” Then we conclude in this section that the gradient projection method of minimization of the functional xmath254 for xmath228 has global convergence with other methods of the gradient method, they will be discussed in subsequent publications. . . . let the conditions of theorem 3 . 1 stand. . . . "Theorem 5:2 claims that there is unique and unique minimization of the functional "xmath158" on the closed ball, #xmath270, and #xmath275, for example,  geq 0 ,  forall y  ,  b  left (r  right) . . . See the sequence of the gradient projection, #xmath270 , let the factor xmath270 be the operator of the projection of the space of Xmath158 on the closed ball, twaint twaint twaint twaint twaint twaint twaint, twaint twaint, twaint twaint, twaint twaint, twaint twaint, twaint twaint twaint twaint twaint, twaint, swaint twaint, twaint twaint, intwaint, twaint. - Below the superscript - xmath285 - and -  px  - p - p - p - p - p - p - p - p - p  1 -    ast   p - c - left [underline - k - p - p - p - right  - c -   -       [the , , ,  ,    " (you can make the number math287 only the set of parameters math287) so that in this section we show that the gradient method delivers points in a small neighbourhood of the function xmath288 and therefore of the function xmath289 the size of this neighborhood is proportional to xmath290, it is convenient to indicate in this section the dependencies of the functional xmath291 from xmath292 and xmath290 , in this section we write in this section math294 * , we write in this section math294  theorem 4 “The latter is clearly not so.” – “So,” said, “the former is the same as in the following figure (#5 – 6. – The latter is a sure rule.” “Second, p –  ,     ,  ,   ,  ,    ,   ,    ast   left  vert p – , p –      ast  right –    c – %  left [    ,    ,   ,     left – vert p –         left – vert p –         left – vert v      ast  right – vert   c %  left [  underline  k,     right]      2  +  left  vert v   alpha  left (delta  right)      2   right )     2 However, we have seen in our simulations that the regular and simpler gradient method provides practically the same results. Theorem 5 - 4 ensures the global convergence of our method, see the definition in the introduction. , which, in order to minimize the functional xmath318 we have written the derivatives of the operator xmath319 in discrete forms, using the trapezoidal rule, with the step size xmath320 , we have also written integrals with respect to xmath264 in discrete forms, using the trapezoidal rule, with the step size xmath320 , the differentiation of the data xmath264 with respect to xmath264, which is necessary for our method (see the definition in the introduction). This procedure was implemented initially by the gradient method . . . However, we have observed in our calculations that the regular and simpler gradient method gives almost the same results. We have therefore made the following numerical steps for the numerical simulation and experimental data . . . now , in our work, where similar differentiations were made, and even with the experimental data, we have minimized the corresponding discrete version of xmath168 with respect to the values of xmath168 on those grid points . . . - minimize the functional ( [3 . 12] - let - xmath328 be its reducer ... ; compute the function ([3 . 12] - see ([3 . 16] and - 3 . 170) ... , in this algorithm, unlike the other globally convergent algorithms, - xcite, we do not need to update the tail function - xmath333, after that, in all our calculations, we use - xmath333 - because, as a matter of fact, our goal is to image a physical object, for example, an explosive target, we have chosen in our numerical experiments the true test coefficient - xmath340: - where - xmath340 is the location of the center of our object and - xmath340 is the width . - Therefore, the depth / the reflection of the figure - is 7 . . . so that the effective - background contrast in '6 . ' . . so let @ xmath361 be the discrete xmath362 norm of the gradient of the above-described discrete version of the functional xmath363 (fig. gnorm) and illustrates the dependencies of this norm on the number of iterations of the gradient method for different values of xmath364. we have seen in our calculations that the dependencies are very similar for targets that satisfy xmath365, i.e., with different contrasts on the target and the background. So the next question is the choice of an optimal parameter, xmath364, even though theorem 4 . 1 says that the functional xmath170 is strictly convex on the closed ball xmath164, so the larger xmath365 is, the less the influence of xmath168 on points xmath357 which are relatively far from the point xmath358 where the data is given. - In this study, klibloc, kuzh, ieee, we used the same data as in klibloc, kuzh, ieee, where the data were treated by the tail-function method. in klibloc, kuzh, ieee, we have used the same data set as in klibloc, kuzh, ieee, where the data are treated by the tail-function method. * the result of xmath375 is truncated as xmath370, in klibloc, klibloc, kuzh, ieeee, the data are treated with the tail-function method. The data in klibloc and klibloc are obtained after applying the laplace transform and the fourier transform, respectively, to the original time-dependent data. Here we obtain the same data as in klibloc, klibloc, kuzh, ieee, where the results of the tail-function method are treated. Thus it is worth testing the new method in this data set. The results of the numerical process in klibloc and klibloc are compared with the results of the experiments in klibloc, kuzh, ieee, where the results of the numerical method are treated by the tail-function method. In klibloc and klibloc, the process of propagation of a hyperbolic equation is modeled with a d-c hyperbolic equation, the laplace transform for the time of the solver is applied, and then the proportions of the function are calculated, [0, 2] No, I don’t want to. “Try this: “To hell with me!” ... (to hell with you ... ah, hell with you ... no, with me ... ah, so now that I’m coming to you ... He ... got it! He ... ah, he ... ah ... 2 ... 3 ... 2 ... 3 ... bh ... 3 ... bh ... bh ... 3 ... 5 ... 5 ... 3 ... bh ... 3 ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... bh ... b They were measured at intervals of up to 20 meters from the target of interest. Then the analysis was done on the whole area. The two tests were done, one on the ground and another on a foundation, on a depth of several centimetres . . . the horizontal axis is the time in nanoseconds . . . if a target occupies a sub-interval, then we estimate the ratio of dielectric constants of targets and backgrounds to xmath380 . . . (after the period for the calculations) . . . . it was shown on page 2944 of 165 that if we assume that the target occupies a sub-interval, we then calculate here the ratio of dielectric constants of targets and backgrounds to xmath380 . . . since the value of 251 in 36 is a high value in physics. The vertical axis is the time in nanoseconds . . . the horizontal axis is the time in nanoseconds . . . It was shown on page 2944 of xcite that, using the time dependent date, we can deduce that the target occupies a sub-interval inside the target, so that we estimate the ratio of dielectric constants of targets and backgrounds for @xmath380, and this is what we do in this case, and the only difference between the time, . . . . . In the figure, Fig. 71/ti) the information for the choice was the same as in the example in section 6.1 the decision (at the first place) was the same as in the simulated data in section 6.2. Two targets, bush and wood stake, were placed in the air, and three targets, metal cylinder, metal cylinder and plastic cylinder, were buried in sand. the temperature was air, in the case of the two targets sprayed in the air, and the pressure was sand, in the case of the buried targets. . . . the temperature was air for the two targets placed in the air, and the background was sand for the three targets buried in the sand. As to the metal targets, it was mathematically proved by means of xcite that they can be represented by dielectric constants with high values of the dielectric constant, xmath397 . . . , , ,   , ,  . . . and the published values of the dielectric constants of the sand, wood and plastic are in xcite. So, the table of values in this table is the most interesting bit of information from the engineering point of view. This table is marked in the first place with the observation that the value of the estimated dielectric constants in the xmath398 region is always within the bounds of xmath399, as was observed in Section 1, this estimate, although not perfectly correct, may be very useful for the very important purpose of reducing false alarms. We have developed a new universal numerical method for the inverse medium scattering ( [3].4] . we have developed theorem 4; we have demonstrated that the strict convexity of the function on a closed ball, in any radius of xmath400, is convex, as long as the parameter xmath401 is selected appropriately. This method is based on the construction of a functional of a weighted cost function, with the carleman weight function. It is based on the construction of a weighted cost function with the Carleman weight function in it . our team is trying to develop it in the future. At its best, I did not catch it, so that the same outcome was done. And I knew it was not for a long time. The computer magazine of inverse and mismatched problems consists of a case study, 28 (2012) p. 74908. m. v. kuzhuget, l. beilina, m. v. klibanov, a. sullivan, l. nguyen, and h. liu, an equation of blind backscattering experiments collected in the field and a universally convergent inverse method, (2016) pp. 9571090. m. v. kuzhuget, l. beilina, m. v. klibanov, a. sullivan, l. nguyen, and m. a. fiddy, quantitative data recovery from measured blind backscattering experimental data, and a global convergent numerical method for 1 - d inverse medium problem, with experimental data - , Journal of inverse and ill-posed problems, 24 (2016), p. 761776. esaim : mathematical modelling and numerical analysis, 58 (2015) , pp. 459480. n. t. thnh, l. beilina, m. v. klibanov, and m. a. fiddy , 'Images ofburied objects from experimental measurements using a global convergent inverse algorithm,' in the Journal of the Imaging Sciences, 8 (2015) , pp. 757786.