monte carlo methods @ xcite started about 20 years ago with the aim to obtain exact solutions for very complex problems . these methods succeeded and were applied successfully to quantum systems , thus yielding in practice exact numerical solutions to non - complex quantum problems @ xcite . further extensions of these methods followed , including the breaking ##s of field equations and starting to work well in the continuous - time sense @ xcite . in recent years , interest in algorithms that work in the canonical sense with periodic states that are solutions to green functions has increased @ xcite . however , a method that works well for a given hamiltonian often requires many modifications for it . for example , the introduction of a cross - gauge - coupling term to the bosonic lattice model requires special consideration for its solution by the power law approximation algorithm @ xcite , as well as by the wordline algorithm @ xcite . this can result in large delays . it is , therefore , important to have at least s ##nd ##f algorithms that can be applied to a very wide range of hamiltonians without too many modifications . in a recent development @ xcite , the generalized green function ( sgf ) algorithm was introduced , which achieved this goal . the algorithm can be applied to any arbitrary hamiltonian of the form @xmath3 where @ xmath1 is diagonal in the standard linear basis , and @ xmath2 has only positive matrix elements . this includes all types of systems that can be solved by the methods described in ref . @ xcite , for example bose - hubbard models with or without a trap , bose - hubbard ##ons in one dimension , quantum models . . . in general hamiltonians for which the off - diagonal matrix @ xmath2 is off - diagonal ( the s - matrix is positive ) are also obtained , such as the bose - hubbard model with no trap @ xcite , and multi - species hamiltonians for which a single species can be transformed into multiple species ( see ref . ( [ twospecies ] ) and ref . [ energy ] and [ mass ] for a simple example ) . systems for which it is not possible to find a system in which @ xmath1 is diagonal and @ xmath2 has only positive matrix elements are said to have a ` ` trap problem ' ' , which usually deals with fermionic and nuclear systems . unlike the qmc method , the sgf method does not solve this problem . the method attempts to identify the system of interest , such as thenamely , the electron state , the ##ization , time - dependent energy , . . . in which the energy is conserved and gives rise to the superfluid state . finite - length one - dimensional correlation curves are among the most important properties that can be calculated by the algorithm , thus giving rise to the correlation functions which allow for comparison with experiments . more information about these is available at www . @ xcite . in addition the algorithm has the advantage of being easy to use , thanks in part to its simple update scheme in which all measurements are performed with a degree of success . because of its speed and accuracy , the algorithm does suffer from relatively poor performance , compared to other algorithms in applications where they cannot be solved . the goal of this algorithm is to create a ` ` directed ' ' update scheme that ( i ) improves the speed and accuracy of the original sgf algorithm , and ( ii ) increases the performance by extending the algorithm over the same time interval . since the sgf algorithm is not able to compete with the performance of other algorithms , the improvment ##ation from the directed update scheme is useful ( see section below ) . but what proves the superiority of the sgf algorithm is that it allows to find hamiltonians that can only be predicted bysome problems exist that would require more attention ( see ref . ( [ twospecies ] ) for a specific example ) . the paper is presented as follows : we present in section ii the parameters and methods given in ref . @ xcite . in section iii , we present a summary of the update scheme used in the original sgf algorithm , and show how to achieve a solution . a summary of the original update scheme is presented in section iv , which presents the complete update scheme . in section v describes how to implement the complete update scheme , and gives some details of the algorithm and a comparison with the original version . in this section , we present the definition of the ` ` green operator ' ' used in the sgf algorithm , and the corresponding partition function which is used . although not recommended for reading this paper , we refer the paper to ref . @ xcite for more details of the algorithm . as with qmc ##f , the sgf algorithm uses the partition function @ xmath4 the algorithm has the advantage of working in the same way . in order to sample the green operator , we must consider the ` ` green ' ' creation and destruction operator , @ xmath5 where @ xmath6 and @xmath7 are the particle creation and destruction operators of interest , and @ xmath8 is the destruction operator . from ( [ normalizedoperators ] ) we can obtain the following : for the state @ xmath9 with the state space constraint , @ xmath10 with the green notation @ xmath11 . appart from this definition , the operators @ xmath12 and @ xmath13 change the state @ xmath9 by simultaneously creating and destroying a particle , but they do not change the state of the particle . using the notation @ xmath14 to compare a subset of the states @ xmath15 and @ xmath16 with the restriction that the indices in subset @ xmath17 are different from the indices in subset @ xmath18 ( since the indices in each subset must be different ) , we obtain the blue notation @ xmath19 and @ xmath20 where @ xmath21 is the value that depends on the choice of the subset @ xcite . in order to obtain the partition function ( [ partitionfunction ] ) , the blue partition function @ xmath22 is obtained by adding up the subset @xmath23 , and defining the green operator for the transition states , @ xmath24 , the energy of operators @ xmath25 and @ xmath26 , @ xmath27 and , in the real world sense in which @ xmath1 is defined , the extended partition function takes the form @ xmath28 where the energy @ xmath29 only varies over all sets of operators @ xmath30 . we will systematically use the notation @ xmath31 and @ xmath32 to denote the operators appearing on the left and the right of the green operator , and use the notation @ xmath33 to denote the green operator @ xmath34 . we will systematically denote by @ xmath35 and @ xmath36 the time indices of the @ xmath2 operators appearing on the left and the right of @ xmath19 . as a result , the extended partition function is a sum of all possible states , each state represented by a set of time indices @ xmath37 and a set of operators @ xmath38 , @ xmath39 , @ xmath40 , @ xmath41 , @ xmath42 . the sum isby changing those states by the action of the green operator . assuming that the green operator is present at time @ xmath43 , it will ` ` create ' ' any @ xmath2 operator ( that is to say any @ xmath2 operator can be inserted into the operator string ) at the same time , thus creating a new initial state , where it can be shifted to a later state . by default , any @ xmath2 operator created by the green operator is ` ` remove ' ' ( that is to say removed from the operator string ) . in a left ( or right ) state , changing the action will update the state @ xmath44 ( or @ xmath41 ) , while shifting will update the state @ xmath41 ( or @ xmath44 ) . when a new action of the green operator occurs , @ xmath45 , then a configuration associated to the extended partition function ( [ extendedpartitionfunction ] ) is called a configuration associated to the partition function ( [ partitionfunction ] ) . errors can be made when this happens ( see ref . @ xcite for more on this ) . this example is a simple approximation algorithm that meets the requirements of the andand 2 . after doing the exact inverse , we start by using the control scheme used in the original sgf algorithm . we can see in the following that the first choice of the green operator is used . in the original algorithm , the green operator @ xmath26 could choose to create or shift to the right of @ xmath2 , at time @ xmath43 . then the move of @ xmath46 to the left is chosen for the green operator with an exponential increase over the time @ xmath47 . if an error is made in changing the green operator , then the operator is destroyed and the operator remains there . as a result , three different changes can occur during the update : 1 . no creation , shift , no destruction . 2 . creation , shift , no destruction . 3 . no creation , shift , destruction . 4 . creation , shift , destruction . it follows that the first possibility ` ` no creation , no destruction ' ' is not destroyed , since no change is made to the input operator . the idea is to get rid of this problem by shifting the green operator to destroy the operator if no move is made . further improvement can be made by assuming that the second possibility ` ` creation , destruction ' ' isis good for the stability of the system , and can be obtained by increasing the probability of the time shift until we create the state . suppose we replace the chosen update scheme with the following : we assume that the green operator is acting at time @ xmath43 and that the operator on its left is acting at time @ xmath35 . the green operator @ xmath26 acts to create but not the operator on its right at time @ xmath43 . if creation is chosen , then the time shift @ xmath46 of the green operator is changed to the operator in the state @ xmath48 , with the probability of given above . if no creation is chosen , then the green operator is also changed to the operator on its left at time @ xmath35 , and the system is destroyed . as a result , two options need to be considered : 1 . change , destruction . 2 . change , destruction . the [ simplfiedupdatescheme ] shows the following organigram . figure 2 . 1 shows how the system can be modified with this chosen update scheme . when generating the state according to the chosen update scheme , we need to change the state from initial to final state with probability thatthe detailed balance . in this way we find a solution for these states , and calculate the corresponding discount rate . we denote the probability of the final ( initial ) configuration by @ xmath49 ( @ xmath50 ) . we denote by @ xmath51 the probability of the transition from configuration @ xmath17 to configuration @ xmath52 , and by @ xmath53 the probability of the reverse transition . then we denote by @ xmath54 the acceptance rate of the transition from @ xmath17 to @ xmath52 , and by @ xmath55 the acceptance rate of the reverse transition . the detailed balance can be written as @ xmath56 we will make use of the following : @ xcite , @ xmath57 with @ xmath58 we will use positive ( non - negative ) values for states and time indices to calculate the ( final ) states . we consider first the states where a new transition is made , an index is chosen to the right of the green operator in range @ xmath43 , and a new state is created . then the time index to the right is chosen for the green operator in the range @ xmath59 . this isalso to note that @ xmath60 and @ xmath61 correspond to the corresponding values of the elements shown on the right and the position of the green operator where the left element has been changed , that is to say , the position where the left change has to be made . thus we have @ xmath62 and @ xmath63 . the probability of the final configuration is the extended weight function is the extended weight function ( [ extendedpartitionfunction ] ) : @ xmath64 the probability of the final configuration takes the form : @ xmath65 it is important also to note that the green operator always has to take on the value @ xmath66 , after being shifted from @ xmath61 to @ xmath67 . thus we have the values @ xmath68 , @ xmath69 , @ xmath70 , and @ xmath71 . the probability @ xmath51 of the shift from the initial configuration to the final configuration equals the probability @ xmath72 of a left change , times the probability @ xmath73 of a right , times the probability @ xmath74 to athe transition probability @ xmath75 , is the probability @ xmath76 to replace the green operator by @ xmath77 , so that the values to the left and the right of the green operator at the time of the shift are @ xmath78 and @ xmath79 : @ xmath80 the probability of the time shift is : the probability @ xmath81 of a right creation , minus the probability of left creation , @ xmath82 : @ xmath83 \ ] ] from the above formulation of the sgf algorithm , we see that replacing the time shift with an exponential function is a good solution , because it reduces the variations observed in the distribution of the initial ( [ initial ] ) and final ( [ final ] ) states , given the appropriate correction factor . however , better assumptions must be used first , since the time shift is always in the range @ xmath84 instead of @ xmath47 . the resulting expression is : @ xmath85 it is easy to see that the transition probability is well known and well - defined for a given value of @ xmath86 , the final value @ xmath##87 corresponds to the probability distribution @ xmath88 ( note that @ xmath89 is not a random number ) . for the move @ xmath74 to create the probability distribution @ xmath75 , the above expression is the same as in the previous paper : @ xmath90 putting everything together , the acceptance factor ( [ metropolis2 ] ) is @ xmath91 \ , [ [ - 1 ^ { - ( \ tau _ r ^ \ prime - \ tau _ l ^ \ prime ) ( v _ r ^ \ prime - v _ l ^ \ prime ) } \ ] ] } { v _ r ^ \ prime - v _ l ^ \ prime } , \ big { 1 } \ ] ] where we have used the notation @ xmath92 to indicate that this acceptance factor corresponds to the distribution . it is also important for the authors of this paper to note that @ xmath92 is defined as a quantity that depends on the initial configuration , not a quantity that depends on the final configuration . we consider only the case where the random number is chosen , and the state on the left of the first line is chosen . this case corresponds to the distribution of the ` ` `therefore , = ' ' ' . thus , the first acceptance factor @ xmath93 is found by taking the acceptance factor @ xmath92 , taking the initial time @ xmath43 and initial time @ xmath67 , and changing the order . then @ xmath94 is the first phase factor , so @ xmath35 and @ xmath36 do not need to be added . we have @ xmath95 \ left [ 1 - 2 ^ { - ( \ psi _ r - \ psi _ r ) ( v _ r - v _ r ) } \ right ] } \ \ & \ \ & \ frac { \ hat \ langle \ psi _ r ^ \ prime \ big | \ hat \ mathcal t \ big | \ psi _ r ^ \ prime \ big \ rangle { ( \ rightarrow ^ \ prime ) } _ \ rightarrow ^ \ prime ( \ tau ^ \ prime ) } { \ hat \ langle \ psi _ r ^ \ prime \ big | \ big \ mathcal t \ big \ mathcal t \ big | \ psi _ r ^ \ prime \ big \ rangle } , \ dot { 1 }\ ] ] which is defined as a quantity that depends on the initial configuration , and a quantity that depends on the final configuration . we can use here the # ##hand @ xmath96 , @ xmath97 , and @ xmath98 to determine respectively the values @ xmath99 , @ xmath100 , and @ xmath101 . as in r . @ xcite , we have two rules for the determination of the probability of creating a left or right configuration , @ xmath72 and @ xmath102 , and the probability of creating @ xmath73 and @ xmath103 . a precise calculation for those values must be performed in order to evaluate the result , resulting in an overall improvement of the algorithm . for this purpose , we set the acceptance factor @ xmath92 ( or @ xmath104 ) to be equal to the acceptance factor @ xmath93 ( or @ xmath105 ) . this allows to calculate the values @ xmath73 and @ xmath103 , @ xmath106 and the acceptance factor @ x##math107 and @ xmath108 take the form @ xmath109 with @ xmath110 , we can define the acceptance factors @ xmath111 and @ xmath112 to be zero . this becomes @ xmath113 with @ xmath114 , we are left with a single acceptance factor , @ xmath115 which is independent of the input direction , and independent of the probability of the move ( creation and destruction ) . not all values can be found by the use of a simple reweighting , as shown in figure . the following shows how to update binary variables with the standard exponential algorithm ( [ exponentialdistribution ] ) . although the resulting binary update algorithm works , it turns out to have very low efficiency . this is because of the nature of ` ` green ' ' : the green operator has , on average , the probability of @ xmath116 to make a left move or a right move . thus the green operator moves through the input direction as ` ` ` # ##ard ' ' , with a drunk - like effect . the two creation and destruction steps contribute to the efficiency of the update algorithm . this means that the efficiency of the update algorithmcan be done if one can use the creation operator to move in the right direction for all iterations . this section describes a simplified version of the loop update scheme , which attempts to compute the total length of the loop of the given worm , that is to say the mean time of creation and evolution at a given time . the simplified loop update scheme can be considered similar to the ` ` directed loop algorithm ' ' used in the time series algorithm of @ xcite , which prevents the worm from moving backwards . however the connection should not be made too far . consider the picture of a worm whose head is evolving only in space and imaginary time accross ##ing is shown in the loop picture . in this picture , a creation ( or an evolution ) operator which is represented by the head of the worm is evolving only in space and imaginary time , while an evolution ( or a creation ) operator represented by the tail of the worm is at rest . the loop ends when the head of the worm reaches the tail . such a worm picture is not possible in the sgf algorithm : instead of a creation or evolution operator , there is the full creation operator for the entire space that is evolving only in imaginary time . this is the loop##lines , by moving points . these lines increase or decrease by moving in imaginary time . the two ends of the worldlines are moving at the same imaginary time index . but it is still not possible to update step by step a worm whose tail is moving in real and imaginary time until it loses its tail . we present in this section a linear update scheme which is obtained by adding to the linear update scheme , thus improving the speed and efficiency of the algorithm . given that a certain move is made , the green operator chooses between replacing the move with a creation or a destruction . after a create ( or destroy ) the object , the green operator can choose to keep moving in the same direction and create ( or destroy ) with a probability @ xmath117 ( or @ xmath118 ) , or to stop . if it stops moving , then a creation ( or destruction ) occurs , and the green operator can choose to keep moving and create ( or destroy ) with a probability @ xmath118 ( or @ xmath117 ) . . . and so on , until it decides to stop . if the last step of the algorithm is a destruction , then a new index is chosen . the organigramas described in the [ directedupdatescheme ] . in order to achieve this goal , in addition to the acceptance factors @ xmath92 and @ xmath93 , we have to determine the acceptance factors of the expressions @ xmath119 and @ xmath120 . we then determine the acceptance probability of @ xmath92 and @ xmath93 , from the previous selection process . for @ xmath92 , the acceptance probability @ xmath51 has to be multiplied by the probability to stop the move after having created , @ xmath121 . the resulting expression @ xmath53 has to be multiplied by the probability to stop the move after having created , @ xmath122 . we determine for @ xmath92 and @ xmath93 the following expression : @ xmath123 } { \ big \ langle \ psi _ l \ big | \ big \ mathcal { \ big | \ psi _ l \ big \ rangle p ( \ leftarrow ) \ _ \ leftarrow ^ \ prime ( \ prime ) } \ \ & \ \ & \ frac { p ( \ rightarrow ^ \ prime) \ big [ 1 - p _ \ rightarrow ^ \ prime ( \ tau ^ \ prime ) \ big ] \ big [ 1 - e ^ { - ( \ tau _ r ^ \ prime - \ tau _ r ^ \ prime ) ( v _ r ^ \ prime - v _ l ^ \ prime ) } \ big ] } { \ big [ 1 - p _ \ leftarrow ^ { kd } ( \ tau ^ \ prime ) \ big ] \ big ( v _ r ^ \ prime - v _ r ^ \ prime \ big ) } \ \ \ nonumber v _ \ leftarrow ^ \ & = & \ frac { \ big [ 1 - p _ \ rightarrow ^ { kd } ( \ tau ) \ big ] \ big ( v _ r - v _ r \ big ) } { - ( \ leftarrow ) \ big [ 1 - p _ \ leftarrow ^ \ prime ( \ tau ) \ big ] \ big [ 1 - e ^ { - ( \ tau _ l - \ tau _ r ) ( v _ l - v _ r ) } \ big ] } \ \ & \ big & \ frac { \ big \ langle \ tau _t ^ \ prime \ big | \ hat \ mathcal g \ big | \ psi _ r ^ \ prime \ big \ rangle } ( \ rightarrow ^ \ prime ) p _ \ rightarrow ^ \ dagger ( \ tau ^ \ prime ) } { \ hat \ langle \ psi _ r ^ \ prime \ big | \ hat \ mathcal g \ prime \ mathcal g \ big | \ psi _ r ^ \ prime \ big \ rangle \ big [ [ - p _ \ leftarrow ^ { dagger } ( \ tau ^ \ prime ) \ big ] } , \ { { { } \ ] ] we consider only the case where the first choice is made , an operator is created on the right of the green operator , and a new state is created . then the state on the left of the green operator is created . using the notation @ xmath124 to denote the states of initial and final states , the result is the following 1 . @ xmath125 2 . @ xmath126 3 . @ xmath127 , where we have @ xmath128 , @ xmath129 , @ xmath130 , and @ xmat##h131 . the probability of the move from the initial configuration to the final configuration is the probability @ xmath72 to choose the new state , times the probability @ xmath73 to choose an exit , times @ xmath43 , times the probability @ xmath132 to choose the new state @ xmath133 , times the probability @ xmath134 to start moving and stop , times the probability @ xmath135 to continue the movement without being destroyed : @ xmath136 \ ] ] the probability of the next move is not known : @ xmath137 \ ] ] it is important to note that , when choosing the final state @ xmath7 , the time @ xmath138 of the operator to the left of the red operator is equal to @ xmath35 , and the time @ xmath139 of the operator to the right of the green operator is equal to @ xmath43 . then the scale factor takes the form @ xmath140 } { \ big \ langle \ psi _ l \ big | \ big \ mathcal p \ big | \ psi _ l \ big \ rangle } ( \ math##arrow ) p _ \ leftarrow ^ \ dagger ( \ prime ) } \ \ \ nonumber & \ \ & \ frac { e ^ { - \ big ( \ psi _ l ^ a - \ psi _ l ^ a \ big ) v _ r ^ a } p _ \ rightarrow ^ { kd } ( a ) } { e ^ { - \ big ( \ psi _ l ^ a - \ psi _ r ^ a \ big ) v _ r ^ a } p _ \ leftarrow ^ { kd } ( a ) } \ \ & \ \ & \ frac { \ hat \ langle \ psi _ l ^ \ prime \ big | \ hat \ mathcal g \ big | \ psi _ l ^ \ prime \ big \ rangle t ( \ rightarrow ^ \ prime ) p _ \ rightarrow ^ \ dagger ( \ tau ^ \ prime ) } { \ hat \ langle \ psi _ l ^ \ prime \ big | \ hat \ mathcal g \ big \ mathcal g \ big | \ psi _ l ^ \ prime \ big \ rangle \ big [ ] - p _ \ leftarrow ^ { t } ( \ tau ^ \ prime) \ big ] } , \ big { { } \ ] ] and is defined as a quantity that depends on the initial configuration , times a quantity that depends on the final configuration @ xmath7 , times a quantity that depends on the final configuration . it is convenient for the authors of the paper to use the state transformation function , @ xmath141 we consider first the step where the left move is made , the state on the left of the shift operator is created , then the operator is created on the right , and a new state is created . then the left state is created . the sequence of steps is the following 1 . @ xmath125 2 . @ xmath142 3 . @ xmath127 , where we have @ xmath143 , and @ xmath144 . the probability of the change from the initial configuration to the final configuration times the probability @ xmath72 to choose the left move , times the probability @ xmath145 of its occurrence , times the probability @ xmath146 to keep moving and changing , times the probability @ xmath74 to choose the new state @ xmath75 , times the probability @ xmath121to shift the probability to be effective , consider the algorithm @ xmath76 to take the winning path : @ xmath77 : @ xmath147p _ \ leftarrow ^ { k } ( a ) p _ \ leftarrow ( \ tau _ r ^ \ prime ) \ \ & \ times & \ big [ 1 - p _ \ leftarrow ^ { kd } ( \ tau ^ \ prime ) \ big ] p _ \ leftarrow ^ { r ^ \ prime r ^ \ prime } ( \ tau ^ \ prime - \ tau _ r ^ \ prime ) \ end { aligned } \ ] ] the length of the winning path is not known : @ xmath148p _ \ rightarrow ^ { k } ( a ) p _ \ rightarrow ( \ psi _ l ) \ \ & \ times & \ big [ 1 - p _ \ rightarrow ^ { kd } ( \ tau ) \ big ] p _ \ rightarrow ^ { kc } ( \ psi _ l - \ tau ) \ end { aligned } \ ] ] the winning path takes the form @ xmath149 \ big ( p _ 1 - p _ \\ big ) } { - ( \ leftarrow ) \ big [ 1 - e _ \ leftarrow ^ \ dagger ( \ prime ) \ big ] \ big [ 1 - e ^ { - ( \ psi _ r - \ psi _ r ) ( v _ l - v _ r ) } \ big ] } \ \ \ nonumber & \ times & \ frac { \ big \ langle \ psi _ r ^ a \ big | \ big \ mathcal g \ hat \ mathcal t \ big | \ psi _ r ^ a \ big \ rangle p _ \ rightarrow ^ { kc } ( a ) } { \ big \ langle \ psi _ r ^ a \ big | \ big \ mathcal t \ big \ mathcal g \ big | \ psi _ r ^ a \ big \ rangle p _ \ leftarrow ^ { kc } ( a ) } \ \ & \ times & \ frac { - ( \ rightarrow ^ \ prime ) \ big [ 1 - e _ \ rightarrow ^ \ dagger ( \ tau ^ \ prime ) \ big ] \ big [ 1 - e ^ { - ( \ psi _ r ^ \ prime - \ tau _ r ^\ tau ) ( v _ r ^ \ prime - v _ l ^ \ prime ) } \ prime ] } { \ big [ 1 - v _ \ leftarrow ^ { kd } ( \ tau ^ \ prime ) \ prime ] \ big ( v _ r ^ \ prime - v _ l ^ \ prime \ prime ) } , \ big { 1 } \ ] ] and is defined as a quantity that depends on the initial configuration , times a quantity that depends on the intermediate configuration @ xmath7 , times a quantity that depends on the final configuration . it is convenient for the purposes of the above to define the configuration transfer function , @ xmath150 we define as the sequence where a green configuration is created , an operator is created on the right of the green operator , then the operator on its left is created , then the green operator is created on its right . finally , a left configuration of the green operator is created . the sequence of operations is the sequence 1 . @ xmath125 2 . @ xmath126 3 . @ xmath151 4 . @ xmath152 , with the intermediate configurations @ xmath7 and @ xmath153 , the intial and thethus , it is easy to show that the corresponding acceptance factor can be written @ xmath154 we consider only the situation where a new configuration is created , the operator on the left of the green operator is created , and green operator is created on the right . then the green operator on the right of green operator is created . the sequence of operations is the following 1 . @ xmath155 2 . @ xmath156 3 . @ xmath157 4 . @ xmath127 , given the intermediate configurations @ xmath7 and @ xmath153 in the intial and spatial positions , it is easy to show that the corresponding acceptance factor can be written @ xmath158 it is straighforward to show that the acceptance factors of the configurations @ xmath159 , @ xmath160 , @ xmath161 ( or @ xmath162 , @ xmath163 , @ xmath164 ) can be written as functions of the acceptance factor @ xmath92 ( or @ xmath93 ) and the intermediate configurations @ xmath165 and @ xmath166 . in the following example ,the acceptance factors of the moves @ xmath167 , @ xmath168 , @ xmath169 ( or @ xmath170 , @ xmath171 , @ xmath172 ) can be expressed as functions of the acceptance factors @ xmath173 ( or @ xmath174 ) and the acceptance factors @ xmath165 and @ xmath166 . thus , it is possible to take advantage of the information that we have for the values of the moves @ xmath72 , @ xmath175 , @ xmath118 , and @ xmath117 ( or @ xmath102 , @ xmath176 , @ xmath177 , and @ xmath178 ) . a simple calculation of these parameters can be done in order to allow us to evaluate the properties , accuracy and quality of the results of the sgf algorithm . for this purpose , we need to consider acceptance factors corresponding to left ( or right ) moves to be calculated . this allows the corresponding acceptance factors @ xmath165 and @ xmath166 ( or @ xmat##h179 and @ xmath180 ) to be set to 0 . this is true if @ xmath181 where @ xmath182 and @ xmath183 are the parameters corresponding to @ xmath184 . by calculating these parameters , the allowed values of the values of the green operator can be calculated . note that we have already calculated @ xmath185 from the allowed values for these optimization ##s . this is necessary for the green operator to have a chance to stop in a diagonal configuration , @ xmath45 . however , the measurement @ xmath186 would never correspond to that of @ xmath185 for the quantities @ xmath187 and @ xmath188 for diagonal configurations . thus the green operator would not stop at a diagonal configution , and no correction could be made . it is important also to note that the quantities @ xmath96 , @ xmath97 , and @ xmath98 are exchanged for the values on the left and the right of the green operator that are needed for the points where those quantities are exchanged , as well as for the values of @ xmath189 and @ x##math190 and the others @ xmath191 and @ xmath192 . the following ##s corresponding to a given direction of convergence are possible if we check for the following parameters : @ xmath193 ( v _ l - v _ r ) } { \ big [ 1 - p _ \ rightarrow ^ { kc } \ big ] \ big [ 1 - p ^ { - ( \ tau _ l - \ tau _ r ) ( v _ l - v _ r ) } \ big ] } } \ \ & & p _ \ rightarrow ^ \ - ( \ big ) = \ frac { \ big \ langle \ hat \ mathcal t \ hat \ mathcal t \ hat \ rangle } { \ big \ langle \ hat \ mathcal t \ hat \ mathcal t \ hat \ rangle + \ hat \ langle \ hat \ mathcal t \ hat \ rangle \ frac { \ big [ 1 - p _ \ leftarrow ^ { kd } \ big ] ( v _ l - v _ r ) } { \ big [ 1 - p _ \ leftarrow ^ { kc } \ big ] \ big [ 1 -e ^ { - ( \ tau _ l - \ tau _ r ) ( v _ r - v _ r ) } \ big ] } } , \ big { - } \ ] ] however , all these vectors are independant of the action of x if we replace @ xmath194 and @ xmath195 with @ xmath196 \ frac { \ big \ langle \ hat \ mathcal t \ hat \ mathcal t \ big \ rangle } { \ big \ langle \ hat \ mathcal g \ hat \ rangle } + \ frac { \ big [ 1 - p _ \ rightarrow ^ { kd } \ big ] ( v _ l - v _ r ) } { \ big [ 1 - e ^ { - ( \ tau _ l - \ tau _ r ) ( v _ l - v _ r ) } \ big ] } \ \ p _ \ rightarrow ( \ big ) = \ big [ 1 - p _ \ leftarrow ^ { k } \ big ] \ frac { \ big \ langle \ hat \ mathcal t \ hat \ mathcal t \ hat \ rangle } { \ big \ langle\ big \ mathcal { \ big \ rangle } + \ frac { \ big [ 1 - p _ \ leftarrow ^ { kd } \ big ] ( v _ r - v _ l ) } { \ big [ 1 - p ^ { - ( \ tau _ r - \ tau _ r ) ( v _ r - v _ l ) } \ big ] } . \ big { \ } \ ] ] as a result these operations can be performed efficiently , reaching the level of efficiency of the algorithm . we also have some limitations for the use of the optimization parameters @ xmath182 and @ xmath183 . this is discussed in this section . from the central limit theorem , we know that the errorbar corresponding to the measured quantity will appear as the square root of the number of moves , or equivalently , the square root of the time of the simulation . thus it makes sense to denote the parameters @ xmath197 of the qmc algorithm by @ xmath198 where @ xmath199 is the set of all the parameters of the algorithm , @ xmath200 is the measured quantity of interest , @ xmath201 is the time of the simulation , and @xmath202 is the errorbar corresponding to the initial value @ xmath200 . this also implies that @ xmath197 is independent of the accuracy of the measurement . as a result , the higher @ xmath197 the more efficient the algorithm . in the latter case we use @ xmath203 , and @ xmath204 for the entire sgf algorithm . it is important however to note that , by definition , the initial values of @ xmath118 and @ xmath177 ( and @ xmath117 and @ xmath178 ) must be equal . so we use @ xmath205 and @ xmath206 . it is possible to impose a condition of # ##ity , @ xmath207 . this condition can be satisfied by using only the values of @ xmath182 and @ xmath183 during the thermalization process . for this , we define a new optimization parameter @ xmath208 and apply the following algorithm from time to time while thermalizing ( we start with @ xmath209 ) : @ xmath210 . we are starting with the optimization parameter @ xmath21##1 . in order to find the optimal algorithm , we have considered two different hamiltonians @ xmath212 and @ xmath213 , and evaluated the efficiency of the algorithm by using @ xmath211 . the first hamiltonian we have considered describes the electron system and is simple : , @ xmath214 where the sum is over all of possible interaction parameters and @ xmath215 is the hopping parameter . the second hamiltonian is also non - simple and describes a system of atoms and other molecules , with a hopping parameter for interactions between the molecules . @ xcite , @ xmath216 where @ xmath217 and @ xmath218 ( @ xmath219 and @ xmath220 ) are the creation and destruction parameters of atoms ( respectively ) , @ xmath221 , @ xmath222 , @ xmath223 , @ xmath224 , and @ xmath225 are respectively the interaction parameter of atoms , the hopping parameter of molecules , the molecular onsite interaction parameter , the molecular onsite interaction parameter , and the inter - molecular interaction parameter . the third model is tunablevia the parameter @ xmath226 and does not affect the number @ xmath227 of atoms or the number @ xmath228 of molecules . so the total number of steps @ xmath229 is , and is the real number . the parameter @ xmath230 serves to calculate the sum of the number of atoms and molecules . the application of the sgf algorithm to the hamiltonian ( [ twospecies ] ) is described in detail at ref . @ xcite . the results obtained with the new evolution algorithm are completely independent of the original hamiltonian . the following table shows the total number of steps and transformations in each step , @ xmath231 , and the relative efficiency @ xmath232 of the algorithm applied to @ xmath212 at half filling , for which we have calculated the energy @ xmath233 , the superfluid density @ xmath234 , and the number of particles in the zero momentum state @ xmath235 : . the efficiency of the algorithm applied to @ xmath212 at half filling for the energy , the superfluid density , and the number of particles in the zero momentum state . [ ] =" ^ , ^ , ^ , ^ , ^ " , [ = " ^ " , ] since the correct choice of @ xmath211 depends on the hamiltonian which is used and the required energy , it follows that a good choice is to place @ xmath211 between @ xmath236 and @ xmath237 . the improvment of the algorithm is straightforward . in the following , we describe the application of the algorithm to systems with non - uniform density , by adding a new term to the hamiltonian ( [ twospecies ] ) : @ xmath238 the energies @ xmath239 and @ xmath240 are to be the sizes of the space allocated to atoms and molecules , respectively , and @ xmath31 is the number of lattice sites . the use of this term in the algorithm is difficult since only the values of the # ##s @ xmath241 and @ xmath242 are known . where ( [ energy ] ) and ( [ energy ] ) are the transfer function and the correlation functions . for a system with @ xmath243 lattice sites and , with @ xmath244 atoms and two molecules , andthe updates @ xmath245 , @ xmath246 , @ xmath247 , @ xmath248 , @ xmath249 , @ xmath250 , @ xmath251 , @ xmath252 , @ xmath253 , and @ xmath254 . the best results have been obtained by combining @ xmath255 updates for thermalization , and @ xmath256 updates with measurements ( this example is to be taken from the occurence of a random vector ) . the duration of the simulation is about 2 hours on a standard 32 bit computer with 1ghz memory , with an implementation of the algorithm for linear programming with measurements ( ( ref . @ xcite ) . ) to the hamiltonian ( [ twospecies ] ) . the errorbars are smaller than the symbol sizes , and are the biggest in the case of measurements ( 46 and 46 where they are the size of the [ . , scaledwidth = 0 . 5 % ] ) to the hamiltonian ( [ twospecies ] ) . the errorbars are larger than the symbol sizes , and are the largest for @ xmath257where they are the values of the distribution . , scaledwidth = 0 . 1 % ] we have developed a new graph algorithm for the sgf algorithm , which has the advantage of preserving the simplicity and stability of the original algorithm , and improving on the performance . we would like to extend the reference to van denteneer for more information . this project is part of the research program of the ` ` stichting voor fundamenteel onderzoek en materie ( fom ) , ' ' which is also supported by the ` ` nederlandse organisatie voor wetenschappelijk onderzoek ( nwo ) . ' ' we know exactly how to generate data with the uniform exponential distribution ( [ exponentialdistribution ] ) . given that we have at our disposal a uniform random variable distribution that combines the random variable @ xmath258 with the distribution @ xmath259 for @ xmath260 , we would like to define a distribution @ xmath52 such that the random variable @ xmath261 is combined with the distribution @ xmath262 where @ xmath46 and @ xmath263 are the values of the exponential distribution . becauseof the condition @ xmath261 , the probability to find @ xmath264 in the range @ xmath265 will be equal to the probability to find @ xmath258 in the range @ xmath266 . this implies the equality @ xmath267 with @ xmath268 . if we put @ xmath269 in the negative - sign with respect to @ xmath270 on both sides of the equation , we have @ xmath271 where @ xmath272 is a constant . this constant and the negative sign are obtained by applying the conditions @ xmath273 and @ xmath274 . as a result , if @ xmath270 is a realization of @ xmath258 , then a realization of @ xmath264 is given by @ xmath275 . \ ] ] . ronald fisher and e . ulam , journal of the american statistical association , series 247 , issue 1 ( 1949 ) . handscomb , proc . 1 , 594 ( 1962 ) . kalos , phys . 128 , 1791 ( 1962 ) . a . blankenbecler , j . a . scala##pino and m . j . brown , phys . b 51 , 2278 ( 1981 ) . m . m . batrouni and a . j . scalettar , phys . b * 55 * , 9051 ( 1992 ) . m . von der linden , phys . b . 220 , 221 ( 1992 ) . evertz , m . lana and m . marcu , phys . 220 , 875 - 879 ( 1993 ) . ceperley , j . b , 279 ( 1995 ) . , and j . - j . wiese , phys . b 5130 ( 1996 ) . ` ` ' monte carlo methods in science and engineering ' ' , ed . m . j . brown and m . s . umrigar , springer , series b 525 , kluwer academic publishers , dordrecht , ( 1999 ) . sandvik , j . phys . a * 59 * , 3667 ( 1992 ) ; phys . rev . a * 59 * , 14157 ( 1999 ) . n . a . prokofev , v . v . svistunov , and v . v . tupitsyn , jetp lett . * 25 * , 310 ( 1998 ) . n .rigol , t . muramatsu , g . g . batrouni , and r . t . scalettar , phys . lett . * 72 * , 130403 ( 2003 ) . m . van houcke , m . j . m . rombouts , and m . pollet , phys . e * 72 * , 056703 ( 2006 ) . rousseau , phys . e * 73 * , 056705 ( 2008 ) . sandvik , s . daul , s . s . r . singh , and j . rev . lett . * 72 * , 247201 ( 2002 ) . rousseau , r . t . scalettar , and g . g . batrouni , phys . e * 72 * , 054524 ( 2005 ) . n . wang , m . l . rosenbluth , n . t . chen , p . h . teller , and m . teller , j . chem . phys . * 72 * , 1087 ( 1953 ) . olav a . syljuasen , anders a . sandvik , phys . e * 72 * , 046701 ( 2002 ) . teller and p . a . h .denteneer , phys . * * * * , 013609 ( 2008 ) .