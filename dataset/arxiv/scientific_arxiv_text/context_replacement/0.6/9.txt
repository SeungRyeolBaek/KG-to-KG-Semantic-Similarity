the recognition process as a whole can be thought of as consisting of two steps : recognition and classification . recognition is to identify ` ` ` where ' ' the object is and to distinguish it from other object - like objects . although recognition is the first step for determining the spatial location of the target object / object in the image , an effective classification technique is the key for achieving recognition . in this regard , a new , efficient method was developed for object recognition to accelerate the recognition ( recognition ) process . this is the object model that can be compared , via the use of small scale ( x - scale ) @ xcite , between the trained image objects and their target objects . as an alternative to the traditional classification based on the size of the object by the parameter @ xcite in the image , atlas based methods can be used for this . for example , in @ xcite , the size of an object model ( such as liver ) is calculated from its shape . in @ xcite , the hough method is succesfully used to estimate properties of shape for different shape models . atlas based methods are also used to estimate the shape for a 3d problem . in @ xcite , affine analysis is used toorganize the data into an array to determine the optimal position for a 3d map of the # ##cap . additionally , a single particle detection algorithm is used to determine the optimal position of objects for both single and multi - particle data @ xcite . however , due to the large sample sizes and high error minimas in both of these algorithms , performing a live analysis of the raw data is not a practical solution . in this way , we use the approach of automatically identifying objects in the assembly without performing live searches or analyses . the training set consists of the following basic concepts and steps : * 1 . model selection : * by grouping the data from all @ xmath0 subjects in the training set into a single coordinate set via 8 - bit vector coordinates , the x - search algorithm @ xcite is used to distinguish @ xmath1 model objects from @ xmath0 subjects . these images are used for the automatic identification of objects in a slice - by - slice fashion @ xcite . from the resulting images for these objects , a new object @ xmath2 is generated . b - scale analysis : * the b - scale analysis of each voxel in the assembly helps to determine ` ` objectness ' ' of a given object without anyimage size . for each voxel , the size of the largest shape of that shape is multiplied by the surface index of that particular voxel in order to introduce appearance ( texture ) information into the image data ( see intensity weighted b - scale : @ xmath3 ) so that a table of the relationships between appearance and texture can be created . a simple and efficient method of thresholding the b - scale data is a few sample balls present in the image . these are used for the analysis of the relationships between the original training images and the new shapes . the corresponding images show a positive correlation with the newly created shapes . relationships between @ xmath2 and @ xmath3 : * the standard model @ xmath4 system is found via pca for the training images in the image , and their mean @ xmath5 system , denoted @ xmath6 , is found for the training images . @ xmath6 has one axis and maps @ xmath5 vertically . finally the mean @ xmath5 system , denoted @ xmath7 , for intensity weighted b - scale : @ xmath8 is found . then the system @ xmath9 that maps @ xmath7to @ xmath6 is computed . for an image @ xmath10 to be processed , the basic idea here is to use @ xmath9 to do a coarse identification of @ xmath2 and @ xmath10 with the correct pose as shown in figure 1 above . * coarse recognition : * for a processed image @ xmath10 , @ xmath3 is computed and the @ xmath5 pose , to @ xmath11 is computed and . assuming the relationship of @ xmath11 to @ xmath6 to be the same as of @ xmath7 to @ xmath6 , and assuming that @ xmath6 has the correct pose of @ xmath2 in the given image , we go to @ xmath9 and @ xmath11 to determine the relationship of @ xmath2 to @ xmath10 . this type of recognition is called coarse recognition . the development of the model can be done with the skin boundary shown in the image with the assumption that the target object of @ xmath2 should be in the same area defined by the skin boundary . alternatively , a direct examination of the skin boundary can be donefor the fine tuning , however , since the fine tuning automatically yields higher recognition accuracy , there is no need to perform the fine tuning . we will focus on the fine tuning of the algorithm for future research . the highest level of tuning is the shape recognition algorithm itself , which is a hybrid ##ization between our algorithm and the g - asm ( global combination of computer - based and biological shape models ) . this hybrid method was described in a technical paper presented to this conference @ xcite . a common way of the recognition of shape features found in biological systems is to create and use _ shape _ model _ to represent information such as the _ _ size _ , _ shape _ , _ appearance _ , and _ position _ of objects in the image @ xcite . among other things , _ size _ and _ shape _ are not separate but closely related properties of 3d objects in general , and together they are often used to construct shape models . in fact , shape has been used both for high and low resolution shape recognition quite successfully , and it has been shown that shape models ( such as active shape models ( asms ) ) can be very effective in searching for complex shapes due to noise , poor resolution , distortion , andanalysis of the data @ xcite . therefore , we use asm @ xcite to obtain the shape from a set of images ( the data ) . in order to verify the point correspondence established by asm , we build our own 3d model using semi - automatic methods : ( 1 ) randomly selecting the defined ##s by an expert , and ( 2 ) semi - automatic methods of identifying the elements of the model , from the corresponding shape profile . once this ( 2 ) is done , the 2d problem turns into the problem of 3d point correspondence between 2d objects , which is easily solved . it is very important to use these methods so that a 3d version of the 3d model exists . although the ##ing is often established manually by researchers , it is time - consuming , prone to error , and inaccessible to the 3d images @ xcite . because of these limitations , a semi - automatic point correspondence technique , _ equal space landmarking _ , was proposed to establish correspondence between points of the same shape in our model . although this technique is difficult for 2d objects , and since identifying a large number of points for 3d objects is much more difficult , we use equal space landmarking technique in 2d - a case where the object is identified only by slice. let @ xmath12 be a given shape and assume that the initial space is in the landmarking set of @ xmath13 . ##ing with shape @ xmath14 , where @ xmath15 is the coordinates of the @ xmath16 point in the shape @ xmath17 . the auto - selection for shape @ xmath18 for @ xmath19 on shape boundaries ( abd ) is by selecting an anatomical point for each other point in the set and to select a fixed number of points on shape boundaries . @ xcite . . the initial space has been selected automatically by selecting the corresponding anatomical point for each point in the reference set . . [ img : landmarking _ abd ] captures the images for the different objects ( kidney , liver , right kidney , left kidney , heart ) in a ct scan of the body cavity . note that different types of points are used for different objects and their positions . [ x = " ^ " , ] \ ( 0 ) the a - scale representation of a 3d object captures the morphometric data without any physical representation . b - scales capture the information of the object in terms of the spherical shape present in the voxelin the literature . the small - scale model has been widely used for object recognition , mapping and recognition . our results suggest that their ability to model object recognition in conjunction with object recognition may be useful for small and simple and efficient object recognition tasks . ( 2 ) the modeling approach is simple and does not depend on all the specific ##s of the image domain . ( 3 ) the accuracy of models increases rapidly as the number of objects in the image increases . ( 4 ) we note that the modeling and testing steps are carried out with the ct data sets that are representative of the combined mri / ct data sets collected at our facility . the ct data set is generally of very high ( spatial and temporal ) quality compared to the stand - alone data with and without ct . we expect better results if high resolution ct data is used for modeling and testing . this paper was presented at spie international conference 2009 - 2010 . falcao , r . m . , udupa , s . s . , samarasekera , s . , sharma , s . , hirsch , j . m . , and lotufo , j . m . , 1998 self - organizing image processing systems : the ct and the i . i . model of vision .60 ( 4 ) , pp . 233260 . kokkinos , g . , maragos , a . , 2009 . algorithms in pattern recognition and image processing : the performance - based approach . ieee transactions on image processing and image intelligience , vol . 60 ( 4 ) , pp . 14861501 . brejl , j . , sonka , m . , 2000 . edge detection and edge detection algorithm design for image - based image processing : machine learning from scratch . ieee transactions on medical imaging , vol . 30 ( 4 ) , pp . 973985 . fripp , m . , lee , j . , warfield , m . j . , ourselin , m . , 2005 . the design of image deformable models for image reconstruction . ieee journal of medical image processing : theory and applications , pp .