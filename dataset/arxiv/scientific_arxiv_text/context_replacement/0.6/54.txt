in both linear and transfer function applications one often has to evaluate recursively to values @ xmath0 of the quantity @ xmath1 , which contains @ xmath2 , but not zero , or values of the quantity @ xmath3 where @ xmath4 is a vector of unknown values , sometimes called the regressor , and @ xmath5 is a small error vector . the goal of optimization is to keep both the estimation error @ xmath6 and the measurement error @ xmath7 as small as possible . there are several different methods for dealing with the error vector , for example least - squares . perhaps the most popular is reducing the estimation error via gradient - descent methods of the form : @ xmath8 where @ xmath9 is a smooth , symmetric , positive - definite transfer function . let us consider @ xmath10 and the following functions and , which under the assumption that @ xmath11 is not zero are : @ xmath12 the following function @ xmath13 in time : @ xmath14 , @ xmath15 analysis of the data set shows that @ xmath16 is zero in time , and @xmath17 , and note that the error @ xmath18 ( both are derived from the domain @ xmath19 where the values are identical ) . these are the basic properties an algorithm needs in order to be considered a good candidate for the use of a function in an optimal tuning algorithm . accuracy @ xmath20 or something similar is considered a desirable property . to achieve the properties , classical algorithms can be used ; however , the relative merits of classical versus unnormalized algorithms are still somewhat unclear . another approach is to use the sub - domain @ xmath9 , which is used in least - squares regression . in [ sec : acceleration ] we use a function that measures the first derivative of @ xmath0 , and in [ sec : acceleration ] the effects of the random noise @ xmath5 on the performance of the two algorithms are discussed . next we give some examples and make some observations . these algorithms are assuming that the _ error _ of f ( the first derivative of the function ) is exactly equal to the regressor and to the _ error @ xmath21 . we want to set the _ error _ of the algorithm : @ xmath22 such that thethe result above is implementable ( using @ xmath23 instead ) if the constant is zero , because the function @ xmath24 exists only in the case with @ xmath25 . for an example of lyapunovian function : @ xmath26 which steps along the lines of : @ xmath27 and @ xmath28 we use @ xmath29 which leads us to the following result : @ xmath30 the # ##ness of @ xmath31 is without the need for integration , and so we use @ xmath32 instead of @ xmath33 as well . we also use @ xmath34 as a modified version , which can be used for the numerical analysis of a linear ##ly ` ` tunable ' ' control system via an error - correction algorithm ; see @ xcite . a variant of is @ xmath35 with @ xmath36 and @ xmath37 real , real , positive - definite @ xmath38 , so that @ xmath39 and @ xmath40 . the values of and , which can be obtained from the positive - definite function @ xmath41 are thethese , as above , are @ xmath42 we first consider the effects on the expected variance and mean of @ xmath43 of the presence of a measurement error . the effects are that @ xmath11 is a random variable with zero mean and that @ xmath44 and that @ xmath45 are random , independent variables . for these purposes , we consider what happens when the fm ##r is set to detect the presence of measurement error @ xmath5 : @ xmath46 the solution to the problem above can be expressed in terms of @ xmath47 the phase decay of @ xmath48 is : @ xmath49 â†’ @ xmath50 because @ xmath51 makes errors . here the expression @ xmath52 , for the decay with respect to the random variable @ xmath5 , is used to indicate that the statistical effects of @ xmath25 are also under consideration . the result is that @ xmath43 will decay to 0 over time as well as @ xmath53 will . the well - known effects of the effects of @ xmath54 are necessary for the decay to occur . tousing the first term of the parameter error , then @ xmath55 the result of @ xmath43 can be written as the sum of the terms . the result is : . the result is @ xmath56 because @ xmath11 has zero error , and the third term is not true . the fourth term @ xmath57 where fubini convergence , and the gain @ xmath58 are known . repeating the calculation and combining the second and third terms results in @ xmath59 this result can be given the following form : for example @ xmath60 , when @ xmath53 is close to the maximum , the result of @ xmath43 is close to @ xmath61 , the upper limit of the errors is the initial convergence of the result with itself . for @ xmath62 , which can occur if @ xmath54 is too small , @ xmath63 close to @ xmath64 . this leads to a compromise between initial convergence , and lower steady - state parameter error , which requires both larger and smaller values of the gain @ xmath9 . algorithms that allow for the best of both types of convergence arethe least - squares algorithms often have time - dependent , variable solutions ; an example is the least - squares algorithm . we shall then find a numerical solution for the acceleration algorithm from to , which results in the following equation @ xmath65 , @ xmath66 where @ xmath67 , @ xmath68 , and @ xmath69 are a function of @ xmath70 unless otherwise specified , and the inner product is with respect to the second term . if @ xmath71 , @ xmath72 repeat the same procedure as for the acceleration algorithm , one finds that @ xmath73 and that @ xmath74 . the results of the acceleration and velocity algorithms are not very well known because the right - hand side of does not lend itself to numerical convergence . to obtain these results , we use the simple and easily calculated expression , @ xmath75 ' ' ' ' ' , for the solutions @ xmath76 and @ xmath77 , and use the [ [ ] - [ ] ] - assumption : + + + + + + + + + + + + + + + ++ + + + + + + + for @ xmath78 , and finally , @ xmath79 , where @ xmath80 is the and @ xmath81 is the @ xmath82 density function . premultiplying [ @ xmath83 $ ] , postmultiplying [ @ xmath83 ^ \ [ $ ] , going from 0 to @ xmath60 , and applying the same rule to all . @ xmath84 ' ' ' ' ' for @ xmath85 for , @ xmath86 is positive - semidefinite , and @ xmath87 the use of and means that @ xmath88 can be increased without affecting @ xmath24 ##8 steady - state performance . on the other hand , to increase the performance we need to increase @ xmath89 , which strictly speaking means improving the properties . since @ xmath88 and @ xmath89 can be increased without affecting the performance as described in [ 1 : 1 ] , a small , @ xmath90 steady - state performance improvement may be madewith the better amplifier than with the acceleration amplifier , at least in the case when @ xmath91 , @ xmath92 , and @ xmath37 are ` ` equal . ' ' note that @ xmath93 is itself . [ [ 1 - 1 ] ] . definition : + + + + + + + + + + + + + + + + + + + + + + the definition of inequality does not require exact equality , and it gives an upper bound for @ xmath94 , but instead of @ xmath54 . a more accurate estimate of the inequality value can be obtained by replacing @ xmath95 by the original value @ xmath96 in the place of @ xmath86 ##a . this also is accurate because @ xmath86 counts as an interval , but not for more sophisticated numerical techniques . to obtain a better estimate , we use @ xmath97 ; or , finding the schur value @ xmath98 . , using the above method and replacing @ xmath95 by the value @ xmath96 @ xmath99 and finding that @ xmath100 . thefor the largest possible gain , we choose @ xmath101 , the smallest value of @ xmath76 that exceeds @ xmath97 . replace @ xmath102 with @ xmath103 \ begin { r } _ 1 \ left [ \ begin { smallmatrix } { \ phi } ^ \ top _ { 12 } ( t , 0 ) \ \ { \ phi } ^ \ top _ { 12 } ( t , 0 ) \ begin { smallmatrix } \ right ] } { 4m _ 3 ^ { 1 _ 2m _ 3r ( t + \ top _ 12 ) - 1 } . $ ] with @ xmath104 we get the above , positive gain . for large enough values of @ xmath77 the first term of the right - hand side of reduces to @ xmath105 , which means that the steady - state value of the gain x increases when the gain @ xmath25 increases in magnitude , and that it can be made larger via the addition of the factors @ xmath88 and @ xmath106 . the calculation for the linear gain is not much more complicated than for the accelerating gain . thesimulations in this article compare the properties of the accelerating amplifier with those of the gradient one and of the negative gradient one . the simulations were performed in open - circuit , with the regressor a two - dimensional signal , and without measurement noise . figure [ fig : si ] shows the behavior of @ xmath107 and @ xmath108 , when @ xmath25 is a two - dimensional input signal . in figure [ fig : si ] the regressor is a polynomial , in figure [ fig : sia ] an infinitely increasing function , and in figure [ fig : prb ] a pseudorandom function defined by matlab . no attempt was made to influence the choice of the values ( @ xmath91 , @ xmath92 , and @ xmath37 were all chosen according to the model ) , and the effect of measurement noise was not observed . the performance of the accelerating amplifier was similar , and therefore identical , to that of the above models . = 2 . 5 in = 2 . 5 in = 2 . 5 in = 2 . 5 in = 2 . 5 in = 2 . 5 in = 2 . 5 in = 2 . 5in other ways related to the above one suggests replacing the function f with a non - real valued function @ xcite , and then high - order tuning ( @ xcite ) . high - order tuning generates derivatives of @ xmath0 as well as further derivatives up to that given order ( in this case we can call the velocity algorithm a second - order tuning ) , and also the accelerating algorithm generates derivatives of @ xmath25 up to that given order . we expect that these algorithms will have applications in the study of nonlinear systems and especially in connection with the nonlinear problem known as the ` ` persistence of stabilizability problem ' ' in the adaptive control theory . the example ##ity of [ 1 : 1 ] shows that the stability and convergence properties of the accelerating algorithm , together with its low computational cost , do indeed make it a useful tool for adaptive control problems . this suggests that a more stable @ xmath90 steady - state response curve is obtained with the accelerating algorithm than with the velocity algorithm . to prove this claim , a study of the properties of the two algorithms and their relationship with the set of boundary conditions was first performed , as well as .continuous training in the presence of measurement equipment .