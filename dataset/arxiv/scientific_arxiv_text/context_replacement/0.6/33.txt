the origin - destination ( ed ) matrix is used in transport planning . the matrix provides information about the number of people that travel and the amount of traffic transported between different zones of a city . the ed matrix is complex and very expensive to calculate by using surveys / surveys and surveys , but by using existing traffic data and other incomplete data one can get a good estimate . the major application of the ed matrix , is in the field of public transport . in order to improve their performance , the transport organisations are responsible for on - line analysis of the traffic flow and the factors that would affect this flow . this is especially the case for the sydney train , sydney bus and sydney ferries systems , which provide the public transport in the area of the city of sydney , australia . cityrail and co are building a large number of facilities ( stations , bus stops ) for transport ( buses and ferries ) in the city . they transport thousands of passengers per day , and they adjust the traffic - based data to better reflect the traffic demand . + + + optimal design of the system would maximize the number of trains , buses , stations and ferries . if the same services ( passengers , drivers , stations ) are available to cityrail and co , the number of passengers -the trip at each destination can then be estimated , given their respective traffic count values and methods . + + various approaches to modeling the transport network using traffic counts have been developed and published @ xcite using traffic counts , and using traffic models @ xcite , @ xcite . most of the papers in the literature solve this problem by developing a general model for the traffic distribution , for example the transport matrix model @ xcite , which aims at assuming a general ##ization of the traffic distribution and assigning a person to each destination . then the matrix is used to determine the parameters of this model . * these persons _ are not known . _ . + most of the papers dedicated to the ##v model are based on passenger orientation and the choice of where the passengers get in and out of the public transport . lo et al @ xcite developed a framework based on the link choice , which they call the optimal link choice , and used this to give a maximum likelihood estimate . nandi et al @ xcite developed a framework based on the average cost per passenger per journey assumption for the public - transport network of india and made some improvements with the available data . + when the data is not available ( for example we have no data on when passengers get in the2 ) , kostakos @ xcite is to use a google survey of the bus network , and lundgren and peterson jr . @ xcite is based on the actual origin - destination distance data . however , none of the above authors used all the data . therefore , if no real information is available about the networks involved , the best solution is to use an online survey to estimate their locations . however , what properties of the network are required for the estimates to be accurate ? bierliaire and toint @ xcite developed a computer - based estimate of the origin - destination distance based on the surveys . in their paper , they used the online surveys to obtain an a priori estimate of the parking matrix , and they used this estimate in combination with the empirical properties of the network topology to obtain a linear inverse - matrix of the parking matrix . despite the differences , this does imply that the topology of end - user and public transport networks is the same , at least for their respective parking matrices . given that the public transport network topology is very different from the traffic network topology , one might question the validity of this assumption . instead , they simply use the network topology data from the surveys . + the goal of this approach is therefore to findthe estimation procedure for the origin - destination matrix depends on the historical data collected for the transport network and / or on the observations . in the example from bierliaire @ xcite , we use the data collected from the transport network , and determine the actual transport network , through the analysis of its eigenvectors . we construct a modified version of the matrix to avoid bias caused by the observations . we also construct a new estimation procedure that accounts for the presence of other variables such as the weather , and the time of the survey . + we first briefly describe the survey model , and then move on to describe the transport network . in section [ sec : om ] , we explain how the measurements are made , and what the errors should be corrected . in section [ sec : ms ] , we explain the assumptions we make about the model , and how this affects our estimation procedure . we present in section [ sec : ms ] the maximum likelihood ( ml ) estimation procedure , for constructing a system of equations to be solved , for the estimates . we build on this ml , to make it applicable to the problems in section [ sec : ms ] . finally , we present a summary , and an introduction to the real world .see section [ sec : app ] . we will report on the results and discuss the new research findings . let @ xmath0 be the number of passengers travelling between the stations of the transport network over time period @ xmath1 and that @ xmath2 be the number of passengers that depart from station @ xmath3 and arrive at station @ xmath4 over time period @ xmath1 . note that there is an important time period relation , given by @ xmath1 the period over which the event occurs ( for example a day ) . the purpose of this relation is to provide an estimation of @ xmath0 from the data provided in section [ sec : om ] . the observations made by the authors are very limited , and only averaging them together gives a good estimate of @ xmath0 . we discuss in the sections [ om - fast ] , [ om - deparr ] and [ om - casual ] the following types of observations . a typical event is defined as a departure / arrival event that is not used regularly ( e . g . holidays ) . therefore , people going to a once - in - a - lifetime event will buy their tickets for that event and will not go .the opposite happens . so for departure and return trip trains , we have # ##ness under the assumption that they take the next train after purchasing their ticket and that they take the recommended route . let @ xmath5 be that vector of arrivals . for journeys between major stations , the passenger has to buy his ticket at the machine at the entrance of the station , and verify it is at the exit . for major stations we assume they take the next train to arrive at the place they purchased their ticket , and that they take the non - recommended route for that journey . two cases are known . in the first case , ( called @ xmath6 ) , every station in the network has these machines . in the second , ( called @ xmath7 ) , the stations have these machines . in this case , we have @ xmath8 the vector corresponding to the arrivals at the station , and @ xmath9 the vector of arrivals . then we can have multiple columns with both origin and destination , and this matrix can be denoted @ xmath10 , where the rows are for the origin stations and the columns for the destination stations . this matrix is denoted , and then , according to the poisson probability distribution with , @ xmath11. + the main problem of the model , however , is statistical . * each of the travellers will only have a zone ticket for a period of time , from 1 day to 1 month . the validity of these assumptions makes the probability of departure and arrival important , and therefore the main problem of this model . * denote @ xmath12 the set of regular stations . . + to make a good statistical model , we make two assumptions ; * the traveller will commit independently of the total value of his ticket ; * the same traveller commits to the zone ticket on each successive trip . the assumptions relevant to this model are two - dimensional . for regular stations , we have the total number of passengers that use the same gates , in and out . for stations without boom gates , the passengers have to be in the tunnel . we therefore have according to the total number of passengers with a valid zone ticket at station @ xmath1 ( e . g . the beginning of the trip ) , denoted @ xmath13 , @ xmath14 at the end , the total number of valid passengers at the end of @ xmath1 will be , @ xmath15 , and we have , @ xmath16 with these two simple assumptions , we have a newa model based on these assumptions . let [ ma - ma ] , [ ma - ma ] , [ ma - rm ] and [ ma - rm ] make these assumptions for each component of our model . assuming that @ xmath17 is the matrix of means , the main constraint of that model is that the number of passengers is the sum of the casual passengers ( @ xmath18 ) and the unusual passenger ( @ xmath15 ) . the statement of the casual passenger is known as big sporting events , or big events ( @ @ xmath19 ) , @ xmath20 the unusual passenger ##s could be taken to be poisson counts i . e . @ xmath21 is supposed to be associated with a poisson matrix which @ ##izes to the form @ xmath22 . ] where @ xmath22 is the matrix of means for the count . + however , the variance of the counts is not supposed to be equal to their mean and therefore the poisson matrix model would be wrong . therefore , we need to use a simple probability distribution , for @ xmath23 , which can be re - estimated in order to better predict the variance of the count . we assume that @xmath22 is distributed according to a normal distribution , @ xmath24 . for the purpose of estimation , let @ xmath23 be distributed as a mean with mean @ xmath25 and @ xmath26 ( we can use @ xmath27 ) . according to the definition of the mean , the following conditions hold : @ xmath28 where @ xmath8 and @ xmath9 are the estimates of the mean number of departure and arrival at each station during the interval @ xmath1 . for the same purpose as that for the casual matrix , we will use a standard normal distribution to estimate the distribution of the observer ' s curve . however , unlike the casual matrix , we will not use an over - distribution or an under - distribution , so that , @ xmath29 and @ xmath30 . let @ xmath31 and @ xmath32 be the mean of @ xmath33 and @ xmath34 . when the distribution is well known , the estimation process is always straight forward , e . g . , for two stations where we estimate the mean of arrival and departure . note that the maximum is estimation .however , this depends on the exact solution of the optimization problem . in this case , the underlying model parameters are estimated from the data . since the data is assumed to be stationary , we consider the second step ( figure [ 2 : reg ] ) , a stationary spatio - temporal model that we use to assign the parameters to . the estimation process can be carried out in well - defined steps . if we estimate the time series , the following steps will be considered random , with sample sizes from the normal ##ized poisson distribution . this means that the maximum likelihood method should work well , even for small sample sizes . we use @ xmath18 for many samples . at the run - time , we find that @ xmath5 is equally likely as @ xmath35 . the likelihood is therefore , @ xmath36 \ { { n } \ ] ] where @ xmath37 stands for an element of the set @ xmath5 . we then can estimate the likelihood as , @ xmath38 despite the lack of closed form solutions to this problem , the optimization problem can still lead to a general solution . if we need # ##h - 1 for those with weekly , daily , monthly and anuual data (long - term tickets ) . we have information of the time they arrives and leaves the major stations . we ' ll have no information for the long term tickets going to or from major stations . our estimate therefore is that only a few @ xmath39 of the @ xmath32 people will arrive on day @ xmath1 , where @ xmath40 . @ xmath39 is an important factor that determines the travellers number . it may be because when performing the calculation , we can expect a better number of people than what we expected . part of the error is due to the use of @ xmath41 , but it may also be caused by the fact that people with the long term tickets do everything else on day of the same time of the year . + however , we cannot get the same values for the @ xmath31 people as we did in the previous paper , that is , @ xmath42 where @ xmath43 is for the same transfer time as before . + this leads us to the following steps , the contribution this paper made to the calculation . the first is to calculate the people @ xmath12 with the same departure and arrival times . the next step is to estimate the weighted averageof the @ xmath10 equation . the goal is to solve this in a straightforward way so that @ xmath12 has to be solved with @ xmath44 equations , and with @ xmath45 equations . the following formula gives an easy solution to this problem . + define @ xmath32 as the expectation of @ xmath46 . if is not known , we can approximate it , such that , @ xmath47 where @ xmath48 is the identity matrix of eigenvectors of @ xmath32 and @ xmath49 is an @ xmath44 - parameter , with entries corresponding to the corresponding variables . however , if the expectation of @ xmath32 is symmetric ( i . e . the eigenvectors are symmetric ) and therefore , then we have reduced the problem to solving a system of @ xmath45 - parameters with @ xmath45 equations . [ ref : odeq ] and the above formula , we have the following system , @ xmath50 where @ xmath51 and @ xmath52 are related by linear equations . the probability density function of the system @ xmath53 can then betherefore , @ xmath54 \ quad p \ big ( y _ { di } ^ t \ vert r _ z , y _ { rz } \ quad ) & \ sim & \ mathcal { i } ( \ { _ i } ^ { ij } _ t , y _ { rz } ) \ big { i } \ ] ] where @ xmath55 and @ xmath56 . according to this example , we would use @ xmath57 likelihood for ( @ xmath58 $ ] ) and @ xmath59 likelihood to solve ( @ xmath32 is positive ) . to perform the estimation , we would need to know the number of parameters . according to ref . [ 1 : diag ] , we have , @ xmath60 likelihood , if we use @ xmath48 , the maximum likelihood would be , and perform the estimation of @ xmath32 ( with @ xmath61 as the @ xmath3th parameter ) . the @ xmath57 likelihood would be like , @ xmath62 \ quad p \ big ( y _ { di } ^ t \ vert r _ z ,p _ { rz } \ big ) & = & \ end _ [ ( \ , ( p _ { di } ^ { \ vert p _ di , p _ { rz } \ big ) \ end { t } \ ] ] where @ xmath63 . the maximum likelihood estimation methods are : , @ xmath64 therefore , this estimation problem can be solved by assuming that the estimates are made based on all the parameters ( e . g . the parameters are known ) , and . , @ xmath65 the size of the state space is reduced due to the use of @ xmath48 . to calculate @ xmath48 , assuming that @ xmath31 is constant , we have , @ xmath66 . , we make the assumption that all the random variables behave differently with time , that is , @ xmath48 is not a function of time . so we have , @ xmath67 . @ xmath48 can be derived from @ xmath68 , and entered into the [ e : ml ] to calculate the . [ e : mle ] . then , we can use @ xmath69 and @ xmat##h70 to be @ xmath71 . then the solution of the [ e : mle ] is a convex optimization problem . the maximum likelihood function guarantees the existence of a solution , and it can be solved using the minimum likelihood function . let this matrix be @ xmath72 . the problem with this matrix is that we can not guarantee that it will satisfy the first constraint of the estimated parameters . therefore , the elements of the matrix will be unknown , and there will be some elements of the matrix that wo ##ve ##h ##70 . therefore , additional constraints need to be added to the # ##e problem . these are : + * constraint 1 * _ all the elements of the matrix @ xmath73 are less than or equal to zero , or equivalently , @ xmath74 _ + * constraint 2 * _ all the other elements of the matrix @ xmath71 to be negative , or equivalently , @ xmath75 _ + * constraint 3 * _ the first constraint of the to be estimated is the probability distribution @ xmath76 . therefore , all the variables should belong to the [ @ xmath77 $ ] , @ xmath78 \ n{ x } \ ] ] _ all of the optimization programs that deal with the constraints have an observation which belongs to the constraint set . we could be able to use as a starting point the mean value of the observation , corresponding to the n - dimensional ( @ xmath79 ) constraint . however , it is highly unlikely that this starting point would satisfy the constraint . therefore , the best solution so far seems to be the real part of the constraint @ xmath80 , so that they both satisfy * constraint 1 * and * constraint 2 * . + + the resulting optimization program then returns , @ xmath81 with the mean value @ xmath82 . this optimization problem can be solved by an alternative version of the algorithm , according to the constraints contained in [ ann : 1 ] . the first constraint is the poisson bracket operator , such that we have , + * constraint 1 : * _ suppose that @ xmath83 , [ @ xmath84 ^ { - 1 } \ bar { x } \ bar { x } \ ] ] where @ xmath85 is the sum of the entries of @ xmath32 . _ + if then we have the maximum ofinstead of poisson , the following maximum likelihood estimate is used , + * proposition 1 : * _ suppose that @ xmath86 , = @ xmath87 where @ xmath88 is the set of the parameters of @ xmath32 . _ + the proof of proposition 1 and 2 is presented in [ ann : a ] . we can also use the follwing function , that tells us of the results of the test , + * proof : * + suppose that @ xmath89 { \ math . p . \ } \ $ ] ( = [ @ xcite , @ xcite ) . thus we get , @ xmath90 { \ \ mathcal { p } \ } \ , \ math { p } \ ] ] the proof is presented in [ ann : a ] . if we want to work with a more robust model , it is necessary that we need to consider spatial , temporal and temporal effects on the number of passengers , and therefore on the performance of our model . + let @ xmath91 be the number of observed events , and @ xmath92 their relative ( temporal ) effects on the number of passengers . ., the resulting model would be : , + @ xmath54 \ big & \ sim ( p _ { di } ^ 2 \ vert x _ z , p _ { rz } , ( x _ z ) _ i \ big ) & \ sim & \ mathcal { k } \ big ( \ sum _ { ik } \ lambda _ i p _ { ik } \ lambda _ i p _ { jk } + \ sum _ i p _ k \ lambda _ i , p _ { rz } \ big ) \ begin { k } \ ] ] where the parameters to be estimated are @ xmath93 . the model is given as in fig . [ 2 : like ] , and we have , @ xmath94 . , if we take the likelihood function to be constant over time , then we have the following proposition ( as in [ ann : like ] ) , + * _ 1 : * _ if we use the same algorithm as above we have the following proposition , @ xmath95 ^ { - 1 } ^ { } ^ { { ( \ { } ^ { } ) ^ { - 1 } \ begin { aligned } \ ] ] where @ xmath##96 is the sum of the random variables . _ + a more efficient solution would be to use the same method as above , except that @ xmath48 will no longer be present . therefore , the sample @ xmath97 recovered from @ xmath31 will result in the loss of the sample @ xmath32 . the reason why we do not do a direct analysis of the @ xmath98 data using this method is because @ xmath32 can be determined , but we cannot determine ##h how the @ xmath98 matches the @ xmath99 . therefore , real - time analysis for the time series data is needed . a more direct analysis has to be performed in order to find out if the results are not affected by the statistical sensitivity . the quality of the results will also depend on the particular sub - sample @ xmath31 . in the [ sec : abs ] , we assume that the quality of the data @ xmath31 and @ xmath32 depends on the quality of @ xmath48 and @ xmath100 . therefore , we assume @ xmath101 ( ex . [ sec : ass1 ] ) , andthis assumption is the basis to calculate the estimate @ xmath102 . + it is very difficult to design and build a survey that provides useful information . therefore , . . [ x : ass1 ] is no longer useful . to do this , we need to create an ad hoc estimate of the 2 - dimensional space . + despite the survey having many possible errors , it provides the information that we need . let @ xmath88 be the estimate based on the assumption of @ xmath32 , not on the assumption @ xmath101 . although incorrect , this estimate looks like the best possible estimate . we calculate , @ xmath103 . , considering that the estimate may be inaccurate , we need to reduce the accuracy of the assumption @ xmath104 , by creating an identity - preserving matrix @ xmath105 , such that , @ xmath106 where @ xmath107 and @ xmath108 . @ xmath109 is accurate , and will lead to an equal distribution of the results in the same seats . , @ xmath110 . therefore , we need to use the information provided by @ xmath109 .when we construct the two ad hoc estimates @ xmath111 , @ xmath112 we define the performance of our sample by the ability to estimate the sampling bias . to estimate the performance of the sample , we assume that the sample s of the survey is distributed according to the following three equations , @ xmath113 where @ xmath114 $ ] stands for the size of the sample , @ xmath115 $ ] stands for the maximum confidence interval , and @ xmath116 for the poisson distribution , and , @ xmath117 the difference between the three equations depends on the statistical model . in q . [ e : noise ] , imaginary values are often used instead of the real values of the parameter . this is the type of bias we expect to find in well performed surveys with people chosen randomly . in ##q . [ e : q . noise ] , we assume that the bias has the same form as the @ xmath32 error . this is an accurate estimate of the sampling error as found in the literature with a normal distribution . however , we expect the bias to produce better results when the sample response parameters are distributed byfig . [ prop : prop . noise ] . + = [ source : sensnoise ] . the ml and ad hoc estimation account for the two kinds of bias , with different types of bias and different types of bias . as such , the second kind of bias ( fig . [ prop : prop . noise ] ) is more easily detected by the system . the best inference we can draw from this observation is that the ad hoc estimation is better than the original ml estimation , no matter what kind of bias we detect . the ad - hoc estimation is plotted in green . the upper line stands for a bias designed according to fig . [ prop : noise ] , and the bottom line for fig . [ prop : prop . noise ] . the mse is calculated among @ xmath118 simulations . , title = " fig : " , width = 264 , height = 226 ] ] . the ad - hoc estimation is plotted in green . the upper line stands for a bias designed according to fig . [ prop : noise ] , and the bottom line for fig . [ prop : prop . noise ] . the mse is calculated among @ xmath118 simulations . , title = " fig: " , width = 264 , height = 226 ] + 1 . the ad - hoc estimation is plotted in green . the upper line stands for a bias designed according to fig . [ see : noise ] , and the bottom line for fig . [ see : prop . noise ] . the mse is calculated among @ xmath118 simulations . , title = " fig : " , width = 264 , height = 226 ] . . the ad - hoc estimation is plotted in green . the upper line stands for a bias designed according to fig . [ see : noise ] , and the bottom line for fig . [ see : prop . noise ] . the mse is calculated among @ xmath118 simulations . , title = " fig : " , width = 264 , height = 226 ] lastly , and perhaps most importantly , the ad hoc estimation is very accurate and the parameters are not affected by the number of observed observations . for example , we can see that the ms ( mse ) estimation is similar to fig . [ see : sensnoise ] for @ xmath119 simulations and for @ xmath120 . the purpose of that is to check for a time - delay .( on a continuous basis , this would be @ xmath121 . ) , which would be more accurate with the continuous version . let m be an @ xmath122 matrix , with arrivals and arrival times ( origin and origin ) . we assume that each value of m is a random variable , chosen according to the number of observations @ xmath123 , and the sample @ xmath124 . the matrix @ xmath123 has the following entries , @ xmath125 \ ] ] let @ xmath126 be an independent sub - matrix of m , i . e . , a sample @ xmath127 of m is represented by @ xmath126 . we assume that for each value of m , @ xmath127 will be the same , but modified by a higher - order correction factor . the realization of @ xmath126 is the following matrix , @ xmath128 \ ] ] the value of @ xmath127 in this case is approximately equal to @ xmath129 . the realization of @ xmath130 is done with the inverse of this matrix . therefore , @ xmath130 is the, we calculate this , and using the same algorithm as in the [ x : oi ] we are able to obtain the following : @ xmath131 observations ( for @ xmath132 , @ xmath133 , @ xmath134 and @ xmath135 observations only ) , @ xmath136 & \ right [ \ begin { array } { ccccc } 0 & 72 & 0 & 0 & 48 \ \ 24 & 0 & 0 & 0 & 124 \ \ 68 & 0 & 0 & 126 & 0 \ \ 68 & 0 & 126 & 0 & 54 \ \ 24 & 124 & 0 & 0 & 0 \ end { array } \ right ] \ \ & \ \ \ left [ \ begin { array } { ccccc } 0 & 72 & 0 & 24 & 48 \ \ 24 & 0 & 0 & 0 & 48 \ \ 24 & 0 & 0 & 102 & 0 \ \ 24 & 0 & 102 & 0 & 0 \ \ 60 & 0 & 0 & 0 & 0 \ end { array } \ right ] & \ right [ \ begin { array } { ccccc } 0 & 0 & 0 & 0 & 0 \ \ 60 & 0& 54 & 42 & 48 \ \ 12 & 0 & 0 & 0 & 96 \ \ 0 & 42 & 48 & 0 & 0 \ \ 12 & 0 & 0 & 0 & 0 \ end { array } \ [ ] \ end { array } \ ] ] . [ tble : mse _ bin ] : the mean square error of the model for the number of observations and the degree of uncertainty in the case of a negative mean model . we also provide the table [ tble : p _ bin ] the p - values for the cramer - von mises statistical model of @ xmath137 replication , for the model . . [ tble : mse _ bin ] negative mean models : estimates of the mean square error of the model , with different number of observations and different model parameters in @ xmath137 replication of the model , and the estimated variance ( or uncertainty ) . [ parameters = " ^ , ^ , ^ , ^ , ^ " , variance = " ^ " , ] we provide as an example the population data from the european union where , according to the tables provided by @ xmath138 , @ xmath139 ,and @ xmath140 from the bureau of transport statistics of new south wales . the original figure could have been larger , but in order to be accurate , we must focus our attention on the eastern sydney area , starting with @ xmath141 different days and @ xmath142 different nights . [ code : lpw20xx ] note the distance between the destinations , so that you can find a preferred route by following only one route . + as we can see from the figures , all the destinations appear to be able to be reached directly from any one route , except for sydney harbour , botany bay and norfolk island . + + from this , the result is the estimation of the transport matrix , which is almost exactly the transport statistics as shown in the figure except that instead of passenger numbers , it will be represented by numbers of passengers . however , this data does not provide enough information to perform this analysis . in fact , it is # ##e an estimate of the passenger counters on the wharf . therefore , to perform this analysis , we use a previous study from the transport bureau , which aimed at determining the preferred mode of transport for people travelling to sydney . from this data , we have identified those who were on the+ . + before we could do an analysis of these data , we had to assume that the origin and destination of the people in the second survey corresponded # ##h to the results of the first survey . therefore , we had to assign to each person the starting point of their journey , the closest wharf to their home , and their destination , the closest wharf to their home . the distance has been calculated according to the origin and destination , and latitude ##s . this being done , we can create a new origin - destination matrix . this is presented in fig . [ fig : jw2006 ] . + this distance matrix is not going to be the same size as the original estimate of the barrier count . instead , we can use the data presented in the [ fig : cpe ] to calculate the 2010 , 2011 and 2012 distance matrix according to the barrier count . the weights and eigenvectors are then calculated , and the statistics of the transport system are presented in fig . [ fig : est1 ] and [ fig : est2 ] . we present in this paper a new calculation method for the distance matrix . we use the data obtained from 2011 to improve the distance matrix , and increase in the accuracy of the estimate2 . + using the maximum likelihood method , we compute the likelihood function and calculate an ad hoc estimate of the transport matrix . we tested its validity using the [ t : r ] . + we also showed that a statistical analysis could be performed on this kind of data , and showed that this statistical method is not reliable . to the best of our knowledge , this is the first time that any such statistical method was used to estimate the transport matrix . this method will improve the statistical accuracy of passenger flow . + we also compared our results to previous , and real - time analysis of the passenger flow using the data from the bureau of labor statistics . + the estimation of the transport matrix is the first step for the estimation of the passengers flow from the transport matrix . however , for this first step , we can use : 1 . [ monit ] monitoring the passengers flow ; 2 . [ forecast ] estimation of the passengers flow ( a year in advance for example ) ; 3 . [ forecast ] monitoring the passengers flow in terms of spatio - temporal traffic distribution of the passengers in order to solve the transport problem ( [ monit ] ) , several important assumptions have to be made , which must be a ##ing before being implemented . amongthem , we can know the time between the purchase and entry into the train and the time at which passengers leave their cars if they are not seated . therefore , a real - time analysis to the data is possible . although difficult , this seems possible . + the prediction of traffic flows ( [ predict ] ) can be done without further observation ( if enough statistical information has been collected in a single instance ) , even if additional observations would also require more data . these observations could be used for the model the train ( for example ) , but further observations have to be done in order to understand the effects of other variables such as the temperature and the humidity . + real - time prediction of traffic flows ( [ predict ] ) is more difficult , but seems still possible . what we consider as spatio - temporal traffic flow is a change in the timetable , or in the actual train schedule . _ to make this decision , we can use the probability density function , where the poisson distribution can be used instead of the usual distribution . thus , the pdf can be written as , @ xmath143 where @ xmath144 is the parameter we are interested in . however , if we make the decision that the .of passengers in the seat p there , then @ xmath145 is distributed according to the poisson distribution , with the parameter @ xmath146 , which can be re - distributed according to : . [ int : diag2 ] , @ xmath147 where the @ xmath148 are the parameters , and the @ xmath149 the rank of the passenger p . if we take @ xmath150 , the transformed density can then be calculated , @ xmath151 + thus , the log - likelihood can be calculated as : , @ xmath152 the log likelihood method is also equivalent to using the following parameters , @ xmath153 also has the parameters * c1 * and * c2 * . * c3 * is used because this set of parameters does not exist in the poisson distribution . if @ xmath154 , @ xmath155 and * c2 * does not exist . the transformed density corresponds to the following distribution : poisson - density , @ xmath156 . + the construction of the [ int : sys _ n ] was at first a very simple one . however ,we can then write so as to write , @ xmath157 where @ xmath158 are the # ##s . finally , if we have @ xmath159 , then , @ xmath160 where @ xmath161 and @ xmath162 . then , we can lead to the formula , @ xmath163 . , the same formula leads to the following formula , @ xmath164 where @ xmath165 . this formula will probably not be the best , given that it depends on the pdf of @ xmath166 , but has the property to be more efficient , with n equal to 1 . _ _ let @ xmath167 be the probability density function . if @ xmath168 is the pdf of @ xmath169 , and @ xmath170 the pdf of @ xmath100 , we can write , @ xmath171 will be the model used by r . [ 1 : linsol _ lamfg ] , and make the assumption that we are considering a single sample , , where @ xmath##172 . + , @ xmath173 where , @ xmath174 \ { { $ } _ { ^ { - 1 } \ begin { \ } \ } . \ ] ] and @ xmath100 is the value of @ xmath48 according to the observed distribution . + + _ to prove the theorem in general , we need to know that , @ xmath175 where @ xmath176 . + with the right hand side , we have , @ xmath177 and we know that @ xmath178 { \ math . m . \ } = \ _ { \ { $ ] . + , @ xmath179 and we have , @ xmath180 where @ xmath181 stands for the probability density function of @ xmath182 . + the first integral decreases towards @ xmath183 as @ xmath57 goes to infinity according to definition . [ 1 : 1 ] . the expression for the second integral is the same . according to the principle of the convergence of @ xmath100 , @ xmath181 decreases towards the upper limit @ xmath184 and @ xmath##185 goes to zero . @ xmath186 is strictly convex , this completes the proof . @ xmath187 . [ [ calculation - in - case - of - poisson - regression - and - log - link - function ] ] * calculation in case of poisson regression ( and log link function ) * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + _ the rest of the proof is similar to the previous one . first , if we assume that the flows have dependence on the number of passengers , we can get , @ xmath188 where @ xmath98 is the variables representing the variance ( @ xmath189 ) for baseline commuter flows and the daily variance ( @ xmath190 ) for differences in commuter flows from baseline commuter flows . second , we assume that the same matrix ( but with the same eigenvectors ) can be used , which leads us to , @ xmath191therefore , @ xmath192 can be estimated according to a poisson distribution with the first observation , @ xmath193 where the parameters to be estimated are @ xmath194 , which means we need to calculate @ xmath195 . . + the likelihood of the observation can also be calculated , @ xmath196 which gives the corresponding log - likelihood , @ xmath197 . , to solve the following set of equations , we need to calculate the variance of the log - likelihood with respect to the observation @ xmath198 . _