they are a useful tool in image science and image processing @ xcite . they serve to provide properties that remain invariant under certain geometric and radiometric transformations of the image , thus extending the image space . they can be divided into global invariant , typically based either on a set of data points or data points , and local invariant , typically based on values of the image , which are assumed to be linear and symmetric . the geometric transformations of images can include translation , rotation , and scaling , commonly referred to as _ similarity _ transformations . in a recent article @ xcite , based on work done by schmid and mohr @ xcite , we have defined differential corrections for those geometric transformations , called _ _ _ brightness corrections . here , we are looking at a _ non - linear _ brightness correction _ and _ gamma correction _ . this correction is a non - linear correction of the brightness changes observed by the cameras during the image processing process . the goal is to achieve _ _ linear _ resolution by maintaining an approximately constant distribution of the brightness ##es , keeping the brightness levels unaffected by the _ _ brightness difference _ . however , this non - linear correction also precompensates for the non -intensity varies from brightness to brightness on the display : @ xcite . this equation can be expressed as the equation @ xmath0 where @ xmath1 is the input intensity , @ xmath2 is the output intensity , and @ xmath3 is the correction factor which is given by the value of @ xmath4 . for output devices , the ntsc standard is @ xmath5 . for input devices and cameras , the parameter value is directly inversed , resulting in a parameter value of @ xmath6 . the camera we ##lder , the sony digital ccd - c dxc 950 , is @ xmath7 . for the kodak megaplus xrc 2000 ] [ source : gammacorr ] is the linear combination of 8 - bit values for parameter values of @ xmath4 . it turns out that rotational invariant and intensity derivatives can be derived from first and second order derivatives . the derivatives under consideration are third order derivatives . they are in general translationally invariant . rotational invariant in 3 - dimensions is obtained by using rotational invariant ##s . the basic idea for the calculation of the rotational derivative is to find the values of the components of the transfer function such that the derivativenote the ability of and to cancel and . this transformation has been used by @ xcite to study images with linear phase transformations , and it can be extended to the level of gamma correction by at least just changing the _ _ _ of the image function . for example , we work with two - dimensional image functions . let @ xmath8 be the image function , i . e . the image function , assumed to be linear and continuous , and @ xmath9 the corresponding gamma correction function . note that @ xmath8 is a special case of @ xmath10 where @ xmath11 . taking the values of @ xmath12 with the invariant @ xmath13 , and @ xmath14 . we can also define the function @ xmath15 with gamma correction to be @ xmath16 { 0mm } { # ##mm } & = $ \ frac { \ gamma \ , \ frac { f ' ( x ) } { f ( x ) } } { \ gamma \ , \ frac { f ( x ) \ , f ' ' ( x ) - f ' ( x ) ^ 2 } { f ( x ) ^ 2 } }$ \ \ & = $ \ frac { f ( x ) \ , f ' ( x ) } { f ( x ) \ , f ' ' ( x ) - f ' ( x ) ^ 2 } $ \ , { [ } \ ] ] the invariant @ xmath3 has been obtained by taking values , and @ xmath4 has fallen away . however , @ xmath15 turns out to be an invariant in terms of the _ _ _ _ function and its derivative , i . e . the derivative that allows # ##h to be used . the factor @ xmath17 means that the invariant depends on the image function . @ xmath8 and in @ xmath18 the invariant holds under time correction , and under space correction of the image function . the disadvantage of @ xmath15 is that it is written where the derivative is zero . therefore , we expect @ xmath15 to be written as : @ xmath19 { 0mm } { 0 ##mm } { \ normalsize $ \ \ _ { m12 \ n } = $ } & $ \ frac { f \ , f ' } { f \ , f ' ' -{ f ' } ^ 2 } $ & { \ normalsize if $ | f \ , f ' | < | f \ , f ' ' - { f ' } ^ 2 | $ } \ \ & $ \ frac { f \ , f ' ' - { f ' } ^ 2 } { f \ , f ' } $ & { \ normalsize else } \ \ \ [ { f } \ ] ] where , for notational convenience , we have used the notation @ xmath18 . the modification continues . note that the modification is not a way to deal with scaling . if the derivatives are zero because the derivative itself is zero , then derivatives are probably not the best way to model the function . if there is a problem that has to be solved , then a variable @ xmath20 with the concept of derivative has to be added . that is , it is written simply as a function @ xcite : the current version of @ xmath8 is @ xmath21 . suppose we are looking at the function @ xmath22 where the derivatives with respect to @ xmath18 are @ xmath23 , @ xmath24 , and @ xmath25 .then the invariant @ xmath26 is obtained by choosing a fixed value of the coefficients such that : @ xmath4 and @ xmath20 work like : @ xmath27 { 0mm } { 8 mm } & = $ \ frac { g ^ 2 g ' \ , g ' ' ' - 3 \ , g \ , { g ' } ^ 2 g ' ' + 2 \ , { g ' } ^ 4 } { g ^ 2 { g ' ' } ^ 2 - 3 \ , g \ , { g ' } ^ 2 g ' ' + \ { g ' } ^ 4 } $ \ , { g } \ ] ] add to this . ( [ ref : thm12 ##0 ] ) , we can obtain the following invariant @ xmath28 { 0mm } { 8 mm } { \ normalsize $ \ int _ { m123 \ } } = $ } & $ \ frac { g ^ 2 g ' \ , g ' ' ' - 3 \ , g \ , { g ' } ^ 2 g ' ' + 2 \ , { g ' } ^ 4 } { g ^ 2 { g ' ' } ^ 2 - 3 \ , g \ ,{ g ' } ^ 2 g ' ' + \ { g ' } ^ 4 } $ & { \ normalsize if cond2 } \ \ & $ \ frac { g ^ 2 { g ' ' } ^ 2 - 3 \ , g \ , { g ' } ^ 2 g ' ' + \ { g ' } ^ 4 } { g ^ 2 g ' \ , g ' ' ' - 3 \ , g \ , { g ' } ^ 2 g ' ' + \ \ , { g ' } ^ 4 } $ & { \ normalsize else } \ \ \ , { f } \ ] ] where condition cond1 is @ xmath29 @ xmath30 , and condition cond2 is @ xmath31 @ xmath32 @ xmath33 . therefore , this also holds . it is a simple albeit useful way to compare the results from above . ( [ q : th12 ##2 ] ) and ( [ q : th123 # ] ) with an analytic , continuous function . for an analytic function , we have @ xmath34 the first three conditions are @ xmath35 , @ xmath36 ,and @ xmath37 . then , according to fig . ( [ q : th12 g ] ) , @ xmath38 . if we can replace @ xmath8 with a gamma corrected version , like @ xmath39 , the first derivative is @ xmath40 , the second derivative is @ xmath41 , and the third is @ xmath42 . if we insert these expressions into fig . ( [ q : th12 g ] ) , we get the expression for @ xmath43 which is equivalent to the expression for @ xmath17 ##a . the more advanced approach is likely to use the expression @ xmath44 for the original function . [ example : analyex ] shows the original function and its gamma corrected version , together with their derivatives and the corresponding auxiliary functions . as usual , the values of the functions are the same on the right and on the left . note that the graphs are a one - to - many mapping . that is , the mapping is not known ##al , and it is not possible to extract the original function from its derivatives ##s . if @ xmath45 and @ xmath46 are to be seen in detail ,transformations from . ( [ e : th12 ##3 ] ) to ( [ e : thm123 g ] ) have to be extended to higher dimensions . this has to be done in a linear invariant way in order to ensure stability of the relations . the other approach is to use rotational invariant ##s . for the first order , we use the well known _ linear variation _ , _ _ @ xmath47 where @ xmath48 is the 2 - dimensional differential operator , and @ xmath49 , @ xmath50 are the derivatives of the x - axis and the y - axis . for the second order derivative , we can use the known _ laplacian _ @ xmath51 . @ xcite ##r is the _ second order derivative _ , the _ linear derivative _ @ xmath52 since the qv is not a linear function and therefore difficult to implement , we use the laplacian for our derivative . for the third order derivative , we can use , in - conjunction with the linear derivative , the _ linear derivative _ _ @ xmath53 the transformation from . . ( [ e : th12 ##3 ] ) to ( [ e : th##m123 ##3 ] ) is obtained in base - d if we replace @ xmath54 with @ xmath55 , @ xmath56 with @ xmath57 , and @ xmath58 with @ xmath59 . this can be done by going through the same steps as for the above . note that the first example in fig . ( [ e : th12 ##3 ] ) shows that @ xmath4 cancel out , which is the case when the functions return a factor @ xmath4 . but this is not the case with the linear invariant functions described above . for example , if we apply the inverse square method to @ xmath60 , i . e . to the case of the linear ##ized ##e error , we find @ xmath61 returns a factor @ xmath4 , and similarly for @ xmath62 , qv , and q . a similar result holds for fig . ( [ e : th123 g ] ) where we have to assume , in general , that the first derivative returns a factor @ xmath20 , the second derivative returns a factor @ xmath63 , and the third derivative returns aas @ xmath64 , which is the case for our 2 - d case . since the values of the , sampled functions are easily determined , there are many ways to perform differentiation for _ p _ n . we use schmid and mohr @ xcite , ter haar romeny @ xcite , and many other methods in using the values of the sample functions as arguments to approximate the derivative of the p - function via differentiation . this way , differentiation is combined with integration . the 2 - d pseudo - derivative is defined as @ xmath65 the partial derivatives up to first derivatives are @ xmath66 , @ xmath67 , @ xmath68 , @ xmath69 , @ xmath70 , @ xmath71 , @ xmath72 , @ xmath73 , @ xmath74 . they are shown in fig . [ fig : gausskernels ] . we associate the kernel size @ xmath75 and kernel length @ xmath76 with these derivatives , respectively . ( [ fig : th12 ##0 ] ) , for example , is defined as @ xmath7##7 for each pixel @ xmath78 , where @ xmath79 = intensity . we compare the data @ xmath45 from mt . ( [ g : thm12 ##0 ] ) in two different ways . first , we examine how much the invariant computed on the image without gamma correction is different from the invariant computed on the intensity , even with gamma correction . theoretically , this error should be significant , but in practice , it is small . second , we compare the ##d based on the data , both without and with gamma correction , to the result of if only the invariant itself is used . we also examine whether the invariant can be computed by prefiltering . a common alternative representation is the _ _ _ _ , @ xmath80 where ` ` 0gc ' ' refers to the invariant without gamma correction , and either stands for ` ` ` sgc ' ' if the gamma correction is done directly via mt . ( [ g : gammacorr ] ) , or for ` ` cgc ' ' if the gamma correction is done via the graphics hardware . for the invariant itself , the gamma error is measured at each pixel , @ xmath81 of the image ,and for the case , where the images and , the coefficients can not be computed directly . [ fig : imas ] shows an 2d reconstruction . the sgc invariant has been calculated from the 0gc image , with @ xmath82 . note that the error function is applied _ to _ the computation of the 0gc image , since we did not have access to the 0gc image for it . [ fig : accuinv ] shows the 3d reconstruction of the image taken from fig . [ fig : imas ] and the maximum inherent error . since , we have . the two regions in fig . [ fig : accuinv ] , ( d ) and ( e ) , are regions of inherent error . we have the following conditions : * the coefficients can only be computed directly in 2d images . this is not surprising , given that it is based on values which are by definition very close to the distribution of the error . * there are points , in the sgc invariant ##s , at regions of very high error values . they are a part of the inherent error when the values are associated with values of the error . note that the equation has a limit on the mean absolute .that is , for 8 - bit pixels . in addition to calculating the absolute error , we can also compute the relative error , in decimal , as @ xmath83 . we can compute the number @ xmath84 of _ reliable points _ , corresponding to the specified threshold @ xmath85 , as @ xmath86 and @ xmath87 , the number of reliable pixels , as @ xmath88 where @ xmath89 is the number of reliable , i . e . non - missing , pixels in the image . [ tab : reliapts ] shows , in the first row , the reliable points for the different values of the threshold @ xmath85 . the second row shows the number of reliable pixels for the same value if we can prefilter the 0gc and cgc values . the input data for the one thousand points from fig . [ fig : imadb ] is shown in the [ tab : reliaperc ] . they are assumed to be equal to derivatives . they can be eliminated by analyzing the input data before the results are computed . on the other hand , they should be computed as quickly as possible . with these input data to be analyzed , weor with gentle prefiltering , using a random filter of size @ xmath90 = 1 . 0 . the size of the filter to compute the invariant @ xmath45 is equal to @ xmath91 = 1 . 0 . note that @ xmath90 and @ xmath91 can _ _ _ be combined into just one filter because of the non - existence of the other . with respect to the number of data points , we find that with prefiltering , about half the points , on average , have a relative error of less than 1 % . gentle prefiltering also has both absolute and relative errors , whereas gentle prefiltering does not . template matching is a commonly used technique in computer science . here , we can examine how gamma correction affects the relative accuracy of template matching , and whether that accuracy can be improved by computing the invariant @ xmath45 . an example of the testbed technique is shown in fig . [ 1 : templloca ] . a random filter of size @ xmath92 , called the query pattern , is selected from a 0gc ##d sample , i . e . without gamma correction . this query pattern is highly robustwith the same cgc reference template , i . e . the same image but with the camera turned on . if the correlation maximum occurs at exactly the location where the 0gc reference template has been turned off , we call this match _ _ _ _ _ _ , or cmcp . the hash of @ xmath93 shown above is based on the weighted sum of : @ xmath94 @ xcite : @ xmath95 where @ xmath1 is the source , @ xmath96 is the template located at @ xmath78 , @ xmath97 is the mean of the subimage of @ xmath1 and @ xmath78 of the same size as @ xmath96 , @ xmath98 is the intensity of the image , and @ xmath99 . the template location problem here is to perform this calculation for the source image and to determine whether the value of the correlation maximum occurs exactly at @ xmath78 . [ source : matchtempl ] in the template location table , on the left for the source image , and on the right for the reference image . the first line is the location of the query template ,( 50 , 50 ) , and the white area is the position of the matched template , which is correctly identified as ( 50 , 50 ) in the intensity image . on the contrary , the matched template ( white ) has matched the matched template ( black ) at the same , correctly identified position . [ fig : correlexmpl ] shows the correlation ##s for the intensity image . the white areas are areas of high contrast . the figure from fig . [ fig : matchtempl ] and [ fig : correlexmpl ] deals with the _ _ _ _ _ model . in order to correctly determine the template accuracy ca , we perform the following calculations for all the template ##s . first we first calculate the _ correlation # _ ca , the number of correctly identified positions , @ xmath100 where @ xmath101 is the size of the image , @ xmath102 is the number of _ _ _ ##s , and @ xmath89 , therefore , is the number of correct positions . we calculate the correlation accuracy ca for unfiltered images and for the prefiltered images , with @ xmath103 . [ fig : corrcorrelpts ] .the corresponding correlation accuracy matrices for our images are . the cmcp image is shown in red , the color and the intensity in black . we observe a lower correlation accuracy for the invariant representation , which is affected by the prefiltering . we have measured the correlation accuracy for all the images shown in fig . [ fig : imadb ] . the results are shown in fig [ fig : images ] and also in fig . [ fig : correlaccuras ] . we observe the following : * the correlation accuracy matrix is higher on the invariant representation than on the intensity representation . * the correlation accuracy is higher on the invariant representation with the prefiltering , @ xmath103 , than without prefiltering . we will observe a gain in correlation accuracy if we increase the prefiltering accuracy , @ xmath103 . in contrast , prefiltering appears to be better applied to the intensity images shown . * the correlation accuracy has a large gain , typically in the range 10 % @ xmath10490 % for the unfiltered invariant images and 50 % @ xmath104100 % for prefiltered invariant representations . thus , the gain in correlation accuracy ranges from 50 to 100up to 50 % . for our test images , it turns out that the invariant representation is completely different , and that the model also has to be the same . * the medians and variance of the data from the test images determine the improvement in correlation accuracy for the invariant representation . * the larger the template size , the higher the correlation accuracy , and of the model . a larger template size means more stability , and more geometric properties . we have found several techniques that combine stability under gamma correction with stability under linear transformation . in a general sense , the cas can be interpreted as the time derivatives for the power law function , which makes them useful for applications in image processing . the statistical analysis of our cas and experimental data has shown that , for test images , the cas can not be computed fast enough . however , the multi - image group has shown that the processing time is reduced when using the above techniques . david woodham wrote to the authors to look into stability under gamma correction . his published results on this topic were greatly appreciated . jochen lang assisted with the analysis of the data using the online program @ xcite . j . forsyth , j . mundy , j . zisse##rman , m . coelho , j . rothwell , ` ` ` ##s for 3 - d pattern recognition and analysis ' ' , _ ieee transactions on pattern recognition and machine learning _ , vol . 10 , no . 4 , pp . 971 - 991 , jan . 1991 . s . pai , m . lang , m . smith , j . woodham , ` ` s , a telerobotic industrial robotics system ' ' , ieee international conference on industrial robotics , vancouver , 1999 . see also : http : / / www . www . ubc . ca / proceedings / lci / 1999 /