we need a detailed discussion of the role of networks in assessing sampling and to shed light on how best to sample from them . a _ network _ is a set of network nodes typically represented simply as a graph : a set of vertices and a set of relationships among the vertices . networks are complex and organized in many and varied ways . for example , many internet - based social networks , such as mobile social networks , produce large amounts of data on interactions and relationships among people . mobile phones and location - aware devices produce large amounts of data on the communication channels and the relationships between people . in the field of biology today , from viruses to bacteria to social insects , there is widespread access to vast amounts of information among living organisms and the need to study and map these networks . with advances in technology , the rise of the internet , and the advent of mobile phones and location - aware devices , networks under study today are not only much larger than those of the past , but sometimes organized in a similar manner ( e . g . the network of friends and the internet itself ) . for many reasons , their internal structure is not directly visible to the user and can only be accessed through ` ` channels ' ' ( e . g . , social networks) . these limitations can make it difficult to collect or even study these data in their entirety . how , then , should one proceed with collecting and analyzing these raw data ? one approach to resolving these issues is _ sampling _ : sampling of the numbers of nodes and networks from the network . from network research @ xcite to network search @ xcite and p2p search @ xcite , network sampling comes in many different applications . in the first section , we focus on a particular area of research that is concerned with network methods that capture the network features of the individual networks . these methods have many applications in network science and network science . in @ xcite , for example , self - consistent algorithms were shown to be useful in improving the processing efficiency in the entire network and in improving the efficiency of network design . in section [ 2 : 1 ] , we discuss many other applications . although there have been a number of significant advances in research on network sampling ( e . g . @ xcite ) , there is still still much that requires further and deeper research . indeed , many applications under study , although not as complete , are , in fact , _ incomplete _ due to differences in data collection processes . therefore , a more comprehensive definition of network samplingis of great importance to this analysis . towards this end , we conduct a detailed study of _ network sampling bias _ . there have been a recent number of papers _ on _ problems _ that arise from network sampling bias and how and why it should be used @ xcite . our work differs from that of this previous work in that , for the first time in a systematic study , we see network sampling bias as an _ opportunity to be exploited _ . we show that bias of specific sampling types can be avoided if they ` ` push ' ' the sampling process towards discovery of new clusters of clusters . our main objective in the current research is to identify and understand the relationship between network sampling bias and other measures of network representativeness , so that these issues can be addressed in future research . * summary of results . * we conduct a detailed study of network sampling bias . we find that bias towards low _ degree _ ( a sample from expander networks ) has some significant advantages over other bias such as those toward high degree networks . we show both theoretically and physically that _ a bias _ ` ` pushes ' ' the sampling process towards new , larger networks and the discovery of new clusters of the network . * thefirst , we show that a network sampling method that selects nodes with higher connections from those already selected is often a very close match to one sampling low degree nodes and finding well - connected ( i . e . high degree ) nodes much faster than most other methods . we also show that the sampling - first approach , a widely - used sampling and sorting method , is surprisingly among the most efficient methods in terms of both sampling the network and finding new , well - connected nodes . finally , we show ways in which some of our methods can be used in many other fields including disease - detection and cancer detection . a number of these new methods are unique in that they are in stark contrast to previous methods found in much of the scientific literature ( e . g . @ xcite ) . * surprisingly , network sampling exists in many other fields . thus , we will explore some of these diverse areas of research . * network sampling in population genetics . * the concept of network sampling first arose to study situations where researchers had to sample unknown , difficult - to - find individuals ( e . g . , internet users , criminals ) . for this research , one can refer to @ xcite . the research in this area focuses almost entirely on acquiring unbiased data relating to theof _ specific to _ network _ . the other work , however , focuses on _ properties specific to the _ network itself _ ( some of which are not up to or not explained by _ network analysis ) . our work , therefore , is much more closely related to _ representative subgraph sampling _ . * representative subgraph sampling . * in recent years , a number of papers have focused on _ representative subgraph sampling _ : constructing networks in such a way that they are drawn out of the original network ( e . g . @ xcite ) . much of this work focuses on how best to construct a ` ` complete ' ' set _ of _ _ _ _ samples of the original network . in general , we hold to the view that no particular sampling method can be optimal for all networks . therefore , our goal , therefore , is to better understand the _ properties _ of _ sampling _ to shed light on how best to use them in practical applications . * uniform sampling . * there has been a more recent body of work ( e . g . @ xcite ) that focuses on constructing uniformly distributed networks in settings where nodes need not be uniformly distributed , ( e . g . , such as the case where edges can not be drawnweb graph ) . these methods , often based on random random samples , have been shown to be useful for certain language discrimination tasks ( e . g . , the number of speakers of a particular language in the web graph @ xcite ) . however , as mentioned above , the current work focuses on taking samples to determine structural ( and functional ) aspects of the _ network itself _ . in this regard , we consider these statistical methods to be not used during this work . therefore , we do not use them and instead focus our attention on the _ _ sampling strategies ( such as those used in _ _ subgraph _ _ ) . * research on _ bias . * several papers have described _ bias _ that results from standard sampling strategies ( e . g . @ xcite ) . for example , @ xcite shows that , under the standard sampling strategy of taking samples at random from a scale - free network ( i . e . a network whose probability distribution is the power law ) , the representative subgraph _ will _ be _ _ scale - free . the results of @ xcite show the same is true for traceroute _ . * * our papers on _ _ bias focus on the structural aspects . in contrast , we focus on the _definition _ of _ properties and ways in which they can be used in network analysis . * property testing . * research on networks is in the fields of combinatorics and graph theory and is based on the concept of _ property testing _ in _ @ xcite . methods such as those commonly used in graph theory , however , may be not useful for the analysis of _ real - world _ networks ( e . g . the precise meaning of , say , @ xmath0 - colorability @ xcite in the context of a real network is unknown ) . therefore , much research on property testing in networks is being conducted in @ xcite . * research methods . * web crawling ( e . g . , in p2p networks ) and network crawling can also be viewed as network sampling strategies , although they involve collecting samples from groups of nodes and not from the whole network . similarly , network sampling itself can be viewed as a form of information retrieval , where the goal is to find only a set of nodes that either individually or collectively meet the criteria of interest . many of the sampling strategies we discuss in the previous article , in particular , are network ##ing strategies ( e . g . breadth - first search ) . however , a number ofour ideas mentioned above have implications for these research areas ( e . g . , @ xcite ) . for discussion of network analysis algorithms in the context of sensor networks and p2p networks , we will refer to @ xcite and @ xcite , respectively . for discussion of connections between network analysis and network design , see @ xcite . we will briefly describe the algorithms and concepts used in this article . [ defn : sample ] @ xmath1 is the _ sample _ or _ sample _ where @ xmath2 is set of vertices and @ xmath3 is the set of edges . [ defn : sample ] the _ sample _ @ xmath4 is a subset of this , @ xmath5 . [ defn : sample ] @ xmath6 is the _ sample _ of @ xmath4 if @ xmath7 . [ defn : inducedsubgraph ] @ xmath8 is the _ induced subgraph _ of @ xmath9 based on the sample @ xmath4 if @ xmath10 where the vertex set is @ xmath5 and the edge set is @ xmath11 . the induced subgraph of the sample can also bereferred to as the _ subgraph _ _ . we observe sampling patterns in a total of nine different networks : a power network ( powergrid @ xcite ) , a wikipedia search network ( wikivote @ xcite ) , a pgp search network ( pgp @ xcite ) , a chemistry network ( hepth @ xcite ) , an energy network ( enron @ xcite ) , two co - operative networks ( condmat @ xcite and astroph @ xcite ) , two p2p time - sharing networks ( gnutella04 @ xcite and gnutella31 @ xcite ) , two digital advertising networks ( epinions @ xcite and slashdot @ xcite ) , and a digital pre - school network ( school @ xcite ) . these datasets are used to represent a diverse set of different networks from different sources . this approach allows a more detailed study of network structure and the analysis of the effects of different sampling patterns in the context of different network types . * [ s : datasets ] . size of each dataset . the data are treated as random and unweighted . [ s ] . random sampling . * note : * _ * = # ofhere , d = distance , pl = maximum path length , m = maximum path size , a = average density . _ [ parameters = " < , ^ , ^ , ^ , ^ , ^ " , parameter = " + " , ] - p . 1 . in the following section , we focus on a specific class of sampling algorithms , which we refer to as _ link - trace sampling _ . in _ link - trace sampling _ , the first node selected for inclusion into the sample is randomly selected from among the neighborhood of nodes not connected to those already selected . in this case , sampling proceeds by selecting and adding nodes to the sample . this process can be described below . [ defn : linktracesampling ] given an node @ xmath0 and an initial node ( or link ) @ xmath12 to which @ xmath4 is connected ( i . e . @ xmath13 ) , _ _ link - trace sampling _ _ , @ xmath14 , is a process in which nodes are iteratively selected from among the initial nodes @ xmath6 and added to @ xmath4 until @ xmath15 . _ link - trace sampling _ can also be referred to as _ link _( since links are ` ` scraped ' ' to discover them ) and _ _ _ _ _ _ ( since the link @ xmath9 removes itself iteratively during the course of the sampling process ) . the main advantage of sampling _ link - trace , however , is that direct access to the network in its entirety is _ _ _ required . this is useful for situations where the network is very large ( e . g . an online social network ) , small ( e . g . an online p2p network ) , or complex ( e . g . the internet ) . as an example , note from the [ defn : linktracesampling ] that we have always assumed that the neighbors of a given node can be obtained by sampling that node during the sampling process ( i . e . @ xmath6 is sampling ) . this , of course , also affects many social networks . for example , neighbors of a visited page can be obtained from the links to the visited page and neighbors of an individual in an online social network can be obtained by sampling ( ` ` ` scraped ' ' ) the entire list . having given the above definition of _ link - trace _ _ , we can also define _which _ neighbors of @ xmath6 should be randomly chosen at each iteration of the sampling algorithm . this choice will generally not affect the size of the network being sampled . we have several sampling algorithms - all of which are very simple and , at the same time , well - known in the context of real - world networks . * breadth - first search ( bfs ) . * starting with a single visited node , the bfs visits the neighbors of other nodes . at each iteration , it visits an unvisited neighbor of the _ least _ visited node @ xcite . for both @ xcite and @ xcite , it was also shown that bfs is biased towards high - ##rank and high - pagerank networks . bfs is applied prevalently to survey and survey networks ( e . g . @ xcite ) . * breadth - first search ( dfs ) . * dfs is similar to bfs , except that , at each iteration , it visits an unvisited neighbor of the most _ earliest _ visited node @ xcite . * random walk ( rw ) . * the random walk algorithm chooses the next node chosen at random from among the neighbors of the first node @ xcite . * frequency - search ( ffs ). * ffs , mentioned in @ xcite , is also a simple variant of bfs . at each iteration of the bfs - based algorithm , a node @ xmath16 is being selected according to ` ` ` knowledge ' ' of @ xmath17 . for @ xmath18 , ffs is equivalent to bfs . we use @ xmath19 , as noted in @ xcite . * directed search ( ds ) . * the ds strategy involves randomly selecting the node @ xmath20 with the highest degree ( i . e . number of nodes ) . this variant of ds was developed and first implemented in a p2p network , called @ xcite . note that , in order to find the node @ xmath21 with the highest degree , the algorithm must use @ xmath22 for selecting @ xmath20 . that is , knowledge of @ xmath23 is required at each iteration . as noted in @ xcite , this method is useful for some applications such as p2p networks and artificial neural networks . the ds strategy is only useful in cases where a ) one is interested in ` ` ` downsampling ' ' the graph to a smaller subgraph ,2 ) the crawl is fast and all of the previous crawl is known , and 3 ) the size of the nodes used to create the sample is not known . * * ( estimated node size ) . * for the currently constructed sample @ xmath4 , how do we select the node @ xmath20 with the most degree _ without _ the degree of @ xmath23 ? the following algorithm maps the links from the currently constructed sample @ xmath4 to the node @ xmath20 and selects the node @ xmath16 with the most degree from @ xmath4 . in other words , we use the degree of @ xmath16 in the first subgraph of @ xmath24 as an estimate of the degree of @ xmath16 in the resulting sample @ xmath9 . several algorithms have been used as methods of distributed sampling , with some success ( e . g . @ xcite ) . * * ( expansion strategy ) . * the following algorithm is based on the notion of expansion from induction on expander , and attempts to efficiently fill the sample with the following nodes : @ xmath25 , where @ xmath0 is the first node in @ xcite . for thethen , the random seed @ xmath16 selected for inclusion in the sample is selected based on the following : @ xmath26 in the sampling strategy , this strategy requires knowledge of @ xmath23 . in sections [ sec : bias . bias ] and [ sec : bias . reach ] , we will discuss in detail the effects of this knowledge base on structural properties of biological systems . what makes one sampling strategy ` ` better ' ' than another ? in statistical science , ` ` better ' ' is commonly understood to mean _ _ representativeness _ ( e . g . , @ xcite ) . that is , samples are considered better if they are more representative of structural properties of the entire sample . there are , of course , many structural properties from which to choose , and , as was shown by ahmed et al . @ xcite , it is not always clear which should be chosen . rather than using general structural properties as measures of representativeness , we use specific measures of representativeness that we regard as the most useful for certain problems . we divide these measures ( see below ) into three categories : selection , bias , and reach . for the sampling strategy , we select our samples from randomly selected populations , and our measure of representativeness for them ., and calculate the degree distribution as network size increases . ( standard values of these measures are discussed in section [ sec : applications . seedsensitivity ] . values for these measures of representativeness are discussed further in section [ sec : applications ] . ) due to these constraints and the large number of samples involved , for each time step , we can get estimates for the datasets that are representative of the patterns observed in those datasets . however , other examples are given in this section . the degree ( number of edges ) of nodes in a network is a fundamental and well - known property . in addition , other graph - based properties such as the average path length of nodes can , in some cases , be used as measures of degree ( e . g . , paths resulting from a large number of well - connected nodes that act as nodes @ xcite ) . we have three main types of degree ( with an emphasis towards real - world applications , discussed in section [ sec : applications ] ) . * degree of distribution ( distsim ) . * we take the degree distribution of the network and compare it to that of the degree distribution in the two - dimensional kolmogorov - smirnov ( k- 2 ) d - statistical @ xcite , a statistical model . our goal here is to measure the difference between the two degree distributions in terms of their shape and size . thus , the d - statistical is defined as @ xmath27 , where @ xmath28 is the number of high degrees , and @ xmath29 and @ xmath30 are the respective degree distributions for @ xmath9 and @ xmath8 , and @ xcite . we estimate the difference , by calculating the high - degree distribution from it . * # ##ble ( * ) . * in these scenarios , one thinks less about measuring the _ high _ degree distribution and more about accumulation the high degree nodes into the sample , ( e . g . , by @ xcite ) . for these scenarios , it is used as a tool for information retrieval . thus , we measure the extent to which these nodes accumulate nodes ( i . e . high degree nodes ) coming into the sample . as sample size increases , we measure the number of the new @ xmath31 nodes coming into the sample . for our estimates , we use @ xmath32 . the [ 0 : 1 . 1 ] of the __ distribution inclusion _ ( distsim ) and _ hub inclusion _ ( hub ) for the slashdot and enron datasets . note that the sec and ds strategies , both of which are limited to high degree distributions , perform best on _ distribution inclusion _ ( # ##im ) , and are the _ best _ based on the distsim score ( which is not a direct consequence of this trend ) . ( the ds strategy follows a similar trend but to a much lesser extent . ) on the other hand , methods such as bfs , ffs , and rw tend to perform best on distsim , but worst on both . for example , the ds and sec strategies locate the nodes of the top three groups with sample sizes greater than @ xmath33 in most cases . bfs and ffs have sample sizes of only @ xmath34 ( and the resulting gap is larger when selecting nodes much lower than @ xmath35 ) . more importantly , each strategy performs best on _ quality _ measures . this , however , creates a gap between methods : producing large samples of the most well - known nodes is in contrast with producing small samples with high degree distributions . more importantly , when comparing sample sizes , decisions made ingains for one strategy may result in losses for another . therefore , these decisions must be made in terms of how samples should be selected - a problem we discuss in more detail in section [ sec : selection ] . we begin this section by also noting that the performance data for sec appears to be strongly dependent upon the size and number of nodes actually present in the network ( relative to the rest of the network , of course ) . that is , sec matches ds performance even when the networks are larger and complex networks ( as noted in section [ sec : rep . sec ] ) . we will discuss this in section [ sec : rep . sec ] . ( other trends are also observed here , but the trend is much less obvious . ) in general , we find sec closely matches ds performance in all of the larger networks ( as opposed to simple networks such as the powergrid with more ` ` complex ' ' nodes , lower average cost , and lower average length ) . however , more research is needed to reach any conclusions on this particular issue . + - 0 . 01 in - 0 . 01 in + - 0 . 01 in - 0 . 15 in most real - world networks , such as social networks , exhibit a much greater statistical variance than whatwe would look for node @ xcite . however , this has been a network topic of interest for some time . therefore , we are interested in measuring the extent to which nodes represent the number of clusters present in the entire network . we have several types of coefficients , which we can define . * local cluster coefficient ( ccloc ) . * the local cluster coefficient @ xcite of a node is the extent to which the neighbors of ##áµ¢ are not neighbors of each other . similarly , the local cluster coefficient of a node is defined as @ xmath36 where @ xmath37 is the distance of node @ xmath16 and @ xmath38 is the number of clusters among the neighbors of @ xmath16 . the corresponding local cluster coefficient for a triangle is as @ xmath39 . * global cluster coefficient ( ccglb ) . * the local cluster coefficient @ xcite is a measure of the number of triangles in the triangle . it is defined as the number of open triangles divided by the number of closed pairs of triangles . results for some measures are more poor than for other measures . however , dfs and rw ##fs seem to be much better than others . we havenote that , for many networks and algorithms , levels of clusters are initially higher - than - average and then gradually lower ( see figure [ sec : 1 . 1 ] ) . this agrees with us . nodes in networks should always have many connections available to them and should , therefore , be found early in the sampling process ( as opposed to only being found in clusters and located at the edges of the network ) . this , too , should be taken into account in cases where directly measuring cluster ##ing is impossible . + - 0 . 01 + - 0 . 01 + we introduced a general measure of representativeness , _ network reach _ . as a general measure , _ network reach _ has historically received much less attention than sampling and analysis of the underlying networks , but it is , nonetheless , a useful measure for a variety of optimization problems ( as we will see in figure [ sec : 1 ] ) . _ network reach _ is the extent to which a sample _ reaches _ the network . thus , for a sample to be considered representative of a given network , it should consist of nodes from all parts of the network , as opposed to being limited to a particular ` ` edge ' ' of the network . this concept can be made more clear by the network -the two measures of _ community reach _ we have : _ community reach _ and the _ community distance _ . * community reach ( cnm and rak ) . * all real - world networks have what is known as _ community reach _ . _ _ structure _ can be roughly defined as a set of nodes more densely connected among themselves than to other nodes in the network . although there are different ways to measure community reach depending on various factors such as whether or not it is random , in this case , we define the network as a _ partition _ : a set of fuzzy sets whose union is the empty set @ xmath2 @ xcite . in this case , each node in the partition is a community . the goal of the community reach algorithm is to find a partition such that vertices in the same subset of the partition are more densely connected to each other than to vertices in another subset @ xcite . for the measure of _ community reach _ , a community is considered part of the network if it consists of members from all of the communities in the partition . we measure _ community reach _ by counting the number of communities represented in the partition and dividing by the total number of communities represented in the entire network . since a community is afor analysis of communities , one can ask why we have defined _ community reach _ as a measure of _ community size _ , rather than as a measure of _ reach _ . the reason is that we are much more interested in the physical properties of communities described above . rather , our purpose is to determine how ` ` spread out ' ' a community is in the network . since community reach is something of an auxiliary measure ( e . g . in @ xcite ) , we define _ community reach _ with respect to two different approaches . we use both the method proposed by clauset et al . in @ xcite ( denoted as cnm ) and the method proposed by raghavan et al . in @ xcite ( denoted as rak ) . thus , for our purposes , we are defining reach _ as the result of the community detection algorithm . * discovery index ( dq ) . * an important application of _ community reach _ is to estimate the part of the network that was _ discovered _ by a sampling algorithm . the number of nodes discovered by this sampling is given by @ xmath40 . the _ discovery index _ is this is equal to the total number of nodes in the network : @ xmath41 . *, we are measuring the _ distance _ of a network element by measuring the degree to which it is one edge away from the center of the network . as we will see in section [ sec : reach ] , algorithms with measuring _ network distance _ have many important advantages . note that a simple greedy strategy for simple networks such as this has a well - defined optimal approximation guarantee of @ xmath42 @ xcite . however , link - trace sampling is equivalent to sampling all network elements from the same set @ xmath6 at each node , which results in a much larger sample size . however , this approximation guarantee can be shown not to hold in the limits of link - trace sampling . as discussed in section [ sec : sec . reach ] , the greedy algorithm has the very good performance on all the measures of _ network distance _ . we note two things here . first , the extent to which the greedy strategy exceeds the others on the rak and cnm measures is very remarkable . we note that the convergence rate of the greedy strategy ` ` favors ' ' the greedy algorithm towards the selection of network elements not already sampled ( see sampling @ xcite ) . in section [ fig : rep . 1 ] , we notewe make this distinction between expansion _ and _ _ reach _ . on the other hand , the sec strategy appears to be among the most effective at recruiting new individuals or communities . we attribute this to the fact that it explicitly selects nodes with close ties to communities already sampled . these nodes are likely to be members of communities already sampled in the sample . similarly , on the dq scale , it is surprising that the ds strategy , which explicitly selects high degree nodes , often fails to even come close to the sec strategy . we also attribute this to the increase in the number of well - known nodes . by explicitly selecting nodes that contribute to _ reach _ , the ds strategy is able to reach a much larger percentage of the population in the same number of years - in some cases , by explicitly selecting _ _ high _ degree nodes . finally , it is also surprising that the bfs strategy , when used to survey and analyze online social networks ( e . g @ xcite ) and telephone networks ( e . g . @ xcite ) , performs very well on all three measures . in particular , we find that nodes contributing significantly to the growth of the population are unique in that they provide significant and immediate benefits over and above those provided by nodes that are .randomly - selected and those derived from previous bfs - based methods . these and other published methods are in contrast to the conventional methods used in much of the scientific literature ( e . g . @ xcite ) . + - 0 . 01 in + - 0 . 01 in - 0 . 01 in as mentioned , sec - based ##r methods are generated from randomly selected seeds . this raises the question : how similar are these methods to the seeds assigned to each node ? figure [ sec : ref ] shows the standard deviation of the sec method for each _ node ##s _ and _ hub # _ as network size increases . we also found that methods with the most significant variability ( sec , sec , rep ) tend to exhibit the least statistical error and variability , while the other methods ( bfs , dfs , ffs , rw ) exhibit the most . this variability is observed in all methods and all datasets . let us briefly describe the sample results from figure [ sec : ref ] . we found that the sec method far exceeded all others in sampling seeds from many different sources . we also found that the sec method is not a very good approach to accurately sample high density networks and that the results of most link -these algorithms are smaller than other analytical methods . therefore , we turn our attention to further studying these network algorithms . we begin by briefly describing the following analytical results . * random walk ( rw ) . * there is a very large body of literature on random walks and directed networks ( see @ xcite for an early example ) . a well - known analytical result is that the probability ( the _ stationary _ probability ) of arriving at a node @ xmath16 during a random walk in a linear , directed network increases with probability to @ xmath43 , where @ xmath44 is the degree of node @ xmath16 @ xcite . in particular , the _ stationary probability _ of a random walk ( i . e . the total number of steps required to reach a node _ from each direction ) has been recently shown to be closely related to this hitting probability @ xcite . random walks , however , are strongly biased towards high degree ( and hence pagerank ) trees , which provides a simple explanation as to why rw is much better than other algorithms ( e . g . bfs ) using parameters such as _ _ _ _ . however , as shown in the [ see : node . graph ] , theand very near the best results . however , these two methods seem not to converge to the extreme and fail to explain the sampling bias . * distributed search ( ds ) . * while studying the problem of finding peer - to - peer networks , adamic et al . @ xcite developed and implemented a distributed search algorithm , similar to the linear search algorithm . this method , which we refer to as the scale - free algorithm , was later extended to only find the highest - ranked networks and to find large numbers of scale - free networks . thus , these results provide a good explanation for limitations of the ds algorithm in problems such as _ _ search _ and the _ _ search _ . * positive results . * as mentioned in section [ sec : relatedwork ] , to the best of our knowledge , most of the current published works on sampling bias rely on _ positive _ results @ xcite . however , these results , although useful , do not provide much help in the interpretation of the _ positive _ results mentioned in section [ sec : analysis ] . + we also have two measures for which there is little or no published research literature : ind and ind . a commonly used measure for the ` ` quality ' ' of the performance of a network in both general andexamples : _ _ _ _ @ xcite , which is a measure of the number of the edges removed from the graph ( smaller values are larger values ) : @ xmath45 where @ xmath46 are elements of the distribution matrix of the community and @ xmath47 , which is the total number of edges incident to the node set @ xmath4 . it can be shown that , when the number of nodes is very large , network behavior is strongly driven by network structure . consider a random directed graph starting with node set @ xmath2 and a node s community , setting @ xmath48 where @ xmath49 . let @ xmath50 and @ xmath51 be the edges of the node s community both inside and outside the node s community , respectively . these edges are distributed uniformly at random to nodes either inside or outside the node s community , according to the distribution matrix ( e . g . , @ xcite ) . note that both @ xmath50 and @ xmath51 are distributed only to edges . when x is small , @ xmath51 is greater than @ xmath52 , the total number of edges incident to @ .##math53 = @ xmath54 , and @ xmath50 and @ xmath51 are the numbers representing the inward and outward edges , respectively , of the community ( as compared to expected edges ) . thus , @ xmath55 and @ xmath56 . if @ xmath57 , then @ xmath58 . ( in this example , the parentheses represent the edges in @ xmath53 community . ) ] as opposed to @ xmath50 . the following example shows the relationship between @ and _ _ _ _ in terms of these inward and outward edges . [ example : xsbias ] let @ xmath4 be the initial community , @ xmath16 be the first community to be added to @ xmath4 , and @ xmath59 be the size of @ xmath16 initial community . if @ xmath60 , then the expected expansion of @ xmath24 is larger when @ xmath16 is in a new community than when @ xmath16 is in a new community . let @ xmath61 be the expected expansion for @ xmath62 when @ xmath16 is in a new community and then @xmath63 is the current community when and . we compute an upper bound on @ xmath63 and a lower bound on @ xmath61 . + generating @ xmath63 : assume @ xmath16 is associated with a current community already represented by at least one node from @ xmath4 . since we are computing an upper bound on @ xmath63 , we assume there is only one node from @ xmath4 in @ xmath16 s community , and this is the condition for @ xmath16 s community to be a _ new _ community . by the law of induction , the upper bound on @ xmath63 is @ xmath64 , where the set @ xmath65 is the minimum number of nodes from @ xmath16 s community that are already affiliated to @ xmath16 _ and _ is the set @ xmath66 . + generating @ xmath61 : assume @ xmath16 belongs to a current community already already represented by @ xmath4 . ( by definition , any node from @ xmath4 can be in @ xmath16 s community . ) using the following##ity of 1 . thus , the upper bound for @ xmath61 is @ xmath67 , where the number @ xmath68 is the total number of nodes in @ xmath16 . ##n that are not connected to @ xmath16 _ and _ are in @ xmath6 . + . for @ xmath51 , if @ xmath60 , then @ xmath69 . theorem [ sec : xsbias ] shows here the link between sec and community structure - a link that , until recently , had not been fully proven @ xcite . here , a simple justification for application of the sec algorithm to _ community structure _ is provided . suppose that the sec algorithm uses the degree of each node @ xmath16 in the initial subgraph @ xmath70 as an estimate for the degree of @ xmath16 and @ xmath9 . in theorem [ sec : 2 ] , we show that this method works very well in general . next , we provide a justification for the sec algorithm . consider a random graph @ xmath9 with only low - degree nodes ( e . g . a power - directed graph , the so - called@ xmath71 ( @ xcite ) and each node @ xmath5 . let @ xmath72 be a parameter that gives the expected degree of a given node in a given neural network ( see @ xcite for more details see _ _ _ degree _ ) . thus , it is fairly straightforward to compute the following formula . [ prop : secbias ] for any two nodes @ xmath73 , + if @ xmath74 , + @ xmath75 . the length of an interval between any two nodes @ xmath76 and @ xmath77 . then if @ xmath78 where @ xmath79 . then @ xmath80 . then , @ xmath81 since @ xmath82 and when @ xmath83 , the formula holds . the section [ prop : secbias ] with the results from @ xcite ( discussed in section [ sec : expected . degree ] ) provides a theoretical basis for the performance of the sec algorithm on nodes such as _ _ ##s _ . also , note from section [ sec : expected . expected . degree ] that the degree to which sec measures the degree of s is the##s appear to also depend on the distribution of college degrees . " [ 1 : secbias ] also provides insight into this phenomenon . longer and wider networks allow for more ` ` flexibility ' ' when departing from these notions of # ##ness ( resulting in real - world growth rates that are not necessarily random ) . we will also describe ways in which some of our ideas can be used for other , real - world purposes . although many potential applications exist , we focus primarily on two areas : 1 ) network prediction 2 ) graph and network theory 3 ) networks . what is the most effective and efficient way to predict and prevent a disease spread in a social network ? in a recent study , christakis and colleagues studied the spread of the h1n1 virus among medical students at stanford university @ xcite . their research has shown that well - connected ( i . e . high risk ) individuals in the network spread the disease faster than those with low risk @ xcite . thus , _ identifying _ these individuals allows for the spread of the disease ( a concern to public health professionals ) and _ identifying _ these ill - connected individuals ( when it is necessary ) can prevent or delay its spread . thus , identifying ill - connected individuals in the network allowsnon - invasive , direct access to their information and relationships is often not readily available . and , obtaining this information is time - consuming , extremely expensive , and nearly impossible for large networks . things are even worse when assuming that the best web - based methods for contact detection and outbreak detection have some knowledge of the underlying network structure ( e . g . @ xcite ) . this , therefore , is a good opportunity to demonstrate the power of _ acquaintance _ . to sample well - connected students and detect the problem , christakis and fowler @ xcite developed a sampling method called _ acquaintance _ _ ( acq ) based on the so - called sampling algorithm @ xcite . the assumption is that the neighbors of randomly selected nodes in the network will appear to be well - connected @ xcite . christakis and fowler @ xcite , therefore , sample the neighbors of randomly selected nodes with the goal of finding a network of well - connected students . based on our experimental results , we ask : can we do better than this acq method ? in both cases , we found independently and independently that the sampling method performs very well at network scale . ( it also seems to require more time than sas and sas , the two best methods. ) section [ fig : outdet ] describes the sample size required to identify the 5 - 10 best - connected individuals for both sec and acq . the performance improvement is quite modest , with the sec method performing very well by simply zero in sampling the number of most best - connected individuals . aside from its superior performance , sec has an important advantage over the acq method developed by christakis and colleagues . the acq method assumes that nodes in @ xmath2 can be selected entirely at random . this is , in turn , based on this @ xcite . ( acq , sec , is _ not _ a link - trace sampling strategy . ) in contrast , sec , being a typical link - trace sampling strategy , has no such limitation and , therefore , can be applied to many situations for which acq is inadequate . - fig . 5 . note from section [ fig : fig . 5 ] that a community in a network is a collection of nodes more closely related among themselves than to others . identifying members is difficult , as they may belong to specific demographic groups , functional groups , and groups ( both demographic and functional ) @ xcite . the ability to accurately identify a community consisting of nodes from different groups has many practical applications .. . _ we _ need to select small groups that best reflect the characteristics of the community @ xcite . if the groups of individuals are not known in advance , this can be difficult . the same approach , which uses the term _ _ design _ , can also be very effective marketing . additionally , it has the added benefit of being able to select individuals from different communities with _ _ _ a priori _ knowledge of communities _ , social networks , and the actual social network _ in the community . there is some empirical evidence to suggest that being able to assemble a sample from many different communities may be an advantage for effective word - of - mouth marketing @ xcite . this , too , is yet another potential practical advantage for the research project . _ landmark - based metric _ is a simple set of methods to generate landmark - based data for social networks in @ xcite . the basic idea is to select a random set of nodes ( i . e . the landmarks ) , then offline the distances from these nodes to each other node in the network , and use these pre - determined distances at runtime to calculate distances between groups of nodes . as described in @ xcite , for this approach to be effective , nodes should be selected so that they _explore _ all nodes of the network . based on our results for _ network reach _ in figure [ fig : rep . reach ] , the reach ratio _ has the highest _ reach _ _ and reaches the network much better than any other measure . therefore , this is a _ network reach strategy . our results for the _ reach ratio _ and other measures of _ network reach _ _ provide important insights into how networks should _ be sampled , explored , and explored . as shown in figure [ fig : rep . reach ] , the most prevalently used method for sampling networks , bfs , scores high on measures of _ network reach _ . this means that the bfs and its potential use for social network knowledge acquisition and exploration ( e . g . , @ xcite ) should probably be studied more closely . we also conducted a comparative study of sampling networks in real - world networks . in our study , we found the bfs , a commonly - used method for sampling and exploring networks , to be among the best suited for both sampling the nodes and finding high , well - connected nodes . we also found that sampling bias towards these nodes tends to favor nodes that are very different from those that are less well - connected and .during the bfs - sampling process . these high - expansion nodes tend to come from more and more portions of the network than those sampled during the sampling process . we have found that sampling nodes with significant differences from those already sampled is a very close approximation to the high expansion nodes . further , we identified several ways in which these findings can be applied to real - world application such as virus , ##s and others . for further development , we need to explore ways in which the best - known sampling strategies can be adapted for even larger applications . one possible approach is to explore the possibility of combining and combining several biases into a single sampling strategy .