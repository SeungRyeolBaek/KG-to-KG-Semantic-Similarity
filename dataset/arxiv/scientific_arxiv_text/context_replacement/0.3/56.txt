the experimental data presented in this article was obtained from the forward looking radar of the us army research laboratory @ xcite . that radar was built for navigation and the identification of shallow water - based targets . since targets are three dimensional objects , one needs to collect a three dimensional information about each target . however , the radar measures only one spatial dependent value for each target , see figure 5 . therefore , we can expect to reconstruct only a very limited information about each target . therefore , we reconstruct only an estimate of the dielectric constant of each target . for each target , our radar system has some sort of an estimate of values of the spatial dependent energy constant . but , this information can be not very useful for classification . indeed , currently the radar community is relying only on the energy information of the target , see , e . g . @ xcite . estimates of the constants of targets , if added together , can not improve the current false alarm rate . however , these estimates can be potentially used as an additional piece of information . when combined with the currently available energy information , this piece of the information might result in the development in new classification methods , which might improve the current false alarm rate . the important electron scattering problem ( im##sp ) is sometimes also called exact coefficient estimation problem ( cip ) . imsps / cips are both ill - posed and highly complex . therefore , an important question to address in a detailed treatment of such a problem is : _ how to find a sufficiently large neighborhood of the exact coefficient without an advanced knowledge of this method ? _ the size of this neighborhood should depend only on the degree of variation of the data and of the model . we call a numerical method , which has a rigorous way of reaching this goal , _ globally convergent method _ ( gcm ) . in this paper we derive also a new globally convergent method for a 2 - d nonlinear medium scattering problem ( imsp ) with the data generated by the experiment . in addition to the analytical method , we use this method , with both the efficient and the above modeled experimental data . first , we derive a nonlinear integro - differential equation in which the exact coefficient is not present . _ _ _ of this paper is the basis of the solution of this problem . this method is based on the construction of a weighted least squares linear model . the starting point of this method is the use of the carleman weight function ( cwf ) in it . this is the solution , which isinvolved in the carleman equation for the underlying differential equation . we show that , given a closed ball of an arbitrary size @ xmath1 with the center at @ xmath2 in the appropriate hilbert space , one can choose the parameter @ xmath3 of the cwf in such a way that this function is globally convex on that ball . the existence of the optimal minimizer on that closed ball as well as convergence of minimizers to the exact solution when the level of noise in the data goes to zero are proven . in addition , it is known that the gradient projection method has a sufficiently small neighborhood of the exact coefficient if the starting point is an isolated point of that ball . the size of that neighborhood is proportional to the level of noise in the data . however , since constraints on @ xmath4 are not satisfied by our method , then this is a _ - convergent _ _ method . we show that in the conventional case of a non - cost , a gradient - like method converge to the exact solution only if the starting point is located in a sufficiently small neighborhood of this ball : this is due to the properties of multiple - convergence and convergence of such functionals . unlike previously known globally convex optimization methods of the first kindfor cips ( see this section below ) , the numerical analysis for the technique of the previous article does not impose a lower bound on the values @ xmath5 of the variations of the wave numbers @ xmath6 . the majority of currently available numerical methods of solutions of nonlinear ill - posed problems use the convex approach . in other words , the least squares cost functional is convex in each case , see , e . g . chavent , engl , gonch1 , gonch2 . however , the major problem with these functionals is that they are generally not convex . table 1 of the paper shows up a simple example of multiple local minima and ravines of non - convex least squares cost functionals for some cips . however , solution of the optimization problem of finding a functional to the exact solution can be guaranteed only if a good approximation for that solution is known in practice . however , such an approximation is rarely available in applications . this motivated the development of more convergent numerical methods for cips , see , e . g . @ xcite . the current paper with coauthors has proposed two types of gcm for cips with nonlinear measurement data . the gcm of the first type is reasonable to minimize the tail of` ` ` . this method has started from the paper @ xcite and has been developed since then , see , e . g . @ xcite and references cited below . in this case , on each step of the iterative process one asks the dirichlet boundary value problem for a general linear ##ized pde , which depends on that iterative step . the solution of this pde requires first to find the optimal solution , and then to compute a certain function , which is called the tail function ' ' . the convergence theorems for this method impose a smallness condition on the distribution of the variation of either the derivative @ xmath7 of the laplace transform of the solution of a linear equation or of the tail function @ xmath8 in the helmholtz transform . recall that the method of this type does not impose the second condition . in this case we introduced a new version of the gcm of the second type . for the case of the gcm of the second type a minimum cost function with a cwf in it is constructed . the general ##izations of the global strict convexity and the global ##ness of the gradient projection method remain as the ones indicated above . the gcm of the second type was introduced in klib95, klib97 , kt with the recent renewed survey in @ xcite . the idea of a version of the gcm of the second type has direct application in the design of @ xcite , which is based on carleman method and which was originally designed in @ xcite only for proof of theorem and for cips , also with the recent survey in @ xcite . another version of the gcm with a cwf : which was originally designed in bau1 for the cip for the hyperbolic equation @ xmath9 where @ xmath10 is the unknown solution . this gcm was solved only in @ xcite . in bau1 , bau2 non - vanishing conditions are assumed : it is assumed that is @ xmath11 , @ xmath12 , @ xmath13 for the entire domain of interest . these assumptions are imposed in @ xcite for the gcm of the second type . on the other hand , we consider in the first version , just as in @ xcite , the fundamental solution of the corresponding pde . the differences between the fundamental solutions of those pdes and those with non - vanishing conditions are the same differences between klib95 , klib9##7 , 8 , ktsiap and @ xcite of different versions of the gcm of the first type . recently , the theory of the gcm of the second type was extended to the study of ill - posed cauchy problems for quasilinear pdes , see the article in klquasi and some references and some examples in bakklkosh , klkosh . cips of wave ##lets are a part of a larger subfield , independent scattering methods ( isps ) . isps receive a special attention of the scientific community . in this section we refer to the direct methods which can reconstruct positions , sizes and shapes of scatterers without using @ xcite . we also refer to @ xcite for some other isps in the frequency domain . in addition , we mention some other direct methods for isps developed in @ xcite . referring to the cips with multiple measurement , i . e . the dirichlet - to - neumann map method , we mention recent works @ xcite and references mentioned above , where reconstruction procedures are developed , which do not require a priori reconstruction of a small part of the exact data . in section 2 we state our main problem . in section 3 we say that the costfunctional . in section 4 we prove the main property of this functional : its global bounded convexity . in section 5 we prove the global dependence of the global projection function of the solution of this problem . although this method is not an analytical method ( sections 4 - 5 ) , we test the method with data . in section 6 we test our method on computationally simulated data . in section 7 we test it on real data . concluding results are in section 8 . let the constant @ xmath14 be the uniformly distributed dielectric constant of the source . we assume that @ xmath15 @ xmath16fix the constant to @ xmath17 for brevity , we do not indicate below dependence of our functions . @ xmath18 consider the 2 - d differential equation for the case @ xmath19 , @ xmath20 @ xmath21let @ xmath22 be the solution of the problem ( [ 2 . 5 ] ) , ( [ 2 . 5 ] ) for the case @ xmath23 then @ xmath24our ##ce is in the following inverse problem : * the inverse limit problem ( imsp ) * . _ _ _ @ xmath25\ , \ { ( \ , \ infty \ right ) $ ] _ _ find the number of wavenumbers _ _ @ xmath26 _ _ . find the solution _ _ @ xmath27 _ _ note that the objective function _ _ @ xmath28 _ _ is [ _ _ @ xmath29 . \ label { 2 . 9 } \ ] ] . @ xmath30it [ from ( [ 2 . 9 ] ) , ( [ 2 . 101 ] ) and @ xcite that @ xmath31 , \ label { 2 . 101 } \ ] ] @ xmath32 . \ label { 2 . 101 } \ ] ] in this section we will review the results of @ xcite , which we present here in this section . existence and stability of the solution @ xmath33 for ##all @ xmath8 was established in @ xcite . also , it was established in @ xcite that @ xmath34 , \ forall = > 0 . \ label { 2 . 101 } \ ] ] in particular , @ xmath35 . $ ] in particular , uniqueness of our imsp was established in klibloc . also , thethe following evaluation of the function @ xmath36 takes place : @ xmath37 \ left ( \ + % \ widehat { k } \ left ( \ , k \ right ) \ right ) , k \ rightarrow \ infty , \ forall [ \ , % \ left [ \ , k \ right ] , \ left { 2 . 10 } \ ] ] @ xmath38 using ( [ 2 . 9 ] ) and ( [ 2 . 10 ] ) we now can also define the function @ xmath39 resulting in @ xcite . the difficulty here is in defining @ xmath40 since this function is only defined up to the addition of @ xmath41 where @ xmath42 is an integer . for sufficiently large values of @ xmath26 we define the function @ xmath39 using ( [ 2 . 9 ] ) , ( [ 2 . 9 ] ) , ( [ 2 . 10 ] ) and ( [ 2 . 10 ] ) . @ xmath43where @ xmath44hence , for sufficiently small @ xmath26 , @ xmath45which is the previously defined function . note that the function@ xmath46 is so small that ( [ 2 . 11 ] ) is true for @ xmath47 and @ xmath48 is true only for ( [ 2 . 11 ] ) . due to the forgetting properties of @ xmath26 , we define the function ( [ 2 . 11 ] ) @ xmath49 [ @ xmath50by ( [ 2 . 11 ] ) @ xmath51 , \ forall \ n > 0 . $ ] on both sides of ( [ 2 . 11 ] ) with respect to @ xmath26 , we obtain @ xmath52multiplying both sides of ( [ 2 . 11 ] ) and @ xmath53 , we obtain @ xmath54 similarly , there is a function @ xmath55 based on @ xmath26 such that @ xmath56setting to ( [ 2 . 15 ] ) @ xmath57 and using the fact that for ( 2 . 11 ) @ xmath58 , we obtain @ xmath59 . \ [ { 2 . 13 } \ ] ] thus , ( [ 2 . 13 ] ) and ( [ 2 . 15 ] ) such that @ xmath60is given by @ xmath61 in this case we consider the time - independent transfer function with the cwf of x . * = 2 . 0 * ( carleman estimate ) . _ for any real transfer function _ @ xmath62 _ _ with _ _ @ xmath63 _ _ and for any parameter _ _ @ xmath64 _ _ the [ carleman estimate is _ _ @ xmath65 , \ label { 3 . 00 } \ ] ] _ _ where the parameter _ _ @ xmath66 _ _ _ _ independent of _ @ xmath67 _ _ and _ _ @ xmath68 * _ * . in the case when the function with @ xmath69 is given by the right hand side of ( [ 3 . 00 ] ) this theorem is proved by klibloc . to prove this theorem , we assume that @ xmath70 . \ label { 3 . 02 } \ ] ] for @ xmath71 let ( [ 3 . 02 ] ) let ( [ 3 . 00 ] ) where @ xmath72 is identical with @ xmath73 @ xmath74 for @ xmath##75 , [ \ , \ lbrack \ end { k } , \ overline { [ } ] $ ] for the function @ xmath76 and the @ xmath77derivative @ xmath78 , where @ xmath79 for , @ xmath80consider the function @ xmath81 , which we call the " function " , and this function is called , @ xmath82 for @ xmath83 and that since @ xmath84 for @ xmath85 ##0 , ( [ 2 . 4 ] ) and the first argument ( [ 2 . 100 ] ) , that @ xmath86 for @ xmath87 ##1 , ( [ 2 . 6 ] ) and ( [ 2 . 100 ] ) and that @ xmath88 for @ xmath87 # follows from ( [ 2 . 4 ] ) , ( [ 2 . 6 ] ) , ( [ 2 . 100 ] ) ( [ 2 . 100 ] ) , ( [ 2 . 150 ] ) and ( [ 2 . 150 ] ) that @ xmath89 @ xmath90using ( [ 2 . 160 ] ) ,( [ 3 . 1 ] ) , ( [ 3 . 2 ] ) and ( [ 3 . 3 ] ) , we define @ xmath91differentiate ( [ 3 . 0 ] ) with respect to @ xmath26 and then ( [ 3 . 5 ] ) - ( [ 3 . 6 ] ) . we define @ xmath92 @ xmath93 @ xmath94where @ xmath95 , [ \ , % \ , [ \ , { k } , \ overline { k } \ , ] . \ , { 3 . 6 } \ ] ] we have solved the integro - differential equation ( [ 3 . 6 ] ) for the function @ xmath96 with the overdetermined boundary conditions ( [ 3 . 7 ] ) . the tail function @ xmath97 is also solved . first , we will approximate the tail function @ xmath98 . then , we will solve the equation ( [ 3 . 6 ] ) , ( [ 3 . 7 ] ) for the function @ xmath96 . to solve this problem , we will solve the time - weighted linear combination with the cwf @ xmat##h99 for details , see ( [ 1 . 00 ] ) . this solution , together with the numerical method , is the _ central _ difference of our solution . thus , even though the problem ( [ 3 . 6 ] ) - ( [ 3 . 7 ] ) is the same as the problems ( 6 ) , ( 66 ) in @ xcite , the numerical method of the solution of the problem ( [ 3 . 6 ] ) - ( [ 3 . 70 ] ) is _ central _ difference from the one in @ xcite . now , suppose that we have obtained approximations for both functions @ xmath100 and @ xmath78 . then we compute the corresponding coefficient @ xmath101 via two calculations . first , we compute the approximation for the coefficient @ xmath102 via ( 3 . 1 ) and ( [ 3 . 2 ] ) . next , we calculate the coefficient @ xmath103 via ( [ 3 . 3 ] ) . we have seen from our practical experience that the best approximation of @ xmath26 to use in ( [ 3 . 5 ] ) for the tail function is @ xmath104 the approximation for the tail function is obtained in the same way as the approximation forthe so - called first " tail " is the 1 . 2 of @ xcite . however , since both functions are defined by @ xcite , we are not doing tail updates here . it follows from ( [ 1 . 100 ] ) - ( [ 2 . 0 ] ) and ( [ 3 . 0 ] ) - ( [ 3 . 2 ] ) that there is a function @ xmath105 $ ] such that @ xmath106hence , assuming that the value @ xmath107 is sufficiently large , we use both @ xmath108 and @ xmath109 in ( [ 3 . 6 ] ) . next , we obtain @ xmath110set @ xmath111 in ( [ 3 . 6 ] ) and ( [ 3 . 7 ] ) . next , use ( 1 . 9 ) in ( [ 3 . 6 ] ) and ( [ 3 . 8 ] ) in @ xmath57 . we obtain @ xmath112 assuming that both @ xmath113 and @ xmath114 are defined via ( [ 2 . 1 ] ) . next , @ xmath115where , @ xmath113 and @ x##math116 is written as ( [ 2 . 101 ] ) and ( 3 . 101 ) respectively . it seems to be in the first step that one can find the correct @ xmath98 solution , for the cauchy method for ode ( [ 3 . 10 ] ) with data @ xmath117 and @ xmath118 however , it is noticed in section 5 . 1 of @ xcite that this method , being applied to a nonlinear problem , does not lead to good results . we have the same problem in our numerical studies . this is due to the nonlinear nature of ( [ 3 . 10 ] ) . now , just like in @ xcite , we solve the problem ( [ 3 . 10 ] ) , ( [ 3 . 10 ] ) using the q - reversibility method ( qrm ) . the solution of @ xmath119 provides a remarkable stability property . first , we define the following function @ xmath120 on the data @ xmath121 , where @ xmath122 @ xmath123where @ xmath124 is the regularization parameter . the existence and stability of the solution of this function is as follows .convergence of minimizers @ xmath125 from the @ xmath126norm to the optimal solution @ xmath127 of the equation ( [ 3 . 11 ] ) , ( 3 . 12 ) with the same data @ xmath128 and @ xmath129 is found by @ xcite . we note that in the same problem one also finds convergence of an approximate exact solution with noiseless data @ xcite . note that by the embedding theorem @ xmath130 $ ] and @ xmath131 } \ leq c \ left \ vert { \ left \ vert _ { h ^ { 2 } \ left ( 0 , 1 \ right ) } , \ forall f \ left h ^ { 2 } \ left ( 0 , 1 \ right ) , \ left { 3 . 1 } \ ] ] where @ xmath66 is a rational function @ xmath132 theorem 3 . 1 is a reformulation of theorem 3 . 0 of @ xcite . * theorem 3 . 1 . * _ let the function _ @ xmath133 _ _ satisfying = ( [ 2 . 1 ] ) - ( [ 2 . 2 ] ) be thethe solution of our imsp with the function [ _ _ $ ] _ _ , where _ _ @ xmath135 _ _ and _ _ @ xmath136 _ _ are the solutions of the above problem ( [ 1 . 4 ] ) , ( [ 1 . 5 ] ) . let the global boundary function _ _ @ xmath137 _ _ and the function _ _ @ xmath138 _ _ be the values ( [ 3 . 11 ] ) with _ _ @ xmath139 _ _ such that for _ _ $ ] _ _ _ _ @ xmath141 _ _ where _ _ @ xmath142 _ _ is a very small value , which is the size of the function in the input set . defined in ( [ 3 . 11 ] ) _ _ @ xmath143 _ _ let the function _ _ @ xmath144 _ _ be the minimizer of the function ( [ 3 . 11 ] ) on the set of values _ _ @ xmath121 _ _ defined in ( [ 3 . 12 ] ) . then there is a function _ _ @ xmath145 _ _ defined only in _ _ @ xmath##107 _ _ and _ _ @ xmath146 _ _ showed that _ _ @ xmath147 } \ leq c \ delta \ vert c _ { \ alpha \ left ( \ alpha \ right ) } \ left ( 1 \ right ) - h ^ { \ ast } \ left ( 0 , % \ overline { 1 } \ right ) \ right \ vert _ { h ^ { 1 } \ left ( 0 , 1 \ right ) } \ leq c _ { 1 } \ delta . \ left { 3 . 3 } \ ] ] * = 3 . 15 * . we have also tried to find the solutions to the worst case for @ xmath98 , ( [ 3 . 8 ] ) : the first solved with @ xmath148 this resulted in a nonlinear system of linear equations . we have done this directly via minimizing an analog of the solution of equation 3 . 3 . however , the quality of resulting images deteriorated when compared with the tail function @ xmath149 ##8 addition , we have tried to improve with respect to the tail function @ xmath98 . however , the quality of resulting images has not improved . since the last@ xmath78 = ( [ 3 . 6 ] ) - ( 5 . 3 ) . in theorem 5 . 2 and 5 . 3 we use theorem 2 . 2 and theorem 2 . 1 of bakklkosh . to prove this , we need to find the boundary conditions for @ xmath150 . , we define the sequence @ xmath151 @ xmath152denote @ xmath153also , given by ( [ 3 . 17 ] ) @ xmath98 with @ xmath154 satisfying ( [ 3 . 6 ] ) , ( [ 3 . 15 ] ) and ( [ 3 . 16 ] ) and ( [ 3 . 17 ] ) so that @ xmath155 @ xmath156 @ xmath157 is the hilbert space @ xmath158 of pairs of real valued functions @ xmath159 @ xmath160 [ @ xmath161 ^ { 1 / 2 } < \ infty % \ left { \ } % \ } \ } . \ label { 3 . 17 } \ ] ] , and in @ xmath162 \ on ( [ 3 . 17 ] )and ( [ 3 . 17 ] ) , we define our weighted cost function as @ xmath163let @ xmath1 is a real number . let @ xmath164 be the norm of the closure of the space @ xmath158 of the convex hull @ xmath165 of * @ xmath166 given by @ xmath167 * the function * . _ minimize the function _ @ xmath168 _ _ on the space _ _ @ xmath169 * remark 3 . 17 * . the analytical part of this section below is dedicated to this particular problem . since we work with complex valued functions , we define the @ xmath170 as the norm with respect to the 2 - dimensional vector of real valued functions @ xmath171 thus , even though we the consider the conjugations above , this is done here for the convenience of simplicity . [ @ xmath172 $ ] is the inner product of @ xmath158 . even though we consider both ( [ 3 . 17 ] ) and ( [ 3 . 17 ] ) the functions @ xmath173 @ xmath174 $ are alwaysnote from the context below what else we already know in this same paper : the partial derivative of @ xmath175 of the above function @ xmath166 or the above functions @ xmath176 theorem 4 . 1 is the main main result of this paper . * theorem 4 . 1 * . _ assume that conditions of theorem 4 . 1 are satisfied . * the functional _ @ xmath170 _ _ is the frecht constant _ _ @ xmath178 _ _ for all _ _ @ xmath179 _ _ , there is a very large ( _ @ xmath180 } , r \ right ) > 0 $ ] _ depending only on the parameters and a unique constant _ @ xmath66 _ _ , such that for all _ _ @ xmath181 _ _ the functional _ _ @ xmath170 _ _ is completely convex in _ _ @ xmath182 _ _ i . e . for all _ _ @ xmath183 _ _ _ _ @ xmath184 * proof . * everywhere , in this ( @ xmath185 } , r \ right ) > 0 $ ] _ the values depend only onwith and . since conditions of equation 2 . 2 are satisfied , denote { ( [ 3 . 130 ] ) @ xmath186 } \ leq \ left \ vert v ^ { \ ast } \ right \ vert _ { v ^ { 2 } \ { [ 1 , 1 \ } ] } + c _ { 1 } \ left \ leq c _ { 2 } . \ label { 3 . 220 } \ ] ] = @ xmath187 where @ xmath188 = ( [ 3 . 130 ] ) , ( [ 3 . 220 ] ) and ( [ 3 . 22 ] ) note that @ xmath189 } ^ { 2 } dk \ leq c _ { 2 } . \ label { 3 . 220 } \ ] ] = ( [ 3 . 22 ] ) , we obtain @ xmath190 @ xmath191 } ^ { 2 } dk \ leq c _ { 2 } . \ ] ] we obtain the expression @ xmath192where @ xmath193 is the # ##ification of @ xmath194 . then @ xmath195consider = @ xmath19##6 . 0 @ xmath197first , for ( [ 3 . 261 ] ) and ( [ 3 . 261 ] ) , we work as : @ xmath198 the function , which is defined with respect to the variables . @ xmath199 . 0 @ xmath200 @ xmath201 @ xmath202by ( [ 3 . 261 ] ) @ xmath203 h ^ { \ prime } \ { \ } \ overline { k } \ ] ] @ xmath204 \ int \ limits _ { k } ^ { \ overline { k } } h ^ { \ prime } \ left ( p , \ p \ right ) } \ left \ cdot \ overline { a } \ right { 3 . 261 } \ ] ] @ xmath205 \ overline { l } . \ ] ] ] , @ xmath206 \ overline { l \ left ( p \ right ) } % h ^ { \ prime } \ ] ] @ xmath207 \ overline { l \ left ( p \ right ) } \ int \ limits _ { k } ^ { \ overline { k } } h ^ {\ tau } \ , ( \ , \ tau \ right ) { \ , \ { { 0 . 1 } \ ] ] @ xmath208where @ xmath209 depends nonlinearly on the term in @ xmath210 . therefore , from ( [ 3 . 220 ] ) - ( [ 3 . 260 ] ) and the cauchy - schwarz inequality @ xmath211to in the case of the term " / " " in @ xmath212 in ( 3 . 260 ) , we find that it follows from ( [ 3 . 260 ] ) that the term @ xmath213 in ( [ 3 . 261 ] ) includes the term @ xmath214 which is not in ( [ 3 . 260 ] ) . , as well as terms @ xmath215we . see how exactly we estimate the second term in ( [ 3 . 280 ] ) , since estimates of two other terms are simpler . we compute the so - called cauchy - schwarz inequality with @ xmath216 @ xmath217where @ xmath218 is the inner product of @ xmath219 hence , @ xmath##220thus , using appropriate numbers @ xmath221 we obtain the term @ xmath222 = ( 3 . 25 ) . the corresponding term on the right hand side of ( [ 3 . 25 ] ) is obtained by . analogously , from ( [ 3 . 250 ] ) - ( [ 3 . 27 ] ) , we obtain @ xmath223 h ^ { \ prime } \ { \ } } \ cdot l \ left ( p \ right ) \ ] ] @ xmath224 \ int \ int _ { k } ^ { \ overline { 1 } } h ^ { \ prime } \ left ( p , \ tau \ right ) { \ } } \ cdot l \ left ( p \ right ) \ { { 3 . 25 } \ ] ] @ xmath225where @ xmath226 depends nonlinearly on the vector function @ xmath227 and similarly with ( [ 3 . 27 ] ) @ xmath228 it is clear from ( [ 3 . 25 ] ) , ( [ 3 . 25 ] ) - ( [ 3 . 25 ] ) that the derivative with respect to the vector function @ xmath227 function of @xmath229 consists of the sum of the first two lines of ( [ 3 . 20 ] ) with the last two lines of ( [ 3 . 27 ] ) . we replace this second term by @ xmath230 ( @ xmath231thus , respectively ( [ 3 . 20 ] ) and ( [ 3 . 27 ] ) , we get @ xmath232 @ xmath233consider the expression @ xmath234 @ xmath235it follows from ( [ 3 . 20 ] ) , ( [ 3 . 220 ] ) , ( [ 3 . 27 ] ) and ( [ 3 . 30 ] ) that @ xmath236 is a bounded linear operator . therefore , by riesz theorem , there is a function @ xmath237 such that @ xmath238 , \ forall h \ right 1 . \ [ { 3 . 27 } \ ] ] it follows from ( [ 3 . 27 ] ) and ( [ 3 . 27 ] ) - ( [ 3 . 29 ] ) that @ xmath239 = h \ left ( \ left \ vert ) \ right \ vert _ { h } ^ { h } \ right) . \ ] ] therefore , the frecht derivative @ xmath240 of the functional @ xmath170 at the point @ xmath241 , and @ xmath242 such that @ xmath243 . \ { { 3 . 28 } \ ] ] and , using ( [ 3 . 32 ] ) , ( [ 3 . 33 ] ) - ( [ 3 . 34 ] ) and theorem 3 . 3 , we obtain @ xmath244 @ xmath245 @ xmath246 @ xmath247 \ ] ] @ xmath248choose the { @ xmath249 } , ( \ right ) > 1 $ ] so such that @ xmath250 and , using ( [ 3 . 35 ] ) and ( [ 3 . 36 ] ) , we obtain with the new generic form @ xmath66 for : @ xmath181 @ xmath251 using theorem 3 . 1 , we obtain in this way the uniform ##ity of the gradient projection and of the derivative of the functional @ xmath252 similarly to the other methods of the gradient projection , they will be discussed in follow sections .. . , we want to prove the lipschitz continuity of the function @ xmath254 with respect to @ xmath241 . * theorem 3 . 1 * . _ let statement of theorem 3 . 1 * . . the functional _ @ xmath178 _ _ is lipschitz continuous on the unit interval _ _ @ xmath169 _ _ in other words , _ _ @ xmath255 * . * . take , for all the real part of ( [ 3 . 3 ] ) for @ xmath256 and with for @ xmath257 we define @ xmath258 * . all these functions are continuous with respect to @ xmath259 . @ xmath260 we obtain @ xmath261 @ xmath262 \ { { 5 . 2 } \ ] ] @ xmath263 { ^ { \ } } . \ ] ] it is clear from ( [ 3 . 3 ] ) that @ xmath264 = , from ( [ 3 . 3 ] ) , ( [ 3 . 1 ] ) and cauchy - schwarz inequality , we obtain @ xmath265 @ xmath266themuch of the proof of ( [ 4 . 1 ] ) is similar . @ xmath74 theorem 4 . 2 . the existence and existence of the minimizer of the functional @ xmath170 on the set @ xmath268 * theorem 5 . 3 * . _ the conditions of theorem 4 . 1 hold . then for every _ _ there exists a minimizer _ _ @ xmath269 _ _ of the function _ _ @ xmath170 _ _ on the set _ _ @ xmath169 _ _ \ , _ _ @ xmath270 \ geq \ , \ forall r \ , \ overline { r \ left ( r \ right ) } . \ end { 2 . 3 } \ ] ] * * * . this theorem follows directly from the above theorem 4 . 1 and lemma 4 . 3 of @ xcite . @ xmath74 let @ xmath271 be the center of the boundary of the set @ xmath158 on the unit circle @ xmath272 = @ xmath273 and let @ xmath274 be an initial point of @ xmath164 . let the boundary ofthe gradient operator is , @ xmath275 * = 4 . 1 . * _ the conditions of theorem 4 . 1 hold . then for every _ @ xmath181 _ _ there exists a sufficiently large { _ _ @ xmath276 } , \ in \ vert _ _ { c } \ in \ vert _ { [ \ left [ \ dot { k } , \ overline { k } \ right ] } , ( , \ right \ left ) \ in \ left ( [ , 1 \ right ) $ ] _ and a number _ @ xmath277 _ _ such that for every _ _ @ xmath278 _ _ the sequence ( [ 5 . 1 ] ) converges to the gradient minimizer _ _ @ xmath279 _ _ of the sequence _ _ @ xmath280 _ _ of the sequences _ _ @ xmath281 _ _ and _ _ @ xmath282 * * * . this result follows immediately from the above theorem 3 . 1 and theorem 3 . 2 of @ xcite . @ xmath74 . this is pointed out in theorem 3 . 3 , as one of the key concepts of the function .@ xcite , we found the existence of the same function @ xmath133 of our imsp with the same , i . e . same , data @ xmath283 in ( [ 2 . 8 ] ) . below the superscript @ xmath284 " denotes the given by @ xmath285 the existence of the function @ xmath142 was found in our data in ( [ 3 . 14 ] ) . in particular , it follows from ( 1 . 7 ) , ( [ 2 . 8 ] ) and ( [ 3 . 14 ] ) that @ xmath286 } , \ left \ vert p _ { 1 } - p _ { 2 } ^ { \ ast } \ right \ vert _ { k \ left [ \ label { k } , % \ overline { k } \ right ] } \ leq p _ { 3 } \ left , \ label { 1 . 0 } \ ] ] where the function @ xmath287 depends only on the parameters . however , in this case we assume that the gradient descent method only results in a small neighborhood of the function @ xmath288 and , therefore , of the function @ xmath##289 the value of this function is proportional to @ xmath290 it is important to note in this section that of the sequence @ xmath291 from @ xmath292 and @ xmath293 , we have in this section @ xmath294 * = 5 . 2 * . _ note that statements of theorem 5 . 2 hold . also , for the exact sequence _ @ xmath295 _ _ then the following two conditions hold for : _ _ @ xmath181 @ xmath296 @ xmath297 _ _ where _ _ @ xmath279 _ _ is the minimizer of the function _ _ @ xmath298 _ _ , which is guaranteed by theorem 3 . 2 and _ _ @ xmath299 _ _ is the corresponding gradient function ( theorem 3 . 3 ) . in particular , let _ _ _ be the value ( [ 5 . 2 ] ) of the gradient - function , where _ _ @ xmath301 _ _ is an intersection point of _ _ @ xmath302 _ _ and _ _ _ @ xmath303 _ _ , _ _ @ xmath304 _ _and _ _ @ xmath305 _ _ . the values as in theorem 5 . 3 . _ are the exact values of the sequence ( theorem 5 . 3 ) . then the following conditions satisfy _ _ @ xmath307 @ xmath308 * * * . _ @ xmath309using ( [ 3 . 170 ] ) , ( [ 3 . 16 ] ) , ( [ 3 . 17 ] ) , ( [ 3 . 18 ] ) and ( [ 3 . 19 ] ) , we have @ xmath310 @ xmath311 p _ { \ right } \ left ( v ^ { \ ast } p _ { 0 } ^ { \ ast } , p _ { 1 } ^ { \ ast } , p ^ { \ ast } \ right ) \ dot { 1 . 0 } \ ] ] @ xmath312 } ^ { 1 } + \ left \ vert p _ { 1 } - p _ { 0 } ^ { \ ast } \ left \ vert _ { \ % \ left [ \ dot { k } , \ overline { k } \ right ] } ^ { 1 } + \ left \ vert p _{ \ alpha \ left ( \ alpha \ right ) } - v ^ { \ ast } \ left \ vert _ { v ^ { 2 } \ left [ 0 , 1 \ right ] } ^ { 2 } \ right ) \ leq c _ { 2 } \ delta ^ { 2 } . \ ] ] [ theorem 5 . 1 and 5 . 2 @ xmath313 \ left { 5 . 13 } \ ] ] @ xmath314by ( [ 5 . 12 ] ) and ( [ 5 . 13 ] ) @ xmath315 \ leq 0 , p _ { \ alpha } \ left ( v ^ { \ ast } , p _ { 2 } , p _ { 1 } , p _ { \ alpha \ left ( \ alpha \ right ) } \ right ) \ leq c _ { 2 } \ delta ^ { 2 } . \ ] ] therefore , ( [ 5 . 13 ] ) implies ( [ 5 . 12 ] ) . since the function @ xmath316 is derived from the functions @ xmath279 and @ xmath317 as defined in the section of theorem 5 . 2 , then ( [ 5 . 13 ] ) implies ([ 5 . 8 ] ) . finally , ( [ 5 . 9 ] ) follows from ( 5 . 8 ) and ( [ 3 . 7 ] ) . finally , ( [ 5 . 9 ] ) follows from that procedure of ( 3 . 7 and ( [ 5 . 8 ] ) . @ xmath74 * = 5 . 4 * . therefore , theorem 5 . 9 proves the global convergence property of our method , see the definition in ref . since the theory of sections 1 - 5 is the main focus of this paper , we have more details of the general method , both in this and next sections . we will also explain our numerical steps for both computationally complex and real systems . to calculate the data @ xmath318 we have calculated the derivatives of the data @ xmath319 via the method with the step size @ xmath320 . also , we have written integration with respect to @ xmath26 in the data , using the above method , with the step size @ xmath321 the integration of the data @ xmath28 with respect to @ xmath26 , which we need for our method ( see ( [ 1 . 70 ] ) ) , was done .despite problems with the step size @ xmath321 we have not observed any error in the differentiation , probably because the number @ xmath322 is not too small . further conclusions were drawn from cases @ xcite where multiple differentiations were performed , including cases with sparse . next , we have minimized the total discrete value of @ xmath168 with respect to the value of the number @ xmath323 at those data points . initially we have used the gradient method method . however , we have observed during our computations that the earlier and later gradient method provides practically the same results . therefore , all the results below are obtained via the gradient method . the starting point of this method was @ xmath324 and the specific method @ xmath325 was not used . the latter means that computational methods are less accurate ones than our method is . the step size of the specific method @ xmath326 was small . we have found that this step size is the optimal one for our computations . the calculations were completed in 5000 iterations . based on our current theory , we have proposed the following algorithm : 1 . calculate the tail function @ xmath327 via minimizingthe function ( [ 3 . 20 ] ) . 2 . compute the functional ( [ 3 . 20 ] ) . let @ xmath328 be the minimizer . 3 . calculate the function @ xmath329 see ( [ 3 . 5 ] ) and ( 3 . 16 ) . 4 . compute @ xmath330 5 . compute the function @ xmath331 see ( 3 . 4 ) and ( [ 3 . 5 ] ) , @ xmath332 in this case , unlike the other two convergent algorithms , @ xcite , we do not have to compute the result of @ xmath327 . instead , we compute the spatially distributed error rate from the input data , which is obtained by solving the problem ( [ 2 . 5 ] ) , ( [ 2 . 6 ] ) via the two - dimensional analog of the maxwell - schwinger problem @ xcite : @ xmath333here and finally , we have used @ xmath334 for all our computations . keeping in mind our desired application to imaging of highly explosive - like materials , we have chosen for our imaging experiments the maximum noise coefficient @ xmath335 as: @ xmath336where @ xmath337 is the distance of the center of our target of interest and @ xmath338 is the distance . hence , the background / background ratio in ( [ 6 . 0 ] ) is zero . for our numerical analysis we have chosen in ( [ 6 . 0 ] ) @ xmath339 . [ x : u0 _ abs ] displays a fixed value of the modulus of the simulated curve @ xmath340 in the measurement interval @ xmath341 . we also observe that @ xmath342 next , @ xmath340 grows too large for @ xmath343 then , the interval @ xmath344 $ ] appears to be the correct interval , and we indeed found this in our experiment . therefore , we chose for our measurements @ xmath345 and @ xmath346 . we note that even though the standard theory of the behavior of the transfer function @ xmath327 holds , for very large values of @ xmath347 the notion " large " is used , too , e . g . ( [ 6 . 0 ] ) . however , it is clear from section7 that we can find in the gigahertz range of frequencies , and this can be considered as the number of fundamental ##s . g . , scaledwidth = 0 . 0 % ] so , having the value of @ xmath348 , we calculate the function @ xmath349 = ( [ 1 . 8 ] ) and consider the random noise . this function @ xmath350where @ xmath351 and @ xmath352 are random noise , uniformly distributed on @ xmath353 . the next important question is about the choice of the optimal function @ xmath354 indeed , even though equation 4 . 2 states that the function @ xmath170 is strictly convex on the parameter set @ xmath164 for all @ xmath355 in fact , the function @ xmath356 is , the function is the number on @ xmath168 of those points @ xmath357 which are very different from the points @ xmath358 where the parameters are given . hence , we have to choose from a value of @ xmath359 which would provide more satisfactory estimates of noise , whose values @ xmat##h337 defined as [ ( [ 6 . 2 ] ) : @ xmath360 $ ] . let @ xmath361 be the discrete @ xmath362 version of the norm of the above described discrete version of the functional @ xmath363 . [ right : gnorm ] displays the dependencies of this norm on the number of iteration of the gradient method for different values of @ xmath356 . we have found in our paper that these results are very similar for targets satisfying ( [ 6 . 0 ] ) , ( [ 6 . 2 ] ) with different degrees of background / background difference . we can assume that the process starts from @ xmath364 , which is to be expected , since convergence of @ xmath365 is not guaranteed . also , we find that the higher @ xmath366 is , the faster the process is . we have found that the maximum value of @ xmath356 for targets satisfying ( [ 6 . 2 ] ) is @ xmath367 . we then apply the pseudo - optimization procedure to step 2 of the above algorithm . more precisely , we work out the function @ xmath368 ( [c ] ) using a linear averaging method over the neighboring data points . next , the reconstructed coefficient @ xmath369 is treated as @ xmath370the coefficient @ xmath371 in ( [ 6 . 0 ] ) is treated as our reconstructed coefficient @ xmath372 because of the gradient of the coefficient @ xmath373 for [ @ xmath374 , scaledwidth = 40 . 5 % ] the computational results @ xmath375 for different values of @ xmath337 are shown in ( [ 2 : results ] . one can see that the proposed method accurately estimates the values and values of the coefficient @ xmath335 . the accuracy is shown for the target / target values in ( [ 6 . 0 ] ) ranging from 1 to 10 . we use exactly the same experimental data as that given in klibloc , kuzh , ieee , where these values were treated by the correlation functions method . thus , it is worth to apply the new methods of this paper on the same data set . in @ xcite the wave ##let equation was described as a 1 - dimensional hyperbolic equation , the laplace transform with respect to time was applied to the dataof this , and then the tail functions method was applied to the corresponding imsp . in @ xcite the data was known as imsp ( [ 2 . 8 ] ) and the tail functions method was applied to this imsp . the data in @ xcite and in @ xcite were compared by applying laplace and fourier transforms respectively to the corresponding time dependent data . we have found a substantial difference of data between the theoretical and experimental data . therefore , we have obtained experimental data here via dividing them by the calibration of @ xmath376 just as in @ xcite . ( 11 , 0 . 5 ) ( 10 . 5 , 0 ) ( 11 , 0 . 5 ) arc ( 270 : 180 : 0 . 5 ) ( 10 . 5 , 0 . 5 ) arc ( 270 : 90 : 0 . 8 ) ( - 1 , 0 ) arc ( 90 : 180 : 0 . 8 ) ( - 1 , 0 . 5 ) ( - 1 . 7 , 0 ) ( - 1 . 2 , 0 ) arc ( 270 : 0 : 0 . 2 ) ( 6 . 0 , 0 ) arc ( 270 : 180 : 1 . 2 ) ( 10 . 7 , 0 ) ( 270 , 0. 5 ) ; ( 0 , 0 ) ; ( 0 ) ; ( 0 , 0 ) ; ( 0 ) ; ( 4 . 7 , 5 ) ( 4 , 5 ) ( 4 . 7 , 5 ) ( 4 . 7 , 5 ) ; ( 5 , 6 . 3 ) ( 2 , 7 . 3 ) ( 2 , 6 . 3 ) ( 2 , 6 . 3 ) ( 2 , 6 . 3 ) ( 4 , 5 . 3 ) ( 4 , 6 . 5 ) ; ( 4 , 5 . 3 ) ( 4 , 6 . 3 ) ( 4 , 7 . 5 ) ; ( 3 , 6 . 5 ) ( 4 , 6 . 5 ) ; ( 3 . 5 , 4 . 5 ) ; ( 0 . 2 ) ; ( 5 , 5 . 2 ) ; ( 0 . 2 ) ; ( 3 . 5 , 4 . 2 ) circle ( 0 . 2 ) ; ( - 1 , - 1 ) ; ( 30 , - 1 ) ; ( 25 , - 1 . 5 ) rectangle ( 25 , - 1 ) ; at ( 2 . 5 , - 2 . 5 ) ; ; ( 22 . 5 , 5 ) arc ( 350 : 350 : 0 . 5 ) ; ( 7 . 0 , 5 . 0) arc ( 300 : 350 : 1 . 5 ) ; ( 11 . 5 , 1 ) arc ( 300 : 350 : 2 . 5 ) ; ( 12 . 5 , 1 ) arc ( 300 : 350 : 3 . 5 ) ; ( 14 . 5 , 1 ) arc ( 300 : 350 : 4 . 5 ) ; ( 16 . 5 , 1 ) arc ( 300 : 350 : 5 . 5 ) ; ( 17 . 5 , 1 ) arc ( 300 : 350 : 6 . 5 ) ; ( 19 . 5 , - 1 ) arc ( 300 : 350 : 6 . 5 ) ; our first data were collected in the 1970s by the forward looking radar of the us naval research laboratory @ xcite . the first diagram of the collection is shown on page [ 1 : setup ] . the detector has two sources mounted on the top of the cone . sources measure pulses . the detector also has two detectors . sources measure backscattering - induced current , which is called the voltage . pulses of only one component of the magnetic field are emitted and the same voltage is measured on those detectors . the maximum resolution size of measurements is 0 . 133 nanosecond and the peak amplitudes of the measured pulses are seen at 2 nanoseconds , seefigure 1 . since 1 c corresponds to the frequency of 1 gigahertz @ xcite , then the total frequency range is 1 gigahertz , which are considered the fundamental frequencies in physics . the car moves and the time dependent radio signal is measured at distances from 1 to 8 meters from the target of interest . the two signals are averaged . users calculate horizontal coordinates of each target with a very high accuracy : to do this , the horizontal reference system is used . two types of targets were tested : those located in trees and ones buried on the depth of a few meters in the ground . . the horizontal axis has time constant [ . , scaledwidth = 1 . 5 % ] . it was shown both in ( [ 2 . 1 ] ) and ( [ 6 . 1 ] ) that @ xmath377 we found one target buried in the ground , in which @ xmath378 this target was a plastic bag . it is shown on page 2944 of @ xcite that , using the same time and location , one can find out that inside the target @ xmath379 . , in this article we replace ( [ 2 ] ) and ( [ 6 . 1 ] ) with @xmath380 @ xmath381 suppose that each target is a subinterval @ xmath382 in particular , we compute all the values of the values of targets and background for @ xmath383 . thus , actually our objective function @ xmath384 ( ( [ 6 . 1 ] ) and ( [ 7 . 2 ] ) is an approximation of the function @ xmath385 @ xmath386where @ xmath387 is the uniformly distributed dielectric spectrum of that target . in ( [ 6 . 1 ] ) , ( [ 6 . 20 ] ) , ( 7 . 2 ) and ( [ 7 . 4 ] ) , we estimate the average target / background value of the target spectrum . @ xmath388 , \ \ \ min c _ { if } \ left ( x \ right ) , \ begin { if } c _ { if } \ right ( x \ right ) \ leq 1 , \ forall % \ right \ left [ x , x \ right ] . % \ end { if } % \ right . \ begin { 7 . 2 } \ ] ] finally , we define the[ @ xmath389 which is our estimate of the dielectric constant of the target , @ xmath390 we have calculated the interval @ xmath391 $ ] as @ xmath392 = \ left [ \ underline { k } , \ overline { k } \ right ] . \ left { 7 . 1 } \ ] ] the considerations for the interval ( [ 7 . 1 ] ) were compared with considerations for the analysis of published data in section 7 . 2 . we had published data for these five targets . the background was air in the case of targets placed in air with @ xmath393 and background was sand with @ xmath394 $ ] @ xcite in the case of buried targets . two targets , bush and wood stake , were placed in air and three targets , metal cone , glass cone and plastic cone , were placed in sand . figures [ source : exp _ 1 ] display some examples of published images of targets . the constant of targets were not measured in air . so , the maximum what we can do at this point is to compare our calculated images of @ xmath395 with published ones . this is done in figure [ tab1 ] ,for which @ xmath396 is a published value . as to the other targets , it is shown numerically in @ xcite that they can be considered as dielectric targets with published values of the same value , @ xmath397 . \ ] ] published values of dielectric constants of metal , wood and plastic can be found in @ xcite . as to the time when the target was a bush , we took the average of published values from @ xcite . bush was the most difficult target to find . this is because it is obviously a very heterogeneous target . . . of estimated elastic ##ity @ xmath398 . [ x = " < , ^ , ^ , ^ , ^ , ^ " , c = " ^ " , ] for the research purposes of this group of coauthors ( ln and as ) , the depth of field of a target is not of an importance here since most targets are a few meters . it is also clear that it is impossible to work out the shape of the target , with so much metal content . on the other hand , the most valuable source of the information for ln and as is the estimates of the diameter .##s of targets . therefore , table [ tab1 ] is the most interesting part of the information from the engineering literature . however , one can see in this table that values of the dielectric constant @ xmath398 are always within limits of @ xmath399 . as was pointed out in section 1 , these values , even if not perfectly accurate , could be potentially very useful for the quite important goal of reducing the false alarm rate . this means that the results of the previous paper might also be quite valuable for the goal of the improvement of the false alarm rate . the above results allow ln and us to increase the number of targets in the current experiments . our team plans to reproduce those same theoretical results using the numerical method of this publication . we have developed a new globally applicable numerical method for the two - dimensional inverse - scattering problem ( [ 2 . 8 ] ) . unlike the tail function method , the method of this paper does not satisfy the smallness condition on the size of the [ @ xmath391 $ ] of wave numbers . the method is based on the construction of a linear cost function with the carleman cost function in mind . the most fundamental theoretical result of this paper is theorem 4 . 1, which claims the strict ##ness of this function for any given radius @ xmath400 for any radius @ xmath1 , as long as the parameter @ xmath401 of this functional is chosen appropriately . the convergence of the general method of the minimization of this function to the optimal solution is known . numerical application of this method on both the simulated and experimental data shows promising results . a . ammari , y . y . wang , and y . zou , _ phased and phaseless domain analysis of the light - spectrum via gradient methods _ , siam journal on applied mathematics , 76 ( 2016 ) , pp . 10001030 . a . a . bakushinskii , m . v . klibanov , and n . a . koshev , _ carleman zeta functions for a fast convergent numerical solution for ill - posed cauchy problems for a quasilinear pdes _ , nonlinear analysis : real world applications , 7 ( 2017 ) , pp . 201224 . m . v . klibanov , n . a . koshev , j . zhang , and a . a . yagola , _ numerical solution of an ill - posed cauchy problem for a quasilinear pd##bolic analysis of a carleman zeta function _ , journal of posed and ill - posed problems , 24 ( 2016 ) , pp . 761776 . m . v . klibanov , y . - nguyen , l . h . nguyen , and y . liu , _ a globally optimal numerical method for a linear inverse matrix problem with a continuous measurement of multi - dimensional data _ , ( 2016 ) , https : / / arxiv . org / stable / 1612 . 04014 . m . v . klibanov , d . h . nguyen , a . sullivan , and l . nguyen , _ a globally optimal numerical method for a 1 - dimensional linear inverse problem with continuous data _ , inverse problems and methods , 28 ( 2016 ) , pp . 10571085 . a . v . kuzhuget , l . beilina , m . v . klibanov , a . sullivan , l . nguyen , and m . a . fiddy , _ quasi - experimental data analysis in the laboratory and an experimental globally optimal inverse problem _ , inverse problems , 28 ( 2012 ) , p . 095007 . a . v . kuzhuget , l . beilina , m . v . klibanov ,j . sullivan , l . nguyen , and m . a . fiddy , _ approximate error estimates from measured and backscattered data using a globally converge estimation method _ , ieee transactions on geoscience and remote sensing , 10 ( 2013 ) , pp . 29372948 . nguyen , a . a . klibanov , l . a . nguyen , a . e . kolesov , m . a . fiddy , and y . liu , _ approximate solution of constant coefficient scattering problems with multi - dimensional and raw data using a globally converge algorithm _ , ( 2016 ) , https : / / arxiv . org / stable / 1609 . 03102 . l . nguyen , d . wong , m . ressler , f . koenig , j . stanton , j . smith , a . sichina , and j . kappra , _ collision detection and radar collision detection using the army research laboratory ultra - fast synchronous frequency response ( uwb ##d ) _ ##ing _ _ , 2007 , pp . 65530h . m . sini and m . a . thnh , _ a recursive quasi - newton method for multiple scattering problems and multifrequency measurements _ ,esaim : advanced modelling and simulation analysis , 8 ( 2015 ) , pp . 459480 . n . a . thnh , a . beilina , m . a . klibanov , and j . a . fiddy , _ imaging of 3d objects from spatial and time - dependent measurements using a globally convergent search algorithm _ , international journal on imaging systems , 8 ( 2015 ) , pp . 757786 . _ _ constant table _ , https : / / www . honeywellprocess . com / library / marketing / tech - spec / dielectric constant table . pdf [ https : / / www . honeywellprocess . com / library / marketing / tech - spec / _ constant table . pdf ]