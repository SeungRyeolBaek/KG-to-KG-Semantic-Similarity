invariants are a popular tool for image recognition and information retrieval @ xcite . they aim to provide properties that remain valid for certain geometric or radiometric properties of the scene , thereby reducing the search time . they can be divided into global invariants , typically based either on a set of key points or on images , and local invariants , typically based on properties of the image , which is assumed to be continuous and symmetric . the geometric transformations of interest typically include translation , rotation , and scaling , summarily referred to as _ similarity _ transformations . in a recent article @ xcite , building on work done by schmid and mohr @ xcite , we have defined differential invariants for those similarity transformations , plus _ linear _ brightness changes . here , we are looking at a _ non - linear _ brightness change _ as _ gamma correction _ . gamma correction is a non - linear correction of the brightness measurements performed by the cameras during the image processing process . the idea is to achieve better _ perceptual _ resolution by using an approximately constant ratio of adjacent brightness levels , dividing the brightness levels apart by the _ brightness _ difference _ . however , this non - linear correction also precompensates for the non -linear mapping from brightness to brightness in electronic devices is @ xcite . the mapping can be described by the equation @ xmath0 where @ xmath1 is the input intensity , @ xmath2 is the output intensity , and @ xmath3 is the correction factor which is given by the value of @ xmath4 . for output devices , the ntsc standard specifies @ xmath5 . for input devices and cameras , the parameter value is just inversed , resulting in a parameter value of @ xmath6 . the camera we ##lder , the sony sony ccd digital camera dxc 950 , specified @ xmath7 . for the kodak megaplus xrc camera ] [ see : gammacorr ] shows the linear mapping of 8 - bit images for different values of @ xmath4 . it turns out that an invariant for gamma correction can be derived from first and second order derivatives . additional invariance under scaling yields higher order derivatives . derivatives are by definition translationally invariant . rotational stability in 2 - dimensions is obtained by using rotationally invariant operators . the first step for the design of the proposed invariants is to find the values of the parameters of the image function such that the shapethen the signal of interest will work better . this method has been used by @ xcite to achieve stability under small brightness changes , and it can be applied to the context of gamma correction by at least just taking the _ logarithm _ of the image function . for this , we begin with 3 - d image processing . let @ xmath8 be the image function , i . e . the input signal , assumed to be continuous and discrete , and @ xmath9 the corresponding gamma corrected function . note that @ xmath8 is a special case of @ xmath10 where @ xmath11 . taking the logarithm of @ xmath12 with the coefficients @ xmath13 , and @ xmath14 . we can also define the function @ xmath15 _ gamma _ to be @ xmath16 { 0mm } { 13 ##mm } & = $ \ frac { \ gamma \ , \ frac { f ' ( x ) } { f ( x ) } } { \ gamma \ , \ frac { f ( x ) \ , f ' ' ( x ) - f ' ( x ) ^ 2 } { f ( x ) ^ 2 } }$ \ \ & = $ \ frac { f ( x ) \ , f ' ( x ) } { f ( x ) \ , f ' ' ( x ) - f ' ( x ) ^ 2 } $ \ text { x } \ ] ] the expression @ xmath3 has been obtained by taking derivatives , and @ xmath4 is canceled out . however , @ xmath15 turns out to be an invariant in terms of the _ _ _ _ function and its derivative , i . e . the logarithm actually does not have to be zero . the notation @ xmath17 indicates that the invariant depends on the underlying image . @ xmath8 and in @ xmath18 the invariant holds under time correction , and under linear changes of the objective function . the shortcoming of @ xmath15 is that it is defined where the derivative is zero . therefore , we define @ xmath15 to be continuous as : @ xmath19 { 0mm } { # ##mm } { \ normalsize $ \ _ _ { m12 \ n } = $ } & $ \ frac { f \ , f ' } { f \ , f ' ' -{ f ' } ^ 2 } $ & { \ normalsize if $ | f \ , f ' | < | f \ , f ' ' - { f ' } ^ 2 | $ } \ \ & $ \ frac { f \ , f ' ' - { f ' } ^ 2 } { f \ , f ' } $ & { \ normalsize else } \ \ \ { { tabular } \ ] ] where , for notational convenience , we have introduced the parameter @ xmath18 . the transformation follows . note that the transformation is just a way to deal with poles . if the derivatives are zero because the objective function is constant , scaled scales are probably not the best way to model the system . if there is a transformation that has to be introduced , then another parameter @ xmath20 describing the definition of derivative has to be introduced . that is , it is modeled simply as follows . @ xcite : the scaled scale of @ xmath8 is @ xmath21 . suppose we are looking at the parameter @ xmath22 where the derivatives with respect to @ xmath18 are @ xmath23 , @ xmath24 , and @ xmath25 .then the invariant @ xmath26 is obtained by finding a constant value of the function such that both @ xmath4 and @ xmath20 cancel so : @ xmath27 { 0mm } { 8 mm } & = $ \ frac { g ^ 2 g ' \ , g ' ' ' - 2 \ , g \ , { g ' } ^ 2 g ' ' + 2 \ , { g ' } ^ 4 } { g ^ 2 { g ' ' } ^ 2 - 2 \ , g \ , { g ' } ^ 2 g ' ' + \ { g ' } ^ 4 } $ \ , { g } \ ] ] according to definition . ( [ 1 : thm12 g ] ) , we can obtain the following : @ xmath28 { 0mm } { 8 mm } { \ normalsize $ \ int _ { m123 \ } } = $ } & $ \ frac { g ^ 2 g ' \ , g ' ' ' - 2 \ , g \ , { g ' } ^ 2 g ' ' + 2 \ , { g ' } ^ 4 } { g ^ 2 { g ' ' } ^ 2 - 2 \ , g \ ,{ g ' } ^ 2 g ' ' + \ { g ' } ^ 4 } $ & { \ normalsize if cond2 } \ \ & $ \ frac { g ^ 2 { g ' ' } ^ 2 - 3 \ , g \ , { g ' } ^ 2 g ' ' + \ { g ' } ^ 4 } { g ^ 2 g ' \ , g ' ' ' - 3 \ , g \ , { g ' } ^ 2 g ' ' + \ \ , { g ' } ^ 4 } $ & { \ normalsize else } \ \ \ , { f } \ ] ] where condition cond1 is @ xmath29 @ xmath30 , and condition cond2 is @ xmath31 @ xmath32 @ xmath33 . unfortunately , this method fails . there is a simple albeit efficient way to compute the derivatives from above . ( [ e : th12 ##2 ] ) and ( [ e : th123 # ] ) with an arbitrary , continuous function . as an easy example , we have @ xmath34 the first three derivatives are @ xmath35 , @ xmath36 ,and @ xmath37 . then , according to fig . ( [ g : th12 g ] ) , @ xmath38 . if we now replace @ xmath8 with a gamma corrected version , like @ xmath39 , the first derivative becomes @ xmath40 , the second derivative is @ xmath41 , and the third is @ xmath42 . if we combine these derivatives into eq . ( [ g : th12 g ] ) , we obtain an invariant for @ xmath43 which is identical to the one for @ xmath17 above . the more advanced reader is encouraged to verify the identity @ xmath44 for the example function . [ image : analyex ] shows the example function and its gamma corrected version , together with their derivatives and the corresponding modified function . as before , the graphs of the functions are the same on the right and on the left . note that the invariants define a one - to - one mapping . that is , the mapping is not # ##al , and it is not possible to extract the original function from the # ##s . if @ xmath45 and @ xmath46 are to be seen in images ,from eqs . ( [ e : th12 g ] ) to ( [ eq : thm123 g ] ) are to be extended to two dimensions . this is to be done in a linear symmetric way in order to achieve stability under linear transformations . the standard approach is to use rotationally symmetric functions . for the first order , we use the well known _ gradient magnitude _ , _ _ @ xmath47 where @ xmath48 is the two - dimensional image function , and @ xmath49 , @ xmath50 are partial derivatives of the x - axis and the y - axis . for the second order derivative , we can use the linear _ laplacian _ @ xmath51 horn @ xcite ##r as an alternative second order derivative _ , the _ linear variation _ @ xmath52 since the qv is not a linear operator and is expensive to compute , we use the laplacian for our derivative . for the third order derivative , we can use , in close conjunction with the linear variation , the _ cubic variation _ as @ xmath53 the invariants from fig . ( [ e : th12 g ] ) to ( [ e : th##m123 ##3 ] ) remain valid in 2 - d if we replace @ xmath54 with @ xmath55 , @ xmath56 with @ xmath57 , and @ xmath58 with @ xmath59 . this can be done by going through the same argument as for the above . note that the critical observation in e . ( [ q : th12 ##3 ] ) is that @ xmath4 cancel out , which is the case when symmetric derivatives return a factor @ xmath4 . doing this is also the case with the other symmetric derivatives mentioned above . for example , if we apply the gradient descent operator to @ xmath60 , i . e . to the derivative of the mirror - image function , we obtain @ xmath61 returns a factor @ xmath4 , and similarly for @ xmath62 , qv , and q . a similar result holds for eq . ( [ q : th123 g ] ) where we want to show , in general , that the first derivative returns a factor @ xmath20 , the second derivative returns a factor @ xmath63 , and the third derivative returns aas @ xmath64 , which is the case for our 2 - d operators . since the derivatives of discrete , differentiable functions are easily determined , there are many ways to compute them for _ sampled _ functions . we use schmid and mohr @ xcite , ter haar romeny @ xcite , and many other methods , employing the derivatives of the sample function as means to compute the derivative of the sampled _ function via smoothing . this way , derivation is possible with smoothing . the 2 - d zero - function is defined as @ xmath65 the other functions up to the derivatives are @ xmath66 , @ xmath67 , @ xmath68 , @ xmath69 , @ xmath70 , @ xmath71 , @ xmath72 , @ xmath73 , @ xmath74 . they are shown in fig . [ fig : gausskernels ] . we used the kernel of @ xmath75 and the kernel @ xmath76 with these derivatives , etc . ( [ eq : th12 ##6 ] ) , for example , is defined as @ xmath7##7 for each pixel @ xmath78 , where @ xmath79 is used . we compute the invariant @ xmath45 from fig . ( [ g : thm12 g ] ) in two different ways . first , we measure how much the invariant computed on an image without gamma correction is different from the invariant computed on the same image but with gamma correction . theoretically , this difference should be zero , but in practice , it is significant . second , we compare template ##d accuracy for all measurements , both without and with gamma correction , to the accuracy of if instead the vector representation is used . we then test whether the invariant can be improved by prefiltering . a straightforward equivalent expression is the _ absolute error _ , @ xmath80 where ` ` 0gc ' ' refers to the image without gamma correction , and either stands for ` ` ` sgc ' ' if the gamma correction is done directly via eq . ( [ eq : gammacorr ] ) , or for ` ` cgc ' ' if the gamma correction is done via the camera itself . like the image itself , the absolute error is computed at each pixel , @ xmath81 of the image ,and for the image , where the derivatives and therefore the invariants can not be computed reliably . [ fig : imas ] shows an example image . the sgc invariant has been calculated from the 0gc image , with @ xmath82 . note that the error correction is applied _ after _ the quantization of the 0gc image , since we do nt have access to the 0gc image after quantization . [ fig : accuinv ] shows the two sources of the image taken from fig . [ fig : imas ] and the corresponding absolute values . since , we have . the two points in fig . [ fig : accuinv ] , ( d ) and ( e ) , are areas of large contrast . we have two different sources : * the derivative can only be computed exactly in homogeneous regions . this is not surprising , given that it is based on values which are by definition very sensitive to the geometry of the image . * there are outliers even in the sgc invariant representation , at points of very high contrast edges . they are a byproduct of the inherent error when the derivatives are computed with values of the origin . note that the latter is a limit of the spatial resolution ofthat is , for 8 - bit images . in addition to computing the absolute error , we can also compute the relative error , in pixels , as @ xmath83 . we can define the sets @ xmath84 of _ reliable points _ , relative to the corresponding threshold @ xmath85 , and @ xmath86 and @ xmath87 , the sets of reliable points , as @ xmath88 where @ xmath89 is the number of valid , i . e . non - missing , pixels in the image . [ tab : reliapts ] shows , in the first row , the reliable points for the different values of the threshold @ xmath85 . the second row shows the sets of reliable points for the same values if we can prefilter the 0gc and cgc images . the corresponding table for the two test images from fig . [ tab : imadb ] is shown in table [ tab : reliaperc ] . derivatives are known to be sensitive to noise . noise can be eliminated by processing the input data before the derivatives are computed . on the other hand , derivatives should be computed as quickly as possible . with these two goals to be met , weexperiment with gentle prefiltering , using a gaussian filter of size @ xmath90 = 1 . 0 . the size of the filter to compute the invariant @ xmath45 is set to @ xmath91 = 1 . 0 . note that @ xmath90 and @ xmath91 can _ not _ be combined into any one filter because of the non - existence of the invariant . with respect to the number of data points , we observe that after prefiltering , about half the points , on average , have a relative accuracy of less than 50 % . gentle prefiltering also reduces the absolute and relative errors , whereas gentle prefiltering does not . template matching is a commonly used technique in computer vision . here , we will examine how gamma correction affects the spatial accuracy of template matching , and whether that accuracy can be improved by using the invariant @ xmath45 . an example of the testbed algorithm is given in fig . [ fig : templloca ] . a random sample of size @ xmath92 , representing the search pattern , is taken from a 0gc ##c sample , i . e . without gamma correction . this sample template is then .with the same cgc intensity representation , i . e . the same image but with gamma values added on . if the correlation maximum occurs at exactly the location where the 0gc image template has been cut off , we call this the _ correct maximum correlation function _ , or cmcp . the correlation function @ xmath93 shown here is based on a weighted mean of : @ xmath94 @ xcite : @ xmath95 where @ xmath1 is the template , @ xmath96 is the template . for @ xmath78 , @ xmath97 is the mean of the subimage of @ xmath1 and @ xmath78 of the whole image . @ xmath96 , @ xmath98 is the mean of the template , and @ xmath99 . the template location problem here is to perform this correlation for the whole image and to determine whether the value of the correlation maximum occurs only at @ xmath78 . [ source : matchtempl ] demonstrates the template location problem , on the left for an intensity representation , and on the right for its invariant representation . the black box shows the location of the query template at( 50 , 15 ) , and the second figure shows the position of the matched template , which is incorrectly located at ( 50 , 15 ) in the original image . on the right , the matched template ( white ) has met the matched template ( black ) at the same , incorrectly located position . [ fig : correlexmpl ] shows the correlation function of the whole image . the white areas represent regions of high contrast . the section from fig . [ fig : matchtempl ] and [ fig : correlexmpl ] deals with the _ one _ arbitrarily selected images . in order to systematically solve the template location problem , we repeat the correlation process for all the template ##s . then we can compute the _ correlation accuracy _ ca for the set of correctly located templates , @ xmath100 where @ xmath101 is the location of the template , @ xmath102 is the number of template _ correlation ##s , and @ xmath89 , again , is the number of valid positions . we compute the correlation accuracy ca for unfiltered images and for the prefiltered images , with @ xmath103 . [ fig : corrcorrelpts ] .the binary correlation error is for our example , . the cmcp set is shown in red , the edges and the center in black . we observe a higher correlation accuracy for the invariant representation , which is improved by the prefiltering . we have calculated the correlation error for all the representations given in fig . [ fig : imadb ] . the results are shown in table [ tab : ca ] and visualized in fig . [ fig : correlaccuras ] . we observe the following : * the correlation error ca is higher on the invariant representation than on the intensity images . * the correlation accuracy is higher on the invariant representation with gentle prefiltering , @ xmath103 , than without prefiltering . we can observe a decrease in correlation accuracy if we extend the prefiltering interval beyond @ xmath103 . by contrast , prefiltering seems to be better applied to the intensity images , . * the correlation accuracy shows a large variation , typically in the range 10 % @ xmath10490 % for the unfiltered invariant images and 50 % @ xmath104100 % for prefiltered invariant representations . similarly , the variation in correlation accuracy ranges from close to 50up to 45 % . for our test images , it turns out that the invariant representation is always superior , but that does not necessarily have to be the case . * the ways and means of the cas for all test images determine the gain in correlation accuracy for the invariant representation . * the larger the template size , the higher the correlation accuracy , and of the representation . a larger template size means more stability , and more discriminatory properties . we have proposed several invariants that combine invariance under gamma correction with invariance under linear transformations . in a general sense , the cas can be viewed as round ##off derivatives for a power law parameter , which makes them interesting for applications in image processing . the error analysis of our cas on real data has shown that , for real data , the invariants can not be used nearly everywhere . however , the template - application scenario has shown that a large gain is achievable when using the proposed cas . bob woodham wrote to the authors to look into invariance under gamma correction . his meticulous reports on this topic were greatly appreciated . jochen lang helped with the acquisition of image data through the online program @ xcite . d . forsyth , a . mundy , a . zisse##rman , m . coelho , j . rothwell , ` ` invariant ##s for 3 - d object recognition and navigation ' ' , _ ieee transactions on pattern recognition and artificial intelligence _ , vol . 13 , no . 10 , pp . 971 - 991 , jan . 1991 . d . pai , j . lang , j . lloyd , r . woodham , ` ` robot , a telerobotic performance measurement system ' ' , ieee international conference on industrial robotics , vancouver , 1999 . see also : http : / / www . ieee . ubc . ca / nest / lci / 1999 /