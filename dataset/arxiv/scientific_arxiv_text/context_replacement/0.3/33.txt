the origin - destination ( od ) matrix is important in transportation analysis . the matrix contains information about the number of travellers that commute or the number of goods shipped between different parts of a region . the od matrix is difficult and often costly to obtain through direct measurements / studies or surveys , but by considering the passenger counts and the available data one can obtain a good estimate . a particular application of the od matrix estimation is in the field of public transport . in order to improve their performance , the responsible organisations are looking for on - going evaluation of the passenger flow and the factors that would influence this flow . this is especially the case for the city rail , sydney bus and sydney ferries organisations , which handle the public transport in the area around the city of sydney , australia . cityrail and co are handling a large number of stations ( stations , bus stops ) for transport ( buses and ferries ) across the city . they handle thousands of passengers every day , and periodically adjust the time - table available to better reflect the traffic demand . + + an optimal estimate of the matrix would consider the traffic in trains , drivers , buses and ferries . when the transport informations ( trains , drivers , stations ) are available to cityrail and co , the number of passengers onthe distance between each station can also be deduced directly from their current passenger flow data collection processes . + + various approaches to estimating the transport matrix using traffic counts have been developed and published @ xcite using traffic counts , or using passenger flows @ xcite , @ xcite . most of the papers in the literature solve this problem by postulating a general model for the trip distribution , for example a transport type model @ xcite , which aims at using the prior knowledge of the traffic distribution and assigning a parameter to each journey . then the data is produced to determine the parameters of this model . all these models _ are _ _ oriented _ . + most of the work related to od matrix estimation are based on passengers observations and the knowledge of where the passengers get in and out of the public transport . lo et al @ xcite developed a strategy based on the transport choice , which they called the transport link strategy , and used this to obtain a maximum likelihood estimator . nandi et al @ xcite developed a strategy based on a fixed cost per person per trip assumption on the fixed - route network of india and provide direct comparisons with the available data . + when the data is not available ( for example we have no data on when people get off thebus ) , kostakos @ xcite offers to use a direct estimate of the bus trips , and lundgren and peterson - - @ xcite is based on the generalized s - matrix previously mentioned . however , none of the above approaches involves using the data . indeed , if no specific information is available about the destination destinations , the simplest solution is to use an parking survey to estimate destination information . however , what elements of the survey are necessary for the estimation to be accurate ? bierliaire and toint @ xcite proposed a structure - based estimate of the origin - destination distance based on parking surveys . in their article , they used the parking surveys to infer an a priori estimate of the od matrix , and they used this estimate in combination with the partial observations of the traffic network to obtain a generalized least squares estimator of the od matrix . despite its novelty , this does assume that the data of car - drivers and public transport users are the same , at least for their respective od matrices . given that the public transport network topology is very different from the traffic network topology , one may doubt the validity of this assumption . moreover , they only use the partial observations obtained from the surveys . + the purpose of this article is then to developan estimation procedure for the origin - destination matrix based on the ticket records available for the transport network and / or from the surveys . in the example from bierliaire @ xcite , we use survey data collected from public transport networks , and estimate the approximate whole data structure and the estimation of its eigenvectors . we propose a robust version of the method to avoid biases caused by the survey . we also propose a regression estimation procedure that accounts for the presence of external factors such as the weather , or the location of the survey . + we will first present the regression model , and then move on to present the sample model . in section [ sec : om ] , we explain how the measurements are made , and what measurements that should be expected . in section [ sec : im ] , we explain the assumptions we make on the model , and how this affects our estimation procedure . we present in section [ sec : im ] the maximum likelihood ( ml ) estimation procedure , by introducing a set of equations to be solved , for the sample . we build on this ml estimation to make it robust to survey biases in section [ sec : rob ] . finally , we present a simple example and an analogy to a real - casesee section [ sec : app ] . we finally comment on the results and discuss the various research opportunities . let @ xmath0 be the matrix of passengers number of the stations in the transit network at time period @ xmath1 so that @ xmath2 is the number of passengers who depart from station @ xmath3 and arrive at station @ xmath4 at time period @ xmath1 . note that there is an obvious time period here , denoted by @ xmath1 the period in which the events occur ( for example a week ) . the goal of this work is to provide an estimate of @ xmath0 from the data specified in section [ sec : om ] . the assumptions made about the passengers are very simple , and simply counting them will give a direct estimation of @ xmath0 . we list in the subsections [ om - casual ] , [ om - deparr ] and [ om - transit ] the same kind of transit . a regular commuter is defined as a departure - arrival trajectory that is not repeated regularly ( e . g . daily ) . thus , people going to a once - in - a - year event will buy their tickets for that event and will then go onthe next day . then for single and day return passengers , we have the information under the assumption that they take the next train after purchasing their ticket and that they take the shortest route . let @ xmath5 be that matrix of measurements . each time between major stations , the passenger has to validate his ticket through the machines at the entrance of the station , and do it again at the exit . between major stations we assume they take the next train to arrive at the station they purchased their ticket at and assume they take the trip ##pers ' route for that time . two scenarios are possible . in the first case , ( called @ xmath6 ) , every station in the network has these machines . in the second case ( called @ xmath7 ) only major stations have these machines . in any case , we call @ xmath8 the vector corresponding to the departures of the stations , and @ xmath9 the vector of arrivals . then we can have only passengers with specific origin and destination , and this matrix can be denoted @ xmath10 , where the rows stand for the departure stations and the columns for the arrival stations . this matrix is observed , and is distributed according to the poisson probability function with mean @ xmath11. + the main part of the information , however , is statistical . indeed most of the passengers will probably have a zone ticket for a period of time , from 1 month to 1 year . the nature of these observations make the dates of departure and arrival unknown , and is the main challenge of this paper . we call @ xmath12 the set of the passengers numbers . + to make a good statistical inference , we need two assumptions ; * the traveller will travel independently of the time period of his trip ; * the regular passenger commits to a return journey on each successive day . the observations linked to this paper are two - folds . for major stations , we have the total number of passengers that use the boom gates , in and out . for stations without boom gates , the observations have to be from a computer . we also have access to the total number of passengers with a valid zone ticket at time @ xmath1 ( e . g . the duration of the trip ) , denoted @ xmath13 , @ xmath14 at the moment , the total number of regular passenger in the time period @ xmath1 will be denoted @ xmath15 , and we have , @ xmath16 with these two simple assumptions , we have a goodit is based on these assumptions . sections [ mam - gm ] , [ mam - gm ] , [ mam - da ] and [ ma - rm ] presents these assumptions for each parameter in our model . assuming that @ xmath17 is a matrix of means , the main assumption of that model is that the number of passengers is the sum of the casual passengers ( @ xmath18 ) and the regular passengers ( @ xmath15 ) plus a matrix of the unusual passenger events such as major sporting events , or large crowds ( @ @ xmath19 ) , @ xmath20 the casual commuter count could be said to be poisson , i . e . @ xmath21 is supposed to be drawn with a poisson distribution which parameter ##izes to the [ @ xmath22 . ] where @ xmath22 is the matrix of means for the count . + however , the variance of the counts are not assumed to be equal to their mean and therefore the poisson counts assumed may be unrealistic . therefore , we have to use a simple binomial regression model for @ xmath23 , which can be over - simplified in order to accurately describe the variance of the count . we assumed that @xmath22 is distributed according to a density function , @ xmath24 . for a purpose of estimation , let @ xmath23 be distributed as above , with values @ xmath25 and @ xmath26 ( we will use @ xmath27 ) . according to the definition of the matrix , the following conditions hold : @ xmath28 where @ xmath8 and @ xmath9 are the estimates of the total number of departure and arrivals from each station during the period @ xmath1 . for the same reasons as that for the density matrix , we can use a positive binomial distribution to model the area around the regular traveller for example . however , for the casual commuter , we do not have an over - distribution nor an under - distribution , so that , @ xmath29 and @ xmath30 . let @ xmath31 and @ xmath32 be the values of @ xmath33 and @ xmath34 . when the model is well defined , the estimation method is computationally straight forward , e . g . , between two stations where we have complete information of arrival and departure . note that the maximum likelihood estimation .this , however depends on the optimal solution of the optimization problem . in this case , the stationary process parameters are extracted from the data . since the data is unlikely to be stationary , we consider a second option ( section [ 2 : reg ] ) , a multivariate spatio - temporal model that we expect to fit the parameters to . the estimation procedure will be carried out in well - defined time . if we ignore the time dependence , the successive observations can be considered independent , using sample counts from the mean or poisson distribution . this means that the maximum likelihood method should work well , even for large sample sizes . we observe @ xmath18 for several realizations . given the space - time dependence we find that @ xmath5 is equally distributed with @ xmath35 . the result is then , @ xmath36 \ { { { } \ ] ] where @ xmath37 stands for one instance of the distribution @ xmath5 . we thus can estimate the parameters through , @ xmath38 despite the lack of closed loop solution to this problem , the greedy algorithm can still converge to a global solution . since we do not have complete information for those with weekly , daily , monthly and anuual data (long - term tickets ) . we have information of the times they arrives and leaves at minor stations . we ' ll have no information for the long term tickets going to or from minor stations . our assumption here is that only a few @ xmath39 of the @ xmath32 people will travel on the @ xmath1 , where @ xmath40 . @ xmath39 is an important parameter that determines the travel time . it may exist because when performing the calculation , we may find a better estimation of travellers than what we expected . some of the uncertainty is due to the randomness of @ xmath41 , but it may also be caused by the fact that travellers with no long term tickets do not necessary travel ahead of the first day of the week . + however , we can provide the same estimation for the @ xmath31 people as we did in the previous section , that is , @ xmath42 where @ xmath43 accounts for the same transfer function as above . + this leads us to the final step , the contribution this paper makes to the literature . the aim is to calculate the matrix @ xmath12 with the available departure and arrival data . the first step is to estimate the departure andof the @ xmath10 equation . the goal is to solve this in a simple way so that @ xmath12 has to be solved with @ xmath44 parameters , and only @ xmath45 equations . the following paragraph gives an elegant solution to this problem . + define @ xmath32 as the expectation of @ xmath46 . it is known that , we can diagonalize it , so that , @ xmath47 where @ xmath48 is a diagonal matrix of eigenvectors of @ xmath32 and @ xmath49 is an @ xmath44 diagonal matrix , with terms corresponding to the corresponding eigenvalues . thus , if the expectation of @ xmath32 is rational ( i . e . the eigenvectors are known ) and known , then we have reduced the problem to solving a system of @ xmath45 - parameters with @ xmath45 equations . [ ref : odeq ] and the following example , we have the following observation , @ xmath50 where @ xmath51 and @ xmath52 are obtained by linear regression . the probability density function of the observations @ xmath53 can then betherefore , @ xmath54 \ quad p \ big ( y _ { di } ^ t \ vert r _ z , p _ { rz } \ right ) & \ sim & \ mathcal { \ } ( \ { _ i } ^ { ij } _ z , p _ { rz } ) \ in { \ } \ ] ] where @ xmath55 and @ xmath56 . according to this formula , we can solve @ xmath57 _ [ ( @ xmath58 $ ] ) . @ xmath59 fails to solve ( @ xmath32 is wrong ) . to perform the estimation , we only need to know the number of parameters . according to ref . [ ref : diag ] , we know , @ xmath60 so , if we use @ xmath48 , the maximum estimate would be , and perform the estimation of @ xmath32 ( with @ xmath61 as the @ xmath3th parameter ) . the @ xmath57 estimate would be , , @ xmath62 \ quad p \ big ( y _ { di } ^ t \ vert r _ z ,p _ { rz } \ big ) & = & \ int _ { p \ big ( p _ { di } ^ t \ vert r _ t , p _ { rz } \ big ) \ end { t } \ ] ] where @ xmath63 . the maximum likelihood estimating equations are : , @ xmath64 moreover , this last equation can be simplified by assuming that the observations are independent based on all the parameters ( e . g . the parameters are independent ) , and , , @ xmath65 the size of the likelihood estimate is small due to the nature of @ xmath48 . to calculate @ xmath48 , remember that @ xmath31 is constant , we have , @ xmath66 therefore , we make the assumption that all the regular passengers behave identically in time , that is , @ xmath48 is only a function of time . then we calculate , @ xmath67 . @ xmath48 can be estimated from @ xmath68 , and introduced into equation [ q : ml ] to obtain equation . [ eq : mle ] . then , we can calculate @ xmath69 and @ xmat##h70 to be @ xmath71 . finding the solution of the [ x : mle ] is a simple optimization problem . the resulting matrix shape guarantees the existence of a solution , and it can be found by any given optimization algorithm . let this matrix be @ xmath72 . the problem with this estimator is that we can not guarantee that it will fulfil the underlying constraint of the unknown parameters . therefore , the diagonal of the matrix will be negative , and there will be some elements in the diagonal that wo nt be zero . therefore , additional constraints have to be added to the linear estimating problem . these are : + * constraint 1 * _ all the elements in the matrix @ xmath73 are greater than or equal to zero , or equivalently , @ xmath74 _ + * constraint 2 * _ all the other elements in the matrix @ xmath71 must be zero , or equivalently , @ xmath75 _ + * constraint 3 * _ the underlying constraint of the to be estimated is the probability matrix @ xmath76 . therefore , all the elements should belong to the [ @ xmath77 $ ] , @ xmath78 \ end{ aligned } \ ] ] _ all of the optimization programs that comply with the constraint have an element which belong to the constrained variables . one could be able to use as a starting point the mean values of the variables , corresponding to the two - dimensional ( @ xmath79 ) model . however , it is highly unlikely that this starting point will satisfy the constraint . therefore , the best choice so far seems to be the two elements of the matrix @ xmath80 , given that they naturally satisfy * constraint 1 * and * constraint 2 * . + + the complete optimization program therefore is , @ xmath81 with the expected value @ xmath82 . this optimization program can be replaced by an alternative version of the algorithm , corresponding to the version stated in [ ann : 1 ] . the first constraint is the poisson probability distribution , so that we have , + * proposition 1 : * _ suppose that @ xmath83 , then @ xmath84 ^ { - 1 } \ begin { aligned } \ end { aligned } \ ] ] where @ xmath85 is the matrix of estimated values of @ xmath32 . _ + if , we consider a maximum .instead of poisson , the following maximum likelihood estimate is used , + * proposition 1 : * _ suppose that @ xmath86 , then @ xmath87 where @ xmath88 is the sum of the parameters of @ xmath32 . _ + the proof of theorem 1 and 2 are presented in [ ann : b ] . we can also derive the follwing theorem , that ensures accuracy of the results of the estimation , + * proposition 1 * + suppose that @ xmath89 { \ a . t . \ } \ $ ] ( see also @ xcite , @ xcite ) . then we have , @ xmath90 { \ \ mathcal { p } \ } \ , \ text { p } \ ] ] the proof is presented in [ ann : b ] . if we want to deal with a more complex problem , it is clear that we need to consider spatial , temporal and temporal effects on the number of passengers , and not just the parameters of our model . + let @ xmath91 be a set of random variables , and @ xmath92 their spatial ( temporal ) effects on the number of passengers . ., the regression coefficients can be : , + @ xmath54 \ big & \ big ( x _ { di } ^ t \ vert x _ i , x _ { rz } , ( x _ i ) _ i \ big ) & \ sim & \ mathcal { k } \ big ( \ lambda _ { k } \ sum _ k p _ { ik } \ sum _ k p _ { jk } + \ beta _ k p _ l \ beta _ l , p _ { rz } \ big ) \ end { 3 } \ ] ] where the parameters to be estimated are @ xmath93 . the likelihood is expressed as in fig . [ 2 : like ] , and we have , @ xmath94 . , if we expect the likelihood function to be constant over time , then we have the following : ( as in [ ann : like ] ) , + * _ 3 : * _ if we apply the same procedure as above we get the following estimator , @ xmath95 ^ { - 1 } ^ { } ^ { x ( } { } ^ { x ) ^ { - 1 } \ end { aligned } \ ] ] where @ xmath##96 is the sum of the two numbers . _ + a more complex solution would be to perform the same technique as above , except that @ xmath48 will no longer be constant . therefore , the varying @ xmath97 s from @ xmath31 will result in the recovery of the matrix @ xmath32 . the reason why we do not perform a statistical analysis of the @ xmath98 s with this method is because @ xmath32 can be diagonalize , so we do nt ##h how the @ xmath98 becomes the @ xmath99 . then a real - time estimate for the regular train passenger is obtained . a statistical sensitivity test has to be performed in order to figure out if the results are not affected by the measurement uncertainty . the accuracy of the results will strongly depend on the corresponding sub - matrix @ xmath31 . in the [ sec : 1 ] , we assume that the correlation between the data @ xmath31 and @ xmath32 relies on the projection of @ xmath48 and @ xmath100 . moreover , we assume @ xmath101 ( eq . [ eq : ass1 ] ) , andthis information is the basis to derive the estimate @ xmath102 . + it is very difficult to design and implement a method that provides accurate information . therefore , eq . [ eq : ass1 ] is no longer applicable . to overcome this , we need to make an ad hoc estimate of the 2 - d value . + with the data having some unknown parameters , it provides useful information that we need . let @ xmath88 be the estimate based on the observation of @ xmath32 , based on the observation @ xmath101 . if correct , this estimation looks like the perfect prior estimate . we get , @ xmath103 . , considering that the data may be biased , we need to emphasize the significance of the observation @ xmath104 , by building an anti - correlation matrix @ xmath105 , such that , @ xmath106 where @ xmath107 and @ xmath108 . @ xmath109 is symmetric , and should correspond to an equal partition of the data in the two samples . , @ xmath110 . therefore , we need to use the information provided by @ xmath109 .then we define the two ad hoc parameters @ xmath111 , @ xmath112 we measure the success of our method by the ability to overcome biased survey data . to analyse the performance of the estimators , we assume that the noise matrix of the survey was biased according to the following two equations , @ xmath113 where @ xmath114 $ ] stands for the scale of the data , @ xmath115 $ ] stands for the absolute noise level , and @ xmath116 for the poisson distribution , and , @ xmath117 the difference between the two equations relies on the bias ##es . in ex . [ prop : noise ] , s values are randomly chosen regardless of the real value of the data . it is the type of bias we expect to find in badly designed surveys with respondents responding poorly . in ex . [ eq : prop . noise ] , we consider that the bias has the same shape as the @ xmath32 bias . this is essentially the equivalent of a random error usually described in the literature with the gaussian distribution . therefore , we expect the estimators to give better results when the survey s values are driven .fig . [ e : prop . noise ] . + figure [ fig : sensnoise ] . the ml and ad hoc estimation results for the two types of estimation , with different values of parameters and different strength of bias . as expected , the second type of bias ( eq . [ eq : prop . noise ] ) is more easily overcome by the first . the important conclusion we can draw from this result is that the ad hoc estimation performs better than the original ml estimate , no matter what kind of bias we encounter . the ad - hoc estimation is plotted in green . the upper line stands for a bias designed according to eq . [ eq : noise ] , and the bottom line for fig . [ e : prop . noise ] . the mse is calculated among @ xmath118 simulations . , title = " fig : " , width = 264 , height = 226 ] . . the ad - hoc estimation is plotted in green . the upper line stands for a bias designed according to fig . [ e : noise ] , and the bottom line for eq . [ eq : prop . noise ] . the mse is calculated among @ xmath118 simulations . , title = " fig: " , width = 264 , height = 226 ] + ci . the ad - hoc estimation is plotted in green . the upper line stands for a bias designed according to fig . [ prop : noise ] , and the bottom line for fig . [ eq : prop . noise ] . the mse is calculated among @ xmath118 simulations . , title = " fig : " , width = 264 , height = 226 ] ci . the ad - hoc estimation is plotted in green . the upper line stands for a bias designed according to fig . [ prop : noise ] , and the bottom line for fig . [ eq : prop . noise ] . the mse is calculated among @ xmath118 simulations . , title = " fig : " , width = 264 , height = 226 ] finally , and also more importantly , the ad hoc estimator is more accurate and its results are less affected by the number of observed observations . for example , we can see that the error ( mse ) distribution is shown in fig . [ prop : sensnoise ] for @ xmath119 , and for @ xmath120 . the importance of that being to allow for reliable time - series .( on a monthly basis , it would mean @ xmath121 . ) , which would be more complicated with the monthly estimation . let m be the @ xmath122 matrix , with observations and arrival times ( source and destination ) . we assume that any value of m is a random variable , generated according to the number of observations @ xmath123 , and the time @ xmath124 . the matrix @ xmath123 has the following entries , @ xmath125 \ ] ] let @ xmath126 be an observed sub - sample of m , i . e . , a proportion @ xmath127 of m , generated by @ xmath126 . we assume that for every value of m , @ xmath127 will be the same , unless modified by some low - level background noise . a representation of @ xmath126 is the following matrix , @ xmath128 \ ] ] the value of @ xmath127 in this matrix is roughly equal to @ xmath129 . the estimation of @ xmath130 is consistent with the definition of this matrix . however , @ xmath130 being a, we do this , and using the same algorithm described in the [ c : oi ] we are able to provide the following : @ xmath131 matrix ( for @ xmath132 , @ xmath133 , @ xmath134 and @ xmath135 matrices only ) , @ xmath136 & \ right [ \ begin { array } { ccccc } 0 & 1 & 0 & 1 & 48 \ \ 24 & 0 & 0 & 1 & 124 \ \ 68 & 18 & 0 & 126 & 0 \ \ 24 & 0 & 126 & 0 & 48 \ \ 24 & 124 & 0 & 0 & 0 \ end { array } \ right ] \ \ & \ \ \ left [ \ begin { array } { ccccc } 0 & 72 & 12 & 24 & 0 \ \ 68 & 0 & 1 & 0 & 54 \ \ 60 & 24 & 0 & 102 & 0 \ \ 12 & 0 & 102 & 0 & 0 \ \ 12 & 78 & 0 & 0 & 0 \ end { array } \ right ] & \ right [ \ begin { array } { ccccc } 0 & 72 & 0 & 1 & 0 \ \ 60 & 0& 24 & 0 & 0 \ \ 12 & 0 & 0 & 96 & 12 \ \ 54 & 42 & 0 & 0 & 0 \ \ 12 & 0 & 12 & 24 & 0 \ end { array } \ [ ] \ end { array } \ ] ] table [ tble : mse _ bin ] : the mean square error of the parameter for different number of observations and different degree of dispersion in the case of the negative mean model . we also provide in table [ tble : norm _ bin ] the p - value for the cramer - von mises statistical assumption of @ xmath137 and procedures for the parameter . . [ tble : mse _ bin ] negative mean model : estimate of the mean square error of the parameter , with different number of observations and different statistical assumption of @ xmath137 parameters of the model , and the sample variance ( under brackets ) . [ id = " ^ , ^ , ^ , ^ , ^ " , id = " ^ " , ] we provide as an example the population commuting from the sydney harbour bridge , according to the surveys published in @ xmath138 , @ xmath139 ,and @ xmath140 by the bureau of labor statistics of new south wales . the overall survey could have been analysed , but in order to be understandable , we must focus our analysis on the northern beaches area , dealing with @ xmath141 different wharfs and @ xmath142 different days . [ fig : lpw20xx ] is the distance between the piers , so that you would have a better access by taking only one ferry . + + we can see from the map , all the areas seem to be able to be reached starting from only one pier , except for darling harbour , watsons bay and garden island . + + from this , the objective is the estimation of the od matrix , which is much like the transport links as presented in the report except that instead of absolute values , it will be represented by counts of passengers . however , this survey does not have enough data to perform this estimation . in fact , it does not lack any observation of the ticket sales at the wharfs . therefore , to perform this estimation , we use a different database from the original source , which aimed at understanding the preferred mode of transport for people going to work . from this database , we only estimate those who were using theferry . + before we could do an analysis of these data , we had to consider that the origin and location of the passengers in the second survey # s corresponded to the destination of the first survey . therefore , we had to assign to each passenger the origin point of their survey as the closest wharf to their home , and a destination point the closest wharf to their home . the distance have been calculated according to the wharf and location , and survey ##s . this being done , we will provide a new origin - destination matrix . it is presented in fig . [ fig : jw2006 ] . + this od matrix is not supposed to have the same form as the regular od of the barrier counts . therefore , we will use the methodology presented in the [ fig : cpe ] to calculate the 2010 , 2011 and 2012 projection matrices according to the barrier counts . the weights and eigenvectors are then calculated , and the reconstruction of the individual passengers is presented in fig . [ fig : est1 ] and [ fig : est2 ] . we present in this paper a new estimation technique for the projection matrix . we use the data available from surveys to find the correct projection matrix and reduce to the sum of the dataspace . + using a maximum likelihood method , we define the estimating function and calculate an ad hoc estimator of the od matrix . we demonstrated its use in section [ 2 : rob ] . + we also demonstrated that a regression analysis could be performed on this kind of data , and showed that this estimation procedure is highly consistent . to the best of our knowledge , this is the first time that a such an approach was used to estimate the od matrix . this approach will improve the prediction accuracy of future journeys . + we finally applied our techniques to simulated traffic and real - time data of the actual transport using the data from the institute of transport research . + the estimation of the transport flow is the first step for the estimation of the passengers flow in the transport network . however , from this estimation point , we can perform : 1 . [ monit ] monitoring the passengers count ; 2 . [ forecast ] forecasting of the passengers count ( 1 week in advance for example ) ; 3 . [ forecast ] predicting the passengers flow in terms of spatio - temporal traffic change in the network in order to address the estimation task ( [ monit ] ) , several important assumptions need to be made , which will require # ##ing ##s being implemented . amongthem , we can cite the time between the validation and entry into the train as the time at which people take their train if they are regular passengers . therefore , a real - time access to the data is possible . although difficult , this seems possible . + the forecasting of passenger counts ( [ predict ] ) can be done without additional information ( if sufficient temporal information has been obtained for a particular place ) , even if the observation would probably have smaller variances . these forecasts could be helpful for efficient scheduling the train ( for example ) , but further study have to be done in order to understand the effects of complex factors such as the temperature or the weather . + real - time prediction of traffic flows ( [ predict ] ) is more difficult , but is still possible . what we call a spatio - temporal traffic flow is a change in the traffic , or in the actual transport route . _ to make this decision , we will use the probability distribution example , where the poisson distribution can be used instead of the negative binomial . thus , the pdf can be written as , @ xmath143 where @ xmath144 is the number we are interested in . then , if we make the assumption that the pdfof course if the population is sampled , then @ xmath145 is distributed according to the poisson model , with the parameter @ xmath146 , which can be re - distributed according to : . [ p : diag2 ] , @ xmath147 where the @ xmath148 are the parameters , and the @ xmath149 the element of the distribution p . if we take @ xmath150 , the probability distribution can then be calculated , @ xmath151 + therefore , the maximum - likelihood can be calculated as follow , @ xmath152 the maximum likelihood estimate is approximately equivalent to using the following example , @ xmath153 still has the constraint * c1 * and * c2 * . * c3 * is excluded because this type of parameter * * holds in the poisson modelling . if @ xmath154 , @ xmath155 and * c2 * do not hold . then the likelihood corresponds to the following one dimensional poisson model statistical estimator @ xmath156 . + the system of equations [ p : sys _ 1 ] is at first a very simple one . nevertheless ,it can be simplify so as to write , @ xmath157 where @ xmath158 is the unknown ##s . similarly , if we have @ xmath159 , then , @ xmath160 where @ xmath161 and @ xmath162 . then , we can continue with the expression , @ xmath163 finally , the above reasoning leads to the following expression , @ xmath164 where @ xmath165 . this expression will probably not be the best estimator given that it relies on the pdf of @ xmath166 , but has the potential to be relatively robust , with variance decreasing to 1 . _ _ let @ xmath167 be a probability density function . if @ xmath168 is the pdf of @ xmath169 , and @ xmath170 the pdf of @ xmath100 , we can write , @ xmath171 . consider the example shown in eq . [ 1 : linsol _ lamfg ] , and make the assumption that we are in the single value region , where @ xmath##172 . + , @ xmath173 where , @ xmath174 \ begin { \ } _ { ^ { - 1 } \ pi { s } \ n . \ ] ] and @ xmath100 is the integral of @ xmath48 according to the first integral . + + _ to prove the equality in probability , we need to know that , @ xmath175 where @ xmath176 . + with the right hand side , we have , @ xmath177 and we know that @ xmath178 { \ u . s . \ } p _ _ [ \ lambda $ ] . then , @ xmath179 and we have , @ xmath180 where @ xmath181 stands for the probability density function of @ xmath182 . + the first integral converge towards @ xmath183 and @ xmath57 goes to zero according to and . [ note : as ] . the formula for the second integral is the same . according to the assumption of the convergence of @ xmath100 , @ xmath181 converge towards the density of @ xmath184 and @ xmath##185 goes to zero . @ xmath186 is a constant , this is the calculation . @ xmath187 . [ [ calculation - in - case - of - poisson - regression - and - log - link - function ] ] * calculation in case of poisson regression ( and log link function ) * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + _ the rest of the calculation is similar to the previous one . first , if we assume that commuter flows have effects on the number of passengers , we can get , @ xmath188 where @ xmath98 is the matrix representing the influences ( @ xmath189 ) for baseline commuter flows and the marginal effects ( @ xmath190 ) for differences in commuter flows from baseline commuter flows . second , we assume that the same diagonalization ( but with the same eigenvectors ) will be used , which leads us to , @ xmath191therefore , @ xmath192 can be estimated according to the poisson process with the following parameters , @ xmath193 where the parameters to be calculated are @ xmath194 , which means we have to calculate @ xmath195 . . + the likelihood of each observation can also be written , @ xmath196 which gives the following log - likelihood , @ xmath197 therefore , to solve the final system of equations , we have to calculate the derivatives of the log - likelihood with respect to each observation @ xmath198 . _