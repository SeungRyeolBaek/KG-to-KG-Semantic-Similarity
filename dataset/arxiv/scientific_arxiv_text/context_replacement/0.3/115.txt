information - intensive research on capacity and performance for state - limited memory results in @ xcite , @ xcite , @ xcite and @ xcite . in @ xcite , the researchers consider a model of write - once memory ( wom ) . in particular , each memory cell can be in state of 0 or 1 . the state of a cell can change from 0 to 1 , but not from 1 later to 0 later . these write - once bits are called _ _ _ . it is shown that , the efficiency of storing data in a wom can be improved if one allows for rewrites and controls the read / write ##s state . multilevel cell memory is a memory model where the charge level of a cell can be easily increased , but is difficult to implement . recent multilevel memory technology allows many charge levels to be stored in a cell . cells are organized into blocks that contain multiple @ xmath2 cells . the best way to decrease the charge level of a cell is to erase the entire block ( i . e . , reduce the charge on all cells to zero ) and reprogram each cell . this takes time , consumes energy , and extends the lifetime of the memory . therefore , it is important to design efficientmodulation schemes that increase the number of cycles between successive erasures @ xcite , @ xcite , @ xcite , @ xcite . the rewriting schemes have different cell - levels depending on the current cell level and data to be stored . in this article , we call a modulation scheme a _ modulation code _ . two different objective functions for modulation codes are primarily discussed in this work : ( i ) increasing the number of rewrites for the worst case @ xcite and ( ii ) maximizing for the average case @ xcite . as finucane et al . @ xcite show , the problem for considering average performance is the entropy increase caused by the large number of erasures during the operation of a flash memory system . our analysis shows that the worst - case objective and the average performance objective are two special cases of our optimization problem . we also discuss under what conditions the optimality objective makes sense . in previous work ( e . g . , @ xcite ) , many modulation codes are shown to be nearly optimal as the number of cell - levels @ xmath0 goes to infinity . under the condition that @ xmath1 can not be used in practical systems . however , we can analyze asym##ptotically optimal modulation codes when @ xmath0 is only moderately large are the results from load - balancing theory @ xcite . this is an enhanced algorithm that improves the performance of practical algorithms here . theoretical analysis and simulation results show that this algorithm performs better than other theoretical - algorithms when @ xmath0 is moderately large . the rest of the paper is as follows . the mathematical model and performance - results are discussed in section [ sec : optimality - results ] . an asymptotically optimal modulation code , which is optimal for all i . i . d . probability distributions , is proposed in section [ sec : another - rewriting - algorithm ] . the storage efficiency of this asymptotically optimal modulation code is presented in section [ sec : an - enhanced - algorithm ] . the enhanced modulation code is also discussed in section [ sec : an - enhanced - algorithm ] . the storage efficiency of the enhanced algorithm is also analyzed in section [ sec : an - enhanced - algorithm ] . simulation results and analysis are presented in section [ sec : simulation - results ] . the analysis is presented in section [ sec : conclusion ] . digital memory systems often rely on error correction / correcting algorithms to ensure a low error rate .so far , these systems tend to use bose - chaudhuri - hocquenghem ( bch ) and reed - solomon ( rs ) codes . the error - correcting codes ( ' s ) are used as the outer codes and the modulation codes are the inner codes . in this section , we focus on the inner codes and consider the analysis and the design of ecc for now . let us assume that a block contains @ xmath3 @ xmath0 - level cells and that @ xmath4 cells ( called a @ xmath4 - variable ) are used together to store @ xmath5 @ xmath6 - ary values ( called b @ xmath5 - variable ) . a block contains @ xmath7 @ xmath4 - cells and the @ xmath7 @ xmath5 - variables are assumed to be i . i . d . - variables . we assume that all the @ xmath5 - variables are updated almost randomly at the same time and the new values are stored in the corresponding @ xmath4 - cells . this is a good assumption for a system with an outer code . we use the subscript @ xmath8 to representthe difference between and each rewrite increases @ xmath8 by 1 . when we use a modulation code , we focus on a single @ xmath4 - variable . ( the encoder of the modulation code increases all of the cell - levels based on the new cell - levels and the new value of the @ xmath5 - variable . ) remember that cell - levels can only be increased during a rewrite . therefore , when a cell - level cannot be increased to the new value @ xmath9 , the whole code is lost and all the cell levels are set to zero . we let the maximal allowable number of block - erasures be @ xmath10 and assume that after @ xmath10 block erasures , the code becomes unreliable . assume the @ xmath5 - variable present at time @ xmath8 is a new value @ xmath11 chosen from the set @ xmath12 with value @ xmath13 . for example , we can update the @ xmath5 - variable at time @ xmath8 in the same way as @ xmath14 where @ xmath15 denotes the set of integers modulo @ xmath6 . the cell - levelvector at time @ xmath8 is written as @ xmath16 and @ xmath17 denotes the charge level of the @ xmath18 - variable vector at time @ xmath19 when we say @ xmath20 we mean @ xmath21 for @ xmath22 since the charge level of the vector can only be zero , continuous expansion of the memory implies that an erasure of the memory itself will be required at some point . although writes , reads and erasures can all introduce noise into the memory , we neglect this and assume that the writes , reads and erasures are noise - free . when sending data to a computer , when encoder knows the previous cell state @ xmath23 the current @ xmath5 - vector @ xmath24 , and the encoding function @ xmath25 that maps @ xmath24 and @ xmath26 to the new cell - state vector @ xmath27 . the decoder also knows the current cell state @ xmath27 and the coding function @ xmath28 that maps the cell state @ xmath27 back to the original vector @ xmath29 . of course , the encoding and coding functions couldchoosing over allows to improve performance , but we only consider time - varying encoding / encoding functions for simplicity . the idea of designing efficient modulation codes able to store multiple information in different cells was introduced by jiang @ xcite . in previous work on modulation code jointly for flash memory ( e . g . @ xcite , @ xcite , @ xcite , @ xcite ) , the density of the device ( either worst - case or average ) is maximized given fixed amount of information per rewrite . improving the density and increasing the lifetime of the device are the main approaches . we can either design for and against the other or choose over these approaches jointly . most recent work ( e . g . , @ xcite ) uses the former approach , fixing the amount of information for each rewrite and setting the number of rewrites for successive cycles . in this work , we consider the latter approach and our goal is to maximize the total amount of information stored in the device until the device fails . this is equivalent to setting the average ( over the @ xmath5 - variable , @ xmath13 ) amount of information stored per bit - level , @ xmath30 where @ xmath31 is the amount ofinformation stored in the @ xmath18 - variable rewrite , @ xmath32 is the number of rewrites between memory cells , and the average case over the @ xmath5 - variable one . we can call @ xmath33 _ _ _ efficiency _ . in the work ##flow of codes for flash memory , the number of changes of an @ xmath4 - cell has been evaluated in two different ways . the authors in @ xcite consider the worst case number of rewrites and the authors in @ xcite consider the average number of changes . as mentioned in @ xcite , the motivation for considering the average case is due to the average number of changes in the state of a flash memory device . interestingly , these two cases can be seen as two extreme cases of the optimization found in ( [ eq : opt ] ) . let the @ xmath5 - variables be a sequence of i . i . d . random variables in time and all the @ xmath4 - variables . the goal of optimization is to maximize the amount of information stored until the device dies . the total amount of information stored in the device - state corresponds to the optimal amount , should it be asmore information ? should this count as a change ? this formula assumes that this counts as a rewrite , so that @ xmath34 s ( less than @ xmath35 ) can be changed during the iteration . ] can be upper - bounded by @ xmath36 where @ xmath37 is the number of bits between the @ xmath38 - th and the @ xmath18 - th values . note that the upper bound in ( [ eq : x _ info _ ub ] ) is achievable for the input distribution , i . e . , when the input @ xmath5 - variable is uniformly distributed over @ xmath39 , the expression contains @ xmath40 bits of information . due to the i . i . d . distribution of the input distribution over variables , @ xmath37 s are i . i . d . over and over time . since @ xmath37 s are i . i . d . over time , we can use the expression @ xmath18 . since @ xmath10 , which is the minimum number of erasures required , is approximately on the order of @ xmath41 , by the lawof natural number ( lln ) , we have @ xmath42k \ log _ { 2 } ( l ) . \ ] ] let the set of all valid encoder / receiver pairs be @ xmath43 where @ xmath44 and the charge levels are step - ##wise non - negative . this allows us to treat the problem @ xmath45 as the following : [ @ xmath46k \ log _ { 2 } ( l ) . \ left { 1 : opt2 - 1 } \ ] ] denote the maximum charge level of the @ xmath18 - th @ xmath4 - cell at time @ xmath8 as @ xmath47 . note that time at @ xmath8 is reset to zero when a block change occurs and increased by one for each change occurs . denote the maximum charge level of a cell at time @ xmath8 as @ xmath48 which can be calculated as @ xmath49 and @ xmath50 as the time when the @ xmath18 - th @ xmath4 - cell reaches its maximum allowed charge , i . e . , @ xmath51 . we have , perhaps ,, that a block - erase is required when any value of a block reaches its maximum allowed value . the time when a block erase is required is defined as @ xmath52 it is easy to see that @ xmath53 = [ \ left [ t \ right ] , $ ] where the values vary in the @ xmath5 - cell s . [ maximizing @ xmath54 $ ] is equivalent to solving @ xmath55 . so the optimization problem ( [ eq : opt2 - 1 ] ) can be written as the following optimization [ @ xmath56 . \ label { 1 : opt3 } \ ] ] under the assumption that the input is i . i . d . for all the @ xmath4 - cells and time t , one knows that the @ xmath50 s are i . i . d . random variables . let their joint probability density function ( pdf ) be @ xmath57 it is easy to see that @ xmath58 is the sum of @ xmath7 i . i . d . random variables with pdf @ xmath57 if , we have @ xmath59 where @ xmath60 is the cumulative distribution function (cdf ) of @ xmath61 . , the optimization problem ( [ e : opt3 ] ) becomes @ xmath62 = \ int _ { f , t \ in \ mathcal { d } } \ int nf _ { t } ( x ) \ left ( x - f _ { t } ( x ) \ right ) ^ { n - 1 } = \ mbox { d } \ . \ label { eq : opt } \ ] ] note that when @ xmath63 the optimization problem ( ( [ eq : opt ] ) reduces to @ xmath64 . \ label { eq : opt2 } \ ] ] this is essentially the case that the data in @ xcite used . when the whole sequence is represented as an @ xmath4 - cell and the number of erasures required is half , then the total ( over all possible sequences ) number of rewrites of an @ xmath4 - cell is equivalent to half the total amount of data in @ xmath65 the analysis above shows that the reason we improve the performance is not necessarily due to the rounding error caused by the large number of erasures . a very general .is that there is only one @ xmath4 - cell per block . the worst case is when @ xmath66 in this case , the pdf @ xmath67 tends to a constant value at the minimum of @ xmath8 and the pdf @ xmath68 at the minimum of @ xmath8 . this is the worst case stopping point for the optimization process of the @ xmath4 - cell . this case is determined by @ xcite . our analysis shows that we should consider the worst case when @ xmath69 even though the function has a large number of cycles . so the optimality of is not determined only by @ xmath10 , but also by @ xmath70 when @ xmath7 and @ xmath10 are small , it makes more sense to consider the worst case when . when @ xmath71 , it is important to consider the average performance . when @ xmath7 is moderately large , we should consider the number of cycles using ( [ x : 1 ] ) which is the worst case and the average performance . when @ xmath7 is very small , we should instead focus on improving the function= ( [ q : 0 ] ) , but it is not clear how to do this directly . so , this is an open problem for further research . next , we can use a load - balancing approach to design practical systems where @ xmath0 is storage efficient . if we assume that there is only one value changed each cycle , the average amount of information per cell - level can be bounded by @ xmath72 because there are @ xmath73 possible new values . since the number of rewrites can be bounded by @ xmath74 we have @ xmath75 if we make arbitrary change on the @ xmath5 - variables , there are totally @ xmath76 possible new values . it can be shown that @ xmath77 for fixed @ xmath6 and @ xmath0 , the bound in ( [ eq : storage _ efficiency _ efficiency ] ) implies using a large @ xmath5 to improve the storage efficiency . this is also the way that working with many cells can improve the storage efficiency @ xcite . since most compression schemes only allow a single cell - level to change by itself during each cycle , decodability implies that @ xmat##h78 for the first case and @ xmath79 for the second case . however , the constraints in ( [ eq : storage _ efficiency _ bound2 ] ) and ( [ q : storage _ efficiency _ bound ] ) both require a @ xmath4 to achieve storage efficiency . the lower bound in ( [ eq : storage _ efficiency _ bound ] ) grows continuously with @ xmath5 and the upper bound in ( [ eq : storage _ efficiency _ bound2 ] ) grows logarithmically with @ xmath5 . therefore , in the analysis of this paper , we assume an explicit change in the @ xmath5 - variable per block and @ xmath71 , i . e . , the whole block is treated as an @ xmath4 - variable , to improve the storage efficiency . this change implicitly improves the efficiency for the storage efficiency because more cells are needed to store the same number of data , and the data can therefore be accessed many more times . note that the assumption of @ xmath71 might be incorrect for real data , but its assumption gives an upper bound on the storage efficiency . from the analysis above with @ xmath71, we also note that for @ xmath33 is equivalent to doubling the total number of bits . in @ xcite , modulation codes are proposed that are not optimal ( since @ xmath0 goes to zero ) in the average case when @ xmath80 . in this section , we propose a modulation scheme that is not optimal for arbitrary input distributions and for @ xmath5 and @ xmath6 . this modulation scheme can be considered as an extension of the one in @ xcite . the idea is , to increase the signal - levels , on average for each arbitrary input value . of course , decodability must be maintained . the solution is to use the information , available to both the encoder ( to determine the input value ) and the decoder ( to determine the decodability ) , to increase the signal levels over time for each particular input value . let us assume the @ xmath5 - variable is an i . i . d . - variable over time with the distribution @ xmath13 and the @ xmath5 - variable over time @ xmath8 is denoted by @ xmath81 the output of the algorithm##der ##iving it as @ xmath82 we choose @ xmath83 and let the cell state vector at time @ xmath8 be @ xmath84 , where @ xmath17 is the charge level of the @ xmath18 - th cell at time @ xmath19 and @ xmath85 , the cells are assigned to @ xmath86 , @ xmath87 and @ xmath88 . the encoding algorithm @ xmath89 is described as follows . * step 1 : read cell state vector @ xmath27 and calculate the @ xmath90 and @ xmath91 . * step 2 : calculate @ xmath92 and @ xmath93 the encoding algorithm @ xmath94 is described as follows . * step 1 : read cell vector @ xmath26 and calculate @ xmath95 and @ xmath96 as follows . if @ xmath97 then do so . * step 2 : calculate @ xmath98 and @ xmath99 * step 3 : increase the charge level of the @ xmath100 - th cell by 1 . forhowever , for the rest of the article , we describe the above modulation scheme as ` ` self - random ##ized code ' ' . the self - random ##ized code achieves at random @ xmath101 rewrites with high probability , as @ xmath102 for arbitrary @ xmath103 @ xmath104 and i . i . d . input distribution @ xmath13 . however , it is asymptotically stable for random inputs as @ xmath1 . [ sketch of proof ] the proof is similar to the proof in @ xcite . since only one cell has its index increased by 1 during each cycle , @ xmath105 is an infinite number that increases by 1 at each rewrite . the cell number to be found @ xmath100 is randomized by adding the value @ xmath106 . this causes each successive cycle of @ xmath76 , to have a uniform affect at all other levels . for @ xmath1 , an infinite number of values are obtained and we can find @ xmath107 . consider the first @ xmath108 cycle , the value @ xmath10##9 is as large as once over @ xmath110 for example , we assume there are @ xmath111 @ xmath112 terms for each point , and the rounding error by 1 is absorbed by the @ xmath113 term . then the uniform distribution is @ xmath114 . for the case that @ xmath115 , the case that @ xmath116 is @ xmath117 for @ xmath118 . therefore , @ xmath119 has a uniform distribution over @ xmath12 . since terms are random over time , and apply the same chernoff integral ##s to @ xcite , it follows that the number of times @ xmath116 is at most @ xmath120 with high probability ( larger than @ xmath121 ) for each @ xmath122 . once over @ xmath122 , we have the proof . suppose that the random term @ xmath105 a random term which is @ xmath100 times _ up _ over time in the sense that there are equally random terms for each value . moreover , @ xmath105 is known to boththe encoder and the receiver such that the encoder can generate ` ` uniform ' ' cell values in time and the decoder knows the maximum value of @ xmath105 , and can subtract it out and interpret the data directly . although this algorithm is asymptotically optimal for @ xmath1 , the maximum number of cells @ xmath123 can not be reached for the @ xmath0 . this motivates the development and the design of an improved version of this algorithm for embedded systems in this section . a pseudo - randomized binary code uses @ xmath83 cells to represent the @ xmath5 - variable . this is much faster than the @ xmath124 used in other asymptotically optimal algorithms because we allow the @ xmath5 - variable to accumulate values . although this appears to be a waste of cells , the total amount of memory required per cell - level is still large ( see ( [ eq : storage _ efficiency _ bound2 ] ) and ( [ q : storage _ efficiency _ bound ] ) ) . in particular , the question of the optimality of @ xmath##79 if we allow some modifications to the @ xmath5 - code . we note that the optimality of the self - random modulation codes is similar to the weak modulation codes presented in @ xcite . we use @ xmath83 cells to represent all of @ xmath125 possible messages . this is slightly worse than the standard method of using @ xmath126 . is it possible to use self - randomization codes only @ xmath126 cells ? a detailed analysis of this problem based on dimensional analysis shows that it is not . thus , the smallest cell gives the possibility to change the mappings between the values and the cell values over time . while asymptotically optimal modulation codes ( e . g . , codes like @ xcite , @ xcite , @ xcite , @ xcite and the self - random modulation codes presented in the [ sec : another - one - code ] ) use @ xmath1 , these codes use @ xmath0 values between @ xmath127 and @ xmath128 . compared to the number of cells @ xmath4 , the number of @ xmath0 is not quite large enough for asympt##otic optimality to compute . in other words , codes that are asymptotically optimal may have a suboptimal performance when the system sizes are not large enough . however , different asymptotically optimal codes may perform differently when @ xmath0 is not large enough . therefore , asymptotic optimality can be misleading in this case . in this case , we first analyze the storage efficiency of non - randomized modulation codes when @ xmath0 is not large enough and then find an efficient algorithm which improves the storage efficiency significantly . after we analyze the storage efficiency of asymptotically optimal modulation codes for moderately large @ xmath0 , we first consider the connection between modulation codes and the load - balancing problem ( aka the balls - into - bin or balls - and - bin model ) which is well studied in mathematics and computer science @ xcite . basically , the load - balancing problem asks how to distribute weight among a set of locations as evenly as possible . specifically , the balls - and - bin model considers the following problem . if @ xmath129 balls are thrown into @ xmath4 bin , with each ball being thrown into a bin chosen independently and uniformly .random , with the _ load _ of the number of balls in a bin , what is the maximal load over all the bin ? based on the results of step 1 of @ xcite , we take a different and more general approach to the balls - into - bins problem and arrive at the following theorem . [ see : random _ load ] suppose that @ xmath129 balls are sequentially loaded into @ xmath4 bins . each time a bin is selected independently and loaded at random . the maximal load over all the bin is @ xmath130 and : ( @ xmath18 ) if @ xmath131 the maximally loaded bin has @ xmath132 balls , @ xmath133 and @ xmath134 , with high probability ( @ xmath135 ) as @ xmath136 ( @ xmath137 ) if @ xmath138 , the maximally loaded bin has @ xmath139 balls , @ xmath140 , with high probability ( @ xmath135 ) as @ xmath136 ( @ xmath141 ) if @ xmath142 the maximally loadedbin ##s @ xmath143 , @ xmath144 , @ xmath145 and @ xmath146 , with the probability ( @ xmath135 ) as @ xmath136 denote the event that there are at least @ xmath5 balls in a given bin as @ xmath147 . applying the union bound to all balls of bin @ xmath103 it is possible to show that the probability that @ xmath147 exists is further bounded by @ xmath148 by stirling kernel ##s , we have @ xmath149 . then @ xmath150 can be further bounded by @ xmath151 if @ xmath152 , substitute @ xmath153 to the value of ( [ x : maxload _ ub ] ) , we have @ xmath154 denote the probability that all bins have at least @ xmath5 balls as @ xmath155 . by applying the union bound , it is shown that @ xmath156 since @ xmath157 we have the probability for the case of @ xmath158 if @ xmath13##8 , substitute @ xmath159 to the limit of ( [ q : maxload _ ub ] ) , we have @ xmath160 by applying the union bound , we finish the proof for the case of @ xmath161 if @ xmath142 substitute @ xmath162 to the rhs of ( [ q : maxload _ ub ] ) , we have @ xmath163 where @ xmath164 by applying the union bound , it is known that @ xmath165 since @ xmath166 we finish the proof for the case of @ xmath167 so that theorem [ th : random _ loading ] also shows an upper bound for the maximum of @ xmath130 with a simple approximation . more precise results can be found in theorem 1 of @ xcite , where the exact maximum of @ xmath130 is given for all cases . it is worth noting that the results in theorem 1 of @ xcite are different from theorem [ th : random _ loading ] because theorem 1 of @ xcite holds with probability @ xmath168 and theorem [ th : random _ loading ] holds with probability( @ xmath135 ) . the asymptotic optimality of the rewriting theorem implies that each rewrite write increases the cell - level of each cell by one and all the charge - levels are only used when an erasure occurs . this theorem implies @ xmath169 . since @ xmath4 is usually a large constant and @ xmath0 is not large enough in practice , the theorem implies that , when @ xmath0 is not large enough , asymptotic optimality is not guaranteed . for example , in block systems , the number of charge - levels @ xmath0 does not depend on the number of cells in the block . thus , rather than @ xmath74 only , @ xmath170 charge level can be increased by @ xmath171 if @ xmath0 is a positive constant which is independent of @ xmath4 . in practice , this loss could be mitigated by using writes that increase the charge level in multiple cells simultaneously ( instead of in the block ) . [ thm : gamma1 ] the self - signed block system has storage efficiency @ xmath172 when @ xmath173and @ xmath174 when @ xmath175 , @ xmath4 goes to zero with high probability ( i . e . , @ xmath168 ) . consider the problem of throwing @ xmath129 balls into @ xmath4 bins and let the r . v . @ xmath10 increase the number of balls thrown into @ xmath4 bin until some bin has more than @ xmath9 balls in it . if we would like to calculate @ xmath176 $ ] ] , we must look for an expression based on the following formula . if @ xmath177 , then there is a constant @ xmath178 such that maximum number of balls @ xmath130 in each bin is @ xmath179 with setting @ xmath168 as @ xmath171 @ xcite . the constant @ xmath178 is given by the largest @ xmath180 - multiple of @ xmath181 and using this formula for @ xmath182 gives the correct constant @ xmath183 . since the upper bound makes the maximum expected value better , we get @ x##math184 and apply this to our problem with the parameters @ xmath185 and @ xmath186 . therefore , the storage efficiency is @ xmath187 if @ xmath188 , the maximum efficiency is approximately @ xmath189 with large @ xmath168 for large @ xmath4 @ xcite . by definition , therefore , the storage efficiency is @ xmath191 the results of the [ 1 : gamma1 ] show that when @ xmath0 is on the order of @ xmath192 , the storage efficiency is on the order of @ xmath193 . taking the limit as @ xmath194 with @ xmath195 , we have @ xmath196 when @ xmath0 is a constant independent of @ xmath4 , the storage efficiency is on the order of @ xmath197 taking the limit as @ xmath171 with @ xmath173 , we have @ xmath198 . in this regime , the non - linear binary algorithms often perform very poorly even when they are as efficient as @ xmath1 . in thebins - and - balls problem , where we split balls more evenly when @ xmath199 is of the order of @ xmath200 fortunately , when @ xmath201 , the maximal gain can be reduced by a factor of 2 @ xmath202 by using _ the _ of _ random choice _ @ xcite . in fact , the result is , every time we pick two cells independently and choose one , and throw the ball into the less loaded bin . by doing this , the less loaded bin is roughly @ xmath203 , with high gain . theorem 2 . @ xcite gives the answer in the following form when we use @ xmath204 random choices . the result shows there is a large gain when the number of random choices is increased from 1 to 2 . beyond that , the gain is of the same order and therefore the constant can be reduced . based on the result of 2 random choices , we define the following phase - space relaxation algorithm . again , we let the current state voltage at time @ xmath8 be @ xmath84 , where @ xmath17 is the charge level of the @ xmath18 - 1 cell at time @ xmath19this way , we write @ xmath205 bits to store a @ xmath5 - variable @ xmath206 ( i . e . , we write @ xmath207 bits to store @ xmath208 bits of information ) . the information store gives @ xmath6 bits to write the same information . this also allows us to avoid thousands of writes that increase the information level too much . we are primarily interested in random variables with 2 possible choices or @ xmath209 . for the number of @ xmath6 bits to be known , we must try to compute ( over time ) , the @ xmath6 - choices over the field of all @ xmath210 elements . the algorithm @ xmath91 is used to do this . let @ xmath211 be the finite field with @ xmath212 elements and @ xmath213 be the bijection that contains @ xmath214 ( i . e . , the finite field of 0 elements associated with the number 0 ) . the following algorithm calculates @ xmath215 from @ xmath27 and operates as follows : * step .: read the state vector @ xmath27 and calculate the @ xmath90 and @ xmath91 . * step 2 : calculate @ xmath216 and @ xmath217 * step 3 : calculate @ xmath218 and @ xmath219 * step 4 : calculate @ xmath220 . the first algorithm is @ xmath11 and is as follows . * step 1 : read state vector @ xmath26 and decode to @ xmath221 and @ xmath96 . if @ xmath222 , do so . * step 2 : calculate @ xmath223 , @ xmath218 , and @ xmath219 * step 3 : calculate @ xmath224 and @ xmath225 for @ xmath226 . * step 4 : calculate @ xmath227 . increase the cell density by number of cells @ xmath228 . note that the state vector of @ xmath85 is equal to @ xmath229 and not @ xmath87 . the first cell density that can be calculated is @ xmath230 . the secondthis means that the random - loading performance of the modulation code is identical to the random loading algorithm with @ xmath209 random choices . [ proof : gamma2 ] if @ xmath209 and @ xmath175 , then the random - loading modulation code has storage efficiency @ xmath231 with probability 1 - @ xmath232 as @ xmath171 . if @ xmath233 the storage efficiency @ xmath234 with probability 1 - @ xmath232 . [ proof of theorem ] consider the modulation code @ xmath235 for @ xmath236 and @ xmath237 . as @ xmath238 vary , this code generates the two elements @ xmath11 and @ xmath239 uniformly for all pairs of their indices . after @ xmath240 steps , we find that all pairs of @ xmath238 vary equally evenly . therefore , after picking the more than pairs , the modulation code is almost identical to the random loading algorithm with the random choices . unfortunately , we are wrong in the case where @ xmath241 , the analysis is much more complicated . if@ xmath177 , the maximum charge level is @ xmath242 with probability @ xmath168 @ xcite . since @ xmath175 in this case , the storage capacity is @ xmath243 . if @ xmath188 , then @ xmath173 and the storage capacity is @ xmath244 . by definition , we have @ xmath245 if , we have @ xmath246 if @ xmath209 and @ xmath0 . on the right of @ xmath247 conjecture [ gamma : gamma2 ] shows that the efficiency ( [ gamma : storage _ efficiency _ bound ] ) is reduced for load - balancing modulation codes when @ xmath4 goes to infinity . in this case , the load - balancing modulation codes have a greater efficiency than self - balancing modulation codes by adding infinitely many bits . [ note : if @ xmath209 and @ xmath0 are a constant multiple of @ xmath4 , the storage capacity is @ xmath248 for the non - constant modulation code and @ xmath249 for the load - balancing modulation code. but , the load - balancing modulation code uses @ xmath250 cells and the load - balancing modulation code uses @ xmath251 cells . to make fair use of the computational difference between them , we use @ xmath251 for both codes . then we have @ xmath252 and @ xmath249 . then , for @ xmath171 , we see that @ xmath253 . therefore , the load - balancing modulation code and the self - randomized code when @ xmath4 are sufficiently efficient . in this section , we present the above results for the modulation codes given in sections [ sub : a - encoding - algorithm ] and [ sub : an - encoding - algorithm ] . in the section , the first modulation code is called the ` ` self - randomized modulation code ' ' and the second is called the ` ` load - balancing modulation code ' ' . let the ` ` loss factor ' ' @ xmath254 be the fraction of cell - blocks which are not used when a memory erasure is applied : @ xmath255 } { [ ( n - 1 ) } . $ ] we show the loss factor for a code with 1and use random choices as input . note that @ xmath254 does not take the amount of data per bit - level into account . results in fig . [ flo : fig2 ] show that the self - based modulation code has the same @ xmath254 with random loading with 1 random choice and the load - based modulation code has the same @ xmath254 with random loading with 2 random choices . this shows the optimality of these two modulation codes in terms of random vs . , @ xmath209 and the following . [ flo : fig2 ] ] with @ xmath80 , @ xmath256 @ xmath257 and many others . [ flo : fig4 ] ] . [ fig : fig5 ] ] . [ fig : fig6 ] ] we then compare the modulation code for random loading with 1 random choice and the algorithm given by @ xcite , which we know as flm - ( @ xmath258 ) algorithm , in fig . [ flo : fig4 ] . from results presented in fig . [ flo : fig4 ] , we see that the flm - ( @ xmath258 ) algorithm has the sameloss ##less as random loading with a random choice . this can be easily seen from the proof of the optimality in @ xcite . the algorithm transforms an arbitrary input variable into a uniform distribution in the cell - level space . note that flm algorithm is also proved to be optimal when every bit of information is stored . so we can compare the flm algorithm with random loading algorithm in this case . [ fig : fig5 ] and fig . [ fig : fig6 ] show the storage efficiency @ xmath33 for these two modulation codes . [ fig : fig5 ] and fig . [ fig : fig6 ] show that the self - random modulation code is better than self - randomized modulation code when @ xmath4 is optimal . this is also shown by the following framework in remark [ fig : if ##f ] . in this paper , we consider modulation code generation techniques for distributed flash memory storage systems . the storage efficiency , or average ( over the set of input variables ) amount of storage per cell - level is maximized . in this framework , we show the ratio of the number of rewrites for the the worst - case criterion @ xcite and the best - case criterion @ xcite in the worst case ofour optimization objective . the self - balancing modulation code is proposed which is storage efficient for arbitrary input distribution and arbitrary @ xmath5 and @ xmath6 , given the number of power - levels @ xmath1 . we first consider performance of practical applications where @ xmath0 is not large enough for the results to obtain . then we consider the storage efficiency of the self - balancing modulation code when @ xmath0 is only moderately large . then the self - balancing modulation codes are calculated based on the interaction of two random variables @ xcite @ xcite . experimental and numerical results show that the load - balancing scheme extends previously proposed algorithms .