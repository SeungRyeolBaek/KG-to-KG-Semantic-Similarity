Computer chips are arguably both the most complex things ever mass produced by humans and the most disruptive to our lives.
So it's remarkable that the  extraordinary pace they have evolved at was in large part influenced by a three-page article published 50 years ago this weekend.
It noted that the maximum number of components that manufacturers could "cram" onto a sliver of silicon - before which the rising risk of failure made it uneconomic to add more - was doubling at a regular pace.
Its author, Gordon Moore, suggested this could be extrapolated to forecast the rate at which more complicated chips could be built at affordable costs.
The insight - later referred to as Moore's Law - became the bedrock for the computer processor industry, giving engineers and their managers a target to hit.
Intel - the firm Mr Moore went on to co-found - says the law will have an even more dramatic impact on the next 20 years than the last five decades put together.
But could its time be more limited?
Although dubbed a "law", computing's pace of change has been driven by human ingenuity rather than any fixed rule of physics