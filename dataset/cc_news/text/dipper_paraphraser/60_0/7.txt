The cloud-speech api has been updated by google, and the first of these, the translation of voices from speech, is already provided. , the first of which is to be done for the customer , the second of which is to be implemented on the other, which is gboard. meanwhile, according to a blog post by google, the api now has the new feature of the word-level timestamps, and the translations of three hours, and the 30 new languages are in addition to those already in the application, with all the languages to be spoken in the api, and it’s the only thing that accompanies the cloud-based speech api, as it’s based on the neural network, which is used to turn the audio to text. Moreover, the language supports three hours of files, an increase from the previous limit of 80 minutes. As a part of a wider announcement of the voice input capabilities of the cloud-based speech api, it’s going to support thirty new languages and three hour files. Among the many languages it supports, you can find the list of the languages that can be used by the cloud-based speech api here. The word-level timestamps feature, the post said, was the most requested feature by the developers, essentially, it adds a time stamp to every word in the transcription that is tagged. The word-level timestamps feature will let users jump up to the moment when the text is being said, or display the text as it is playing, ” the post said. The list of the languages that are supported by the cloud-based speech api can be found here. - The foreign language — is just a kind of proverb for Google. You can join the list of supporters, and you can also subscribe to the Google Weekly.