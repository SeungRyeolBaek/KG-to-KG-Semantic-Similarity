At the same time, the cloud speech api introduced a new feature - called word-level timestamps - with 30 new languages and three hours of files. This feature, the developer said, is a software, a neural network, which converts audio to text. Its result is instantaneous and is automatically presented to the user. As a consequence, the api became more attractive to business users. As a matter of fact, the cloud speech api had a number of new languages added, with the first support for them to the api, but eventually, the other products of google, like gboard, will be supported. As a result of this, the developers of the api demanded a new feature called word-level timestamps, and this feature added thirty new languages and three hours. It is a neural network that can convert sound to text. It is powered by machine learning and can return the results in real time. So, on Monday, Google announced that it had also announced a new feature: word-level timestamps, and it now supports 30 languages, which will bring the total number of languages supported to 119. In a broader announcement on the voice input of the api, the api now supports 30 additional languages, raising the total number of languages in the system to 119. As the api, the file lengths of files will be up to three hours, which is an increase from the previous limit of 80 minutes. the file lengths will be up to three hours, the post says, - there is a friendly tone in a word, and the language could help Google to win some business in emerging markets ... . . - You can stay informed by signing up for the weekly newsletter from the techrepublic of Google ...